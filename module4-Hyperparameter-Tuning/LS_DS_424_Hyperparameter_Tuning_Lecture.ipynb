{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "41TS0Sa0rDNx"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Lecture 4*\n",
    "\n",
    "# Model Validation with Keras - Boston Housing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZyirqVC_sC64"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0s0o2pqBs88q"
   },
   "source": [
    "### Load Boston Housing Data\n",
    "\n",
    "Even though we can import this dataset from Keras, Keras already has it divided up into test and train datasets for us I don't want that for this demonstration, so I'm going to import it from Scikit-Learn instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "cMMt4MtAsVx0",
    "outputId": "a4e3e990-f948-46e6-ea93-dd7433a317e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "from sklearn.datasets import load_boston\n",
    "boston_dataset = load_boston()\n",
    "df = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\n",
    "df['MEDV'] = boston_dataset.target\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pm7zow5IvaTt"
   },
   "source": [
    "## Normalizing Input Data\n",
    "\n",
    "It's not 100% necessary to normalize/scale your input data before feeding it to a neural network, the network can learn the appropriate weights to deal with data of as long as it is numerically represented,  but it is recommended as it can help **make training faster** and **reduces the chances that gradient descent might get stuck in a local optimum**.\n",
    "\n",
    "<https://stackoverflow.com/questions/4674623/why-do-we-have-to-normalize-the-input-for-an-artificial-neural-network>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "q5qDpUj9vZVw",
    "outputId": "ce27017a-b173-455d-954e-d462e17e66f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.41978194  0.28482986 -1.2879095  ... -1.45900038  0.44105193\n",
      "  -1.0755623 ]\n",
      " [-0.41733926 -0.48772236 -0.59338101 ... -0.30309415  0.44105193\n",
      "  -0.49243937]\n",
      " [-0.41734159 -0.48772236 -0.59338101 ... -0.30309415  0.39642699\n",
      "  -1.2087274 ]\n",
      " ...\n",
      " [-0.41344658 -0.48772236  0.11573841 ...  1.17646583  0.44105193\n",
      "  -0.98304761]\n",
      " [-0.40776407 -0.48772236  0.11573841 ...  1.17646583  0.4032249\n",
      "  -0.86530163]\n",
      " [-0.41500016 -0.48772236  0.11573841 ...  1.17646583  0.44105193\n",
      "  -0.66905833]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split into X and y and turn into numpy arays\n",
    "y = df.MEDV.values\n",
    "X = df.drop(\"MEDV\", axis='columns').values\n",
    "\n",
    "# Scale input data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l6hgCWbir90R"
   },
   "source": [
    "## Model Validation using an automatic verification Dataset\n",
    "\n",
    "Instead of doing a train test split, Keras has a really nice feature that you can set the validation.split argument when fitting your model and Keras will take that portion of your test data and use it as a validation dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1750
    },
    "colab_type": "code",
    "id": "GMXVfmzXp1Oo",
    "outputId": "b05e251e-508f-46e6-865b-f869ae2a5dc4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0718 13:45:08.771214 140307783022400 deprecation_wrapper.py:119] From /home/seek/anaconda3/envs/U4-S2-NNF/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0718 13:45:08.782205 140307783022400 deprecation_wrapper.py:119] From /home/seek/anaconda3/envs/U4-S2-NNF/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0718 13:45:08.783950 140307783022400 deprecation_wrapper.py:119] From /home/seek/anaconda3/envs/U4-S2-NNF/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0718 13:45:08.810444 140307783022400 deprecation_wrapper.py:119] From /home/seek/anaconda3/envs/U4-S2-NNF/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0718 13:45:08.926615 140307783022400 deprecation_wrapper.py:119] From /home/seek/anaconda3/envs/U4-S2-NNF/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0718 13:45:08.979226 140307783022400 deprecation_wrapper.py:119] From /home/seek/anaconda3/envs/U4-S2-NNF/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 339 samples, validate on 167 samples\n",
      "Epoch 1/50\n",
      "339/339 [==============================] - 1s 3ms/step - loss: 656.6758 - mean_squared_error: 656.6758 - val_loss: 283.6923 - val_mean_squared_error: 283.6923\n",
      "Epoch 2/50\n",
      "339/339 [==============================] - 0s 171us/step - loss: 441.1910 - mean_squared_error: 441.1910 - val_loss: 176.2945 - val_mean_squared_error: 176.2945\n",
      "Epoch 3/50\n",
      "339/339 [==============================] - 0s 166us/step - loss: 124.4932 - mean_squared_error: 124.4932 - val_loss: 119.7941 - val_mean_squared_error: 119.7941\n",
      "Epoch 4/50\n",
      "339/339 [==============================] - 0s 166us/step - loss: 34.4127 - mean_squared_error: 34.4127 - val_loss: 93.7980 - val_mean_squared_error: 93.7980\n",
      "Epoch 5/50\n",
      "339/339 [==============================] - 0s 167us/step - loss: 18.5432 - mean_squared_error: 18.5432 - val_loss: 89.1373 - val_mean_squared_error: 89.1373\n",
      "Epoch 6/50\n",
      "339/339 [==============================] - 0s 168us/step - loss: 14.8870 - mean_squared_error: 14.8870 - val_loss: 89.8743 - val_mean_squared_error: 89.8743\n",
      "Epoch 7/50\n",
      "339/339 [==============================] - 0s 163us/step - loss: 12.9423 - mean_squared_error: 12.9423 - val_loss: 84.3894 - val_mean_squared_error: 84.3894\n",
      "Epoch 8/50\n",
      "339/339 [==============================] - 0s 163us/step - loss: 11.9470 - mean_squared_error: 11.9470 - val_loss: 80.0044 - val_mean_squared_error: 80.0044\n",
      "Epoch 9/50\n",
      "339/339 [==============================] - 0s 168us/step - loss: 11.1692 - mean_squared_error: 11.1692 - val_loss: 76.1156 - val_mean_squared_error: 76.1156\n",
      "Epoch 10/50\n",
      "339/339 [==============================] - 0s 170us/step - loss: 10.6109 - mean_squared_error: 10.6109 - val_loss: 74.0853 - val_mean_squared_error: 74.0853\n",
      "Epoch 11/50\n",
      "339/339 [==============================] - 0s 171us/step - loss: 10.2930 - mean_squared_error: 10.2930 - val_loss: 70.0746 - val_mean_squared_error: 70.0746\n",
      "Epoch 12/50\n",
      "339/339 [==============================] - 0s 161us/step - loss: 9.4594 - mean_squared_error: 9.4594 - val_loss: 67.2399 - val_mean_squared_error: 67.2399\n",
      "Epoch 13/50\n",
      "339/339 [==============================] - 0s 166us/step - loss: 8.9744 - mean_squared_error: 8.9744 - val_loss: 64.1413 - val_mean_squared_error: 64.1413\n",
      "Epoch 14/50\n",
      "339/339 [==============================] - 0s 173us/step - loss: 8.5632 - mean_squared_error: 8.5632 - val_loss: 62.8129 - val_mean_squared_error: 62.8129\n",
      "Epoch 15/50\n",
      "339/339 [==============================] - 0s 172us/step - loss: 8.1582 - mean_squared_error: 8.1582 - val_loss: 60.2608 - val_mean_squared_error: 60.2608\n",
      "Epoch 16/50\n",
      "339/339 [==============================] - 0s 196us/step - loss: 7.9045 - mean_squared_error: 7.9045 - val_loss: 58.8135 - val_mean_squared_error: 58.8135\n",
      "Epoch 17/50\n",
      "339/339 [==============================] - 0s 180us/step - loss: 7.6739 - mean_squared_error: 7.6739 - val_loss: 57.0794 - val_mean_squared_error: 57.0794\n",
      "Epoch 18/50\n",
      "339/339 [==============================] - 0s 178us/step - loss: 7.4152 - mean_squared_error: 7.4152 - val_loss: 55.7853 - val_mean_squared_error: 55.7853\n",
      "Epoch 19/50\n",
      "339/339 [==============================] - 0s 172us/step - loss: 7.0903 - mean_squared_error: 7.0903 - val_loss: 53.5614 - val_mean_squared_error: 53.5614\n",
      "Epoch 20/50\n",
      "339/339 [==============================] - 0s 165us/step - loss: 6.8296 - mean_squared_error: 6.8296 - val_loss: 51.3249 - val_mean_squared_error: 51.3249\n",
      "Epoch 21/50\n",
      "339/339 [==============================] - 0s 166us/step - loss: 6.6759 - mean_squared_error: 6.6759 - val_loss: 50.4140 - val_mean_squared_error: 50.4140\n",
      "Epoch 22/50\n",
      "339/339 [==============================] - 0s 163us/step - loss: 6.5738 - mean_squared_error: 6.5738 - val_loss: 48.1812 - val_mean_squared_error: 48.1812\n",
      "Epoch 23/50\n",
      "339/339 [==============================] - 0s 166us/step - loss: 6.3392 - mean_squared_error: 6.3392 - val_loss: 47.7926 - val_mean_squared_error: 47.7926\n",
      "Epoch 24/50\n",
      "339/339 [==============================] - 0s 169us/step - loss: 6.3225 - mean_squared_error: 6.3225 - val_loss: 47.6229 - val_mean_squared_error: 47.6229\n",
      "Epoch 25/50\n",
      "339/339 [==============================] - 0s 168us/step - loss: 5.9184 - mean_squared_error: 5.9184 - val_loss: 44.9246 - val_mean_squared_error: 44.9246\n",
      "Epoch 26/50\n",
      "339/339 [==============================] - 0s 163us/step - loss: 5.8285 - mean_squared_error: 5.8285 - val_loss: 44.8609 - val_mean_squared_error: 44.8609\n",
      "Epoch 27/50\n",
      "339/339 [==============================] - 0s 163us/step - loss: 5.7081 - mean_squared_error: 5.7081 - val_loss: 43.3255 - val_mean_squared_error: 43.3255\n",
      "Epoch 28/50\n",
      "339/339 [==============================] - 0s 159us/step - loss: 5.5681 - mean_squared_error: 5.5681 - val_loss: 42.1649 - val_mean_squared_error: 42.1649\n",
      "Epoch 29/50\n",
      "339/339 [==============================] - 0s 164us/step - loss: 5.6050 - mean_squared_error: 5.6050 - val_loss: 42.0664 - val_mean_squared_error: 42.0664\n",
      "Epoch 30/50\n",
      "339/339 [==============================] - 0s 163us/step - loss: 5.4758 - mean_squared_error: 5.4758 - val_loss: 41.3714 - val_mean_squared_error: 41.3714\n",
      "Epoch 31/50\n",
      "339/339 [==============================] - 0s 161us/step - loss: 5.2490 - mean_squared_error: 5.2490 - val_loss: 40.3693 - val_mean_squared_error: 40.3693\n",
      "Epoch 32/50\n",
      "339/339 [==============================] - 0s 167us/step - loss: 5.3183 - mean_squared_error: 5.3183 - val_loss: 41.0985 - val_mean_squared_error: 41.0985\n",
      "Epoch 33/50\n",
      "339/339 [==============================] - 0s 164us/step - loss: 5.0757 - mean_squared_error: 5.0757 - val_loss: 39.6502 - val_mean_squared_error: 39.6502\n",
      "Epoch 34/50\n",
      "339/339 [==============================] - 0s 171us/step - loss: 5.1037 - mean_squared_error: 5.1037 - val_loss: 38.5852 - val_mean_squared_error: 38.5852\n",
      "Epoch 35/50\n",
      "339/339 [==============================] - 0s 165us/step - loss: 5.1316 - mean_squared_error: 5.1316 - val_loss: 39.4804 - val_mean_squared_error: 39.4804\n",
      "Epoch 36/50\n",
      "339/339 [==============================] - 0s 167us/step - loss: 4.7808 - mean_squared_error: 4.7808 - val_loss: 38.3114 - val_mean_squared_error: 38.3114\n",
      "Epoch 37/50\n",
      "339/339 [==============================] - 0s 168us/step - loss: 4.8312 - mean_squared_error: 4.8312 - val_loss: 38.7558 - val_mean_squared_error: 38.7558\n",
      "Epoch 38/50\n",
      "339/339 [==============================] - 0s 161us/step - loss: 4.6554 - mean_squared_error: 4.6554 - val_loss: 37.5340 - val_mean_squared_error: 37.5340\n",
      "Epoch 39/50\n",
      "339/339 [==============================] - 0s 157us/step - loss: 4.7184 - mean_squared_error: 4.7184 - val_loss: 37.6118 - val_mean_squared_error: 37.6118\n",
      "Epoch 40/50\n",
      "339/339 [==============================] - 0s 163us/step - loss: 4.6130 - mean_squared_error: 4.6130 - val_loss: 37.0222 - val_mean_squared_error: 37.0222\n",
      "Epoch 41/50\n",
      "339/339 [==============================] - 0s 163us/step - loss: 4.6167 - mean_squared_error: 4.6167 - val_loss: 37.9605 - val_mean_squared_error: 37.9605\n",
      "Epoch 42/50\n",
      "339/339 [==============================] - 0s 162us/step - loss: 4.4323 - mean_squared_error: 4.4323 - val_loss: 37.1464 - val_mean_squared_error: 37.1464\n",
      "Epoch 43/50\n",
      "339/339 [==============================] - 0s 168us/step - loss: 4.4337 - mean_squared_error: 4.4337 - val_loss: 37.4908 - val_mean_squared_error: 37.4908\n",
      "Epoch 44/50\n",
      "339/339 [==============================] - 0s 172us/step - loss: 4.9562 - mean_squared_error: 4.9562 - val_loss: 36.1799 - val_mean_squared_error: 36.1799\n",
      "Epoch 45/50\n",
      "339/339 [==============================] - 0s 173us/step - loss: 4.4410 - mean_squared_error: 4.4410 - val_loss: 37.1268 - val_mean_squared_error: 37.1268\n",
      "Epoch 46/50\n",
      "339/339 [==============================] - 0s 166us/step - loss: 4.2980 - mean_squared_error: 4.2980 - val_loss: 37.1455 - val_mean_squared_error: 37.1455\n",
      "Epoch 47/50\n",
      "339/339 [==============================] - 0s 168us/step - loss: 4.2021 - mean_squared_error: 4.2021 - val_loss: 37.3521 - val_mean_squared_error: 37.3521\n",
      "Epoch 48/50\n",
      "339/339 [==============================] - 0s 161us/step - loss: 4.2454 - mean_squared_error: 4.2454 - val_loss: 36.8122 - val_mean_squared_error: 36.8122\n",
      "Epoch 49/50\n",
      "339/339 [==============================] - 0s 168us/step - loss: 4.1829 - mean_squared_error: 4.1829 - val_loss: 35.7847 - val_mean_squared_error: 35.7847\n",
      "Epoch 50/50\n",
      "339/339 [==============================] - 0s 159us/step - loss: 4.1641 - mean_squared_error: 4.1641 - val_loss: 37.1510 - val_mean_squared_error: 37.1510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9b7b691940>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Important Hyperparameters\n",
    "inputs = X.shape[1]\n",
    "epochs = 50\n",
    "batch_size = 10\n",
    "\n",
    "# Create Model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(inputs,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "# Compile Model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "# Fit Model\n",
    "model.fit(X, y, validation_split=0.33, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FYgb6yiKzyK5"
   },
   "source": [
    "## Model Verification using a Manual Verification Dataset\n",
    "\n",
    "Even though Keras has this nice feature you can still do train test split and pass it both X_test and y_test datasets as a tuple using the `validation_data` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1750
    },
    "colab_type": "code",
    "id": "D6SenwGVzQlK",
    "outputId": "ccab02a8-f28f-4db9-9065-89b52b177266",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 339 samples, validate on 167 samples\n",
      "Epoch 1/50\n",
      "339/339 [==============================] - 0s 591us/step - loss: 519.4874 - mean_squared_error: 519.4874 - val_loss: 365.9913 - val_mean_squared_error: 365.9913\n",
      "Epoch 2/50\n",
      "339/339 [==============================] - 0s 164us/step - loss: 315.0657 - mean_squared_error: 315.0657 - val_loss: 177.0889 - val_mean_squared_error: 177.0889\n",
      "Epoch 3/50\n",
      "339/339 [==============================] - 0s 165us/step - loss: 123.4233 - mean_squared_error: 123.4233 - val_loss: 63.0012 - val_mean_squared_error: 63.0012\n",
      "Epoch 4/50\n",
      "339/339 [==============================] - 0s 159us/step - loss: 50.5835 - mean_squared_error: 50.5835 - val_loss: 36.2535 - val_mean_squared_error: 36.2535\n",
      "Epoch 5/50\n",
      "339/339 [==============================] - 0s 165us/step - loss: 32.1084 - mean_squared_error: 32.1084 - val_loss: 26.2886 - val_mean_squared_error: 26.2886\n",
      "Epoch 6/50\n",
      "339/339 [==============================] - 0s 163us/step - loss: 25.3804 - mean_squared_error: 25.3804 - val_loss: 20.8686 - val_mean_squared_error: 20.8686\n",
      "Epoch 7/50\n",
      "339/339 [==============================] - 0s 167us/step - loss: 21.9954 - mean_squared_error: 21.9954 - val_loss: 19.2966 - val_mean_squared_error: 19.2966\n",
      "Epoch 8/50\n",
      "339/339 [==============================] - 0s 158us/step - loss: 20.0220 - mean_squared_error: 20.0220 - val_loss: 17.6861 - val_mean_squared_error: 17.6861\n",
      "Epoch 9/50\n",
      "339/339 [==============================] - 0s 149us/step - loss: 18.3553 - mean_squared_error: 18.3553 - val_loss: 16.4890 - val_mean_squared_error: 16.4890\n",
      "Epoch 10/50\n",
      "339/339 [==============================] - 0s 162us/step - loss: 17.2971 - mean_squared_error: 17.2971 - val_loss: 15.6196 - val_mean_squared_error: 15.6196\n",
      "Epoch 11/50\n",
      "339/339 [==============================] - 0s 154us/step - loss: 16.3619 - mean_squared_error: 16.3619 - val_loss: 15.5516 - val_mean_squared_error: 15.5516\n",
      "Epoch 12/50\n",
      "339/339 [==============================] - 0s 165us/step - loss: 15.7549 - mean_squared_error: 15.7549 - val_loss: 14.4158 - val_mean_squared_error: 14.4158\n",
      "Epoch 13/50\n",
      "339/339 [==============================] - 0s 154us/step - loss: 15.1482 - mean_squared_error: 15.1482 - val_loss: 14.0524 - val_mean_squared_error: 14.0524\n",
      "Epoch 14/50\n",
      "339/339 [==============================] - 0s 160us/step - loss: 14.5491 - mean_squared_error: 14.5491 - val_loss: 13.7007 - val_mean_squared_error: 13.7007\n",
      "Epoch 15/50\n",
      "339/339 [==============================] - 0s 157us/step - loss: 14.1644 - mean_squared_error: 14.1644 - val_loss: 13.6367 - val_mean_squared_error: 13.6367\n",
      "Epoch 16/50\n",
      "339/339 [==============================] - 0s 151us/step - loss: 13.7645 - mean_squared_error: 13.7645 - val_loss: 12.9659 - val_mean_squared_error: 12.9659\n",
      "Epoch 17/50\n",
      "339/339 [==============================] - 0s 162us/step - loss: 13.0559 - mean_squared_error: 13.0559 - val_loss: 12.7399 - val_mean_squared_error: 12.7399\n",
      "Epoch 18/50\n",
      "339/339 [==============================] - 0s 156us/step - loss: 13.0001 - mean_squared_error: 13.0001 - val_loss: 12.5791 - val_mean_squared_error: 12.5791\n",
      "Epoch 19/50\n",
      "339/339 [==============================] - 0s 160us/step - loss: 12.8112 - mean_squared_error: 12.8112 - val_loss: 12.4496 - val_mean_squared_error: 12.4496\n",
      "Epoch 20/50\n",
      "339/339 [==============================] - 0s 155us/step - loss: 12.1070 - mean_squared_error: 12.1070 - val_loss: 12.7595 - val_mean_squared_error: 12.7595\n",
      "Epoch 21/50\n",
      "339/339 [==============================] - 0s 160us/step - loss: 12.1297 - mean_squared_error: 12.1297 - val_loss: 13.0854 - val_mean_squared_error: 13.0854\n",
      "Epoch 22/50\n",
      "339/339 [==============================] - 0s 155us/step - loss: 11.9373 - mean_squared_error: 11.9373 - val_loss: 11.7180 - val_mean_squared_error: 11.7180\n",
      "Epoch 23/50\n",
      "339/339 [==============================] - 0s 157us/step - loss: 11.4325 - mean_squared_error: 11.4325 - val_loss: 13.0982 - val_mean_squared_error: 13.0982\n",
      "Epoch 24/50\n",
      "339/339 [==============================] - 0s 156us/step - loss: 11.3839 - mean_squared_error: 11.3839 - val_loss: 12.1295 - val_mean_squared_error: 12.1295\n",
      "Epoch 25/50\n",
      "339/339 [==============================] - 0s 157us/step - loss: 10.9182 - mean_squared_error: 10.9182 - val_loss: 13.1988 - val_mean_squared_error: 13.1988\n",
      "Epoch 26/50\n",
      "339/339 [==============================] - 0s 161us/step - loss: 10.8641 - mean_squared_error: 10.8641 - val_loss: 11.3831 - val_mean_squared_error: 11.3831\n",
      "Epoch 27/50\n",
      "339/339 [==============================] - 0s 157us/step - loss: 10.7482 - mean_squared_error: 10.7482 - val_loss: 12.1664 - val_mean_squared_error: 12.1664\n",
      "Epoch 28/50\n",
      "339/339 [==============================] - 0s 160us/step - loss: 10.4357 - mean_squared_error: 10.4357 - val_loss: 11.0877 - val_mean_squared_error: 11.0877\n",
      "Epoch 29/50\n",
      "339/339 [==============================] - 0s 155us/step - loss: 10.3387 - mean_squared_error: 10.3387 - val_loss: 11.7770 - val_mean_squared_error: 11.7770\n",
      "Epoch 30/50\n",
      "339/339 [==============================] - 0s 155us/step - loss: 10.1015 - mean_squared_error: 10.1015 - val_loss: 12.5824 - val_mean_squared_error: 12.5824\n",
      "Epoch 31/50\n",
      "339/339 [==============================] - 0s 160us/step - loss: 9.9847 - mean_squared_error: 9.9847 - val_loss: 11.1138 - val_mean_squared_error: 11.1138\n",
      "Epoch 32/50\n",
      "339/339 [==============================] - 0s 158us/step - loss: 9.9506 - mean_squared_error: 9.9506 - val_loss: 10.9869 - val_mean_squared_error: 10.9869\n",
      "Epoch 33/50\n",
      "339/339 [==============================] - 0s 157us/step - loss: 9.5835 - mean_squared_error: 9.5835 - val_loss: 10.7292 - val_mean_squared_error: 10.7292\n",
      "Epoch 34/50\n",
      "339/339 [==============================] - 0s 170us/step - loss: 9.5341 - mean_squared_error: 9.5341 - val_loss: 10.9844 - val_mean_squared_error: 10.9844\n",
      "Epoch 35/50\n",
      "339/339 [==============================] - 0s 153us/step - loss: 9.4555 - mean_squared_error: 9.4555 - val_loss: 11.1800 - val_mean_squared_error: 11.1800\n",
      "Epoch 36/50\n",
      "339/339 [==============================] - 0s 169us/step - loss: 9.1081 - mean_squared_error: 9.1081 - val_loss: 11.1625 - val_mean_squared_error: 11.1625\n",
      "Epoch 37/50\n",
      "339/339 [==============================] - 0s 178us/step - loss: 8.9391 - mean_squared_error: 8.9391 - val_loss: 10.6223 - val_mean_squared_error: 10.6223\n",
      "Epoch 38/50\n",
      "339/339 [==============================] - 0s 168us/step - loss: 9.2489 - mean_squared_error: 9.2489 - val_loss: 10.6742 - val_mean_squared_error: 10.6742\n",
      "Epoch 39/50\n",
      "339/339 [==============================] - 0s 161us/step - loss: 8.7865 - mean_squared_error: 8.7865 - val_loss: 10.6626 - val_mean_squared_error: 10.6626\n",
      "Epoch 40/50\n",
      "339/339 [==============================] - 0s 168us/step - loss: 8.6696 - mean_squared_error: 8.6696 - val_loss: 10.4922 - val_mean_squared_error: 10.4922\n",
      "Epoch 41/50\n",
      "339/339 [==============================] - 0s 161us/step - loss: 8.6590 - mean_squared_error: 8.6590 - val_loss: 10.5357 - val_mean_squared_error: 10.5357\n",
      "Epoch 42/50\n",
      "339/339 [==============================] - 0s 162us/step - loss: 8.6698 - mean_squared_error: 8.6698 - val_loss: 10.8956 - val_mean_squared_error: 10.8956\n",
      "Epoch 43/50\n",
      "339/339 [==============================] - 0s 167us/step - loss: 8.4510 - mean_squared_error: 8.4510 - val_loss: 10.9854 - val_mean_squared_error: 10.9854\n",
      "Epoch 44/50\n",
      "339/339 [==============================] - 0s 175us/step - loss: 8.3135 - mean_squared_error: 8.3135 - val_loss: 10.8825 - val_mean_squared_error: 10.8825\n",
      "Epoch 45/50\n",
      "339/339 [==============================] - 0s 166us/step - loss: 8.3735 - mean_squared_error: 8.3735 - val_loss: 11.1136 - val_mean_squared_error: 11.1136\n",
      "Epoch 46/50\n",
      "339/339 [==============================] - 0s 169us/step - loss: 8.2178 - mean_squared_error: 8.2178 - val_loss: 10.9441 - val_mean_squared_error: 10.9441\n",
      "Epoch 47/50\n",
      "339/339 [==============================] - 0s 168us/step - loss: 7.9823 - mean_squared_error: 7.9823 - val_loss: 10.7644 - val_mean_squared_error: 10.7644\n",
      "Epoch 48/50\n",
      "339/339 [==============================] - 0s 157us/step - loss: 8.0635 - mean_squared_error: 8.0635 - val_loss: 10.5886 - val_mean_squared_error: 10.5886\n",
      "Epoch 49/50\n",
      "339/339 [==============================] - 0s 161us/step - loss: 7.7929 - mean_squared_error: 7.7929 - val_loss: 10.5306 - val_mean_squared_error: 10.5306\n",
      "Epoch 50/50\n",
      "339/339 [==============================] - 0s 154us/step - loss: 7.6601 - mean_squared_error: 7.6601 - val_loss: 10.7163 - val_mean_squared_error: 10.7163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9b60239978>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Random Seed\n",
    "seed = 42\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# Load Dataset\n",
    "boston_dataset = load_boston()\n",
    "df = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\n",
    "df['MEDV'] = boston_dataset.target\n",
    "\n",
    "# Split into X and y and turn into numpy arays\n",
    "y = df.MEDV.values\n",
    "X = df.drop(\"MEDV\", axis='columns').values\n",
    "\n",
    "# Scale inputs\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Manual Validation Dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=seed)\n",
    "\n",
    "# Important Hyperparameters\n",
    "inputs = X.shape[1]\n",
    "epochs = 50\n",
    "batch_size = 10\n",
    "\n",
    "# Create Model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(inputs,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "# Compile Model\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['mse'])\n",
    "# Fit Model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k3FOE1vxx7yn"
   },
   "source": [
    "## Manual K-fold Cross Validation (regression)\n",
    "\n",
    "K-fold Cross Validation is the best way to validate your model as it will reduce the variance of your overall accuracy measure by splitting the data into smaller cross validation batches using one of the split out datasets as the validation dataset. The model is then fit K times rotating the validation set until each portion of the data has served as the validation dataset, the accuracy results from each subset are then averaged and reported as the overall test accuracy. The upside is that you can be more confident in your model's final reported accuracy. The downside is that you have to train your model K times which is computationally expensive and just not pheasible for some large networks that can take days to train a single time.\n",
    "\n",
    "K-fold Cross Validation gets tricky if you want to standardize your data because you will have to standardize your X values for each fold of your model separately. Due to this, we're going to use a Scikit-Learn Pipeline to help us do this for each fold of our dataset. \n",
    "\n",
    "Also, it's weird, but cross_val_score returns MSE values as negative values:\n",
    "<https://github.com/scikit-learn/scikit-learn/issues/2439>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OnIHhAYV3Xt-",
    "outputId": "ad8afa5d-740f-4988-8b34-7bf3966e2c5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold Cross-Val Results - Mean: 24.61 StDev: 12.97 MSE\n"
     ]
    }
   ],
   "source": [
    "# Keras imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "# sklearn imports\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Random Seed\n",
    "seed = 42\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# Load Dataset\n",
    "boston_dataset = load_boston()\n",
    "df = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\n",
    "df['MEDV'] = boston_dataset.target\n",
    "\n",
    "# Split into X and y and turn into numpy arays\n",
    "y = df.MEDV.values\n",
    "X = df.drop(\"MEDV\", axis='columns').values\n",
    "\n",
    "# Important Hyperparameters\n",
    "inputs = X.shape[1]\n",
    "epochs = 50\n",
    "batch_size = 10\n",
    "\n",
    "# define base model\n",
    "def baseline_model():\n",
    "  # create model\n",
    "  model = Sequential()\n",
    "\n",
    "  model.add(Dense(64, input_dim=inputs, activation='relu'))\n",
    "  model.add(Dense(64, activation='relu')) \n",
    "  model.add(Dense(1))\n",
    "  # Compile model\n",
    "  model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "  return model\n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=epochs, batch_size=batch_size,\n",
    "    verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=5, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
    "print(f\"K-fold Cross-Val Results - Mean: {-results.mean():.2f} StDev: {results.std():.2f} MSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N95xwMJw-5Di"
   },
   "source": [
    "## Manual K-fold Cross Validation (classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "722BauYV_4Y4",
    "outputId": "bb1b35fa-4e14-4a4d-cd90-a02a03158ef6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-07-18 13:58:47--  https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 199.232.32.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|199.232.32.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 23278 (23K) [text/plain]\n",
      "Saving to: ‘pima-indians-diabetes.data.csv’\n",
      "\n",
      "pima-indians-diabet 100%[===================>]  22.73K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2019-07-18 13:58:47 (1.04 MB/s) - ‘pima-indians-diabetes.data.csv’ saved [23278/23278]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import files\n",
    "# files.upload()\n",
    "\n",
    "!wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "4YNTT4Tm6E0W",
    "outputId": "0c4bcbb5-a831-42f4-ddf1-1d0ee47769b8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0718 14:00:49.212339 140307783022400 deprecation.py:323] From /home/seek/anaconda3/envs/U4-S2-NNF/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 64.94%\n",
      "acc: 73.38%\n",
      "acc: 72.08%\n",
      "acc: 69.28%\n",
      "acc: 70.59%\n",
      "70.05% +/- 2.91%\n"
     ]
    }
   ],
   "source": [
    "# MLP for Pima Indians Dataset with 10-fold cross validation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 42\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"./pima-indians-diabetes.data.csv\", delimiter=\",\")\n",
    "\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "# define 5-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(X, Y):\n",
    "  # create model\n",
    "  model = Sequential()\n",
    "  model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "  model.add(Dense(8, activation='relu'))\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "  # Compile model\n",
    "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) # Fit the model\n",
    "  model.fit(X[train], Y[train], epochs=150, batch_size=10, verbose=0)\n",
    "  # evaluate the model\n",
    "  scores = model.evaluate(X[test], Y[test], verbose=0)\n",
    "  print(f'{model.metrics_names[1]}: {(scores[1]*100):.2f}%') \n",
    "  cvscores.append(scores[1]*100)\n",
    "print(f'{numpy.mean(cvscores):.2f}% +/- {numpy.std(cvscores):.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JILi3KJjAkfF"
   },
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Hyperparameter tuning is much more important with neural networks than it has been with any other models that we have considered up to this point. Other supervised learning models might have a couple of parameters, but neural networks can have dozens. These can substantially affect the accuracy of our models and although it can be a time consuming process is a necessary step when working with neural networks.\n",
    "\n",
    "Hyperparameter tuning comes with a challenge. How can we compare models specified with different hyperparameters if our model's final error metric can vary somewhat erratically? How do we avoid just getting unlucky and selecting the wrong hyperparameter? This is a problem that to a certain degree we just have to live with as we test and test again. However, we can minimize it somewhat by pairing our experiments with Cross Validation to reduce the variance of our final accuracy values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sYJ8t_ezHP4W"
   },
   "source": [
    "## Hyperparameter Tuning Approaches:\n",
    "\n",
    "### 1) Babysitting AKA \"Grad Student Descent\".\n",
    "\n",
    "If you fiddled with any hyperparameters yesterday, this is basically what you did. This approach is 100% manual and is pretty common among researchers where finding that 1 exact specification that jumps your model to a level of accuracy never seen before is the difference between publishing and not publishing a paper. Of course the professors don't do this themselves, that's grunt work. This is also known as the fiddle with hyperparameters until you run out of time method.\n",
    "\n",
    "### 2) Grid Search\n",
    "\n",
    "Grid Search is the Grad Student galaxy brain realization of: why don't I just specify all the experiments I want to run and let the computer try every possible combination of them while I go and grab lunch. This has a specific downside in that if I specify 5 hyperparameters with 5 options each then I've just created 5^5 combinations of hyperparameters to check. Which means that I have to train 3125 different versions of my model Then if I use 5-fold Cross Validation on that then my model has to run 15,525 times. This is the brute-force method of hyperparameter tuning, but it can be very profitable if done wisely. \n",
    "\n",
    "When using Grid Search here's what I suggest: don't use it to test combinations of different hyperparameters, only use it to test different specifications of **a single** hyperparameter. It's rare that combinations between different hyperparameters lead to big performance gains. You'll get 90-95% of the way there if you just Grid Search one parameter and take the best result, then retain that best result while you test another, and then retain the best specification from that while you train another. This at least makes the situation much more manageable and leads to pretty good results. \n",
    "\n",
    "### 3) Random Search\n",
    "\n",
    "Do Grid Search for a couple of hours and you'll say to yourself - \"There's got to be a better way.\" Enter Random Search. For Random search you specify a hyperparameter space and it picks specifications from that randomly, tries them out, gives you the best results and says - That's going to have to be good enough, go home and spend time with your family. \n",
    "\n",
    "Grid Search treats every parameter as if it was equally important, but this just isn't the case, some are known to move the needle a lot more than others (we'll talk about that in a minute). Random Search allows searching to be specified along the most important parameter and experiments less along the dimensions of less important hyperparameters. The downside of Random search is that it won't find the absolute best hyperparameters, but it is much less costly to perform than Grid Search. \n",
    "\n",
    "### 4) Bayesian Methods\n",
    "\n",
    "One thing that can make more manual methods like babysitting and gridsearch effective is that as the experimenter sees results he can then make updates to his future searches taking into account the results of past specifications. If only we could hyperparameter tune our hyperparameter tuning. Well, we kind of can. Enter Bayesian Optimization. Neural Networks are like an optimization problem within an optimization problem, and Bayesian Optimization is a search strategy that tries to take into account the results of past searches in order to improve future ones. This is the most advanced method but can be a little bit tricky to implement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HfQ7D043OMMn"
   },
   "source": [
    "## What Hyperparameters are there to test?\n",
    "\n",
    "- batch_size\n",
    "- training epochs\n",
    "- optimization algorithms\n",
    "- learning rate\n",
    "- momentum\n",
    "- activation functions\n",
    "- dropout regularization\n",
    "- number of neurons in the hidden layer\n",
    "\n",
    "There are more, but these are the most important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Xl9c2VPPITI"
   },
   "source": [
    "## Creating a \"Test Harness\"\n",
    "\n",
    "You want it to be easy to specify different version of your model and for that model to undergo the same conditions every time with nothing different except for the hyperparameter(s) that you are testing. \n",
    "\n",
    "In order to do this we're going to use GridSearchCV from scikit learn to run our model with different hyperparameters and then report back to us the best one. In order to do this we have to wrap our model in either a KerasRegressor or KerasClassifier object to prepare it to work with Scikit-Learn. We also have to put our model specification within a function that we can call in order to generate it. This is required in order to use KerasRegressor or KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "NJTj0ZAPRfh7",
    "outputId": "86aad133-f31c-42ef-df9d-0d3673f03268"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mri5-kXzVKAa"
   },
   "source": [
    "## Batch Size\n",
    "\n",
    "Batch size determines how many observations the model is shown before it calculates loss/error and updates the model weights via gradient descent. You're looking for a sweet spot here where you're showing it enough observations that you have enough information to updates the weights, but not such a large batch size that you don't get a lot of weight update iterations performed in a given epoch. Feed-forward Neural Networks aren't as sensitive to bach_size as other networks, but it is still an important hyperparameter to tune. Smaller batch sizes will also take longer to train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 13561
    },
    "colab_type": "code",
    "id": "2smXfriNAGn7",
    "outputId": "ae996575-78e2-43fb-9dbe-5d44aaf0b430",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seek/anaconda3/envs/U4-S2-NNF/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 5.1149 - acc: 0.6289\n",
      "Epoch 2/20\n",
      "512/512 [==============================] - 0s 181us/step - loss: 5.0136 - acc: 0.6328\n",
      "Epoch 3/20\n",
      "512/512 [==============================] - 0s 175us/step - loss: 4.7815 - acc: 0.6348\n",
      "Epoch 4/20\n",
      "512/512 [==============================] - 0s 175us/step - loss: 4.7050 - acc: 0.6387\n",
      "Epoch 5/20\n",
      "512/512 [==============================] - 0s 173us/step - loss: 4.5592 - acc: 0.6426\n",
      "Epoch 6/20\n",
      "512/512 [==============================] - 0s 175us/step - loss: 3.7561 - acc: 0.6035\n",
      "Epoch 7/20\n",
      "512/512 [==============================] - 0s 179us/step - loss: 2.7282 - acc: 0.5957\n",
      "Epoch 8/20\n",
      "512/512 [==============================] - 0s 174us/step - loss: 2.0642 - acc: 0.6113\n",
      "Epoch 9/20\n",
      "512/512 [==============================] - 0s 171us/step - loss: 1.5019 - acc: 0.6367\n",
      "Epoch 10/20\n",
      "512/512 [==============================] - 0s 184us/step - loss: 1.2290 - acc: 0.6172\n",
      "Epoch 11/20\n",
      "512/512 [==============================] - 0s 173us/step - loss: 1.1056 - acc: 0.6055\n",
      "Epoch 12/20\n",
      "512/512 [==============================] - 0s 174us/step - loss: 1.0257 - acc: 0.6250\n",
      "Epoch 13/20\n",
      "512/512 [==============================] - 0s 171us/step - loss: 0.9798 - acc: 0.6191\n",
      "Epoch 14/20\n",
      "512/512 [==============================] - 0s 173us/step - loss: 0.9254 - acc: 0.6309\n",
      "Epoch 15/20\n",
      "512/512 [==============================] - 0s 179us/step - loss: 0.8365 - acc: 0.6602\n",
      "Epoch 16/20\n",
      "512/512 [==============================] - 0s 174us/step - loss: 0.7807 - acc: 0.6621\n",
      "Epoch 17/20\n",
      "512/512 [==============================] - 0s 179us/step - loss: 0.7706 - acc: 0.6543\n",
      "Epoch 18/20\n",
      "512/512 [==============================] - 0s 181us/step - loss: 0.7453 - acc: 0.6680\n",
      "Epoch 19/20\n",
      "512/512 [==============================] - 0s 178us/step - loss: 0.7182 - acc: 0.6582\n",
      "Epoch 20/20\n",
      "512/512 [==============================] - 0s 175us/step - loss: 0.6490 - acc: 0.6875\n",
      "256/256 [==============================] - 0s 665us/step\n",
      "Epoch 1/20\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 10.3065 - acc: 0.3535\n",
      "Epoch 2/20\n",
      "512/512 [==============================] - 0s 191us/step - loss: 10.3065 - acc: 0.3535\n",
      "Epoch 3/20\n",
      "512/512 [==============================] - 0s 179us/step - loss: 10.3065 - acc: 0.3535\n",
      "Epoch 4/20\n",
      "512/512 [==============================] - 0s 180us/step - loss: 10.3065 - acc: 0.3535\n",
      "Epoch 5/20\n",
      "512/512 [==============================] - 0s 179us/step - loss: 10.3065 - acc: 0.3535\n",
      "Epoch 6/20\n",
      "512/512 [==============================] - 0s 176us/step - loss: 10.3065 - acc: 0.3535\n",
      "Epoch 7/20\n",
      "512/512 [==============================] - 0s 184us/step - loss: 10.3065 - acc: 0.3535\n",
      "Epoch 8/20\n",
      "512/512 [==============================] - 0s 181us/step - loss: 10.3065 - acc: 0.3535\n",
      "Epoch 9/20\n",
      "512/512 [==============================] - 0s 185us/step - loss: 10.3065 - acc: 0.3535\n",
      "Epoch 10/20\n",
      "512/512 [==============================] - 0s 183us/step - loss: 10.3065 - acc: 0.3535\n",
      "Epoch 11/20\n",
      "512/512 [==============================] - 0s 210us/step - loss: 10.3065 - acc: 0.3535\n",
      "Epoch 12/20\n",
      "512/512 [==============================] - 0s 214us/step - loss: 10.3065 - acc: 0.3535\n",
      "Epoch 13/20\n",
      "512/512 [==============================] - 0s 214us/step - loss: 10.3065 - acc: 0.3535\n",
      "Epoch 14/20\n",
      "512/512 [==============================] - 0s 214us/step - loss: 10.3065 - acc: 0.3535\n",
      "Epoch 15/20\n",
      "512/512 [==============================] - 0s 201us/step - loss: 10.3065 - acc: 0.3535\n",
      "Epoch 16/20\n",
      "512/512 [==============================] - 0s 181us/step - loss: 10.3065 - acc: 0.3535\n",
      "Epoch 17/20\n",
      "512/512 [==============================] - 0s 183us/step - loss: 10.3065 - acc: 0.3535\n",
      "Epoch 18/20\n",
      "512/512 [==============================] - 0s 179us/step - loss: 10.3065 - acc: 0.3535\n",
      "Epoch 19/20\n",
      "512/512 [==============================] - 0s 181us/step - loss: 10.3065 - acc: 0.3535\n",
      "Epoch 20/20\n",
      "512/512 [==============================] - 0s 183us/step - loss: 10.3065 - acc: 0.3535\n",
      "256/256 [==============================] - 0s 743us/step\n",
      "Epoch 1/20\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 8.6822 - acc: 0.4102\n",
      "Epoch 2/20\n",
      "512/512 [==============================] - 0s 181us/step - loss: 7.8038 - acc: 0.4805\n",
      "Epoch 3/20\n",
      "512/512 [==============================] - 0s 182us/step - loss: 7.3940 - acc: 0.5117\n",
      "Epoch 4/20\n",
      "512/512 [==============================] - 0s 190us/step - loss: 6.1861 - acc: 0.5352\n",
      "Epoch 5/20\n",
      "512/512 [==============================] - 0s 185us/step - loss: 4.3804 - acc: 0.5801\n",
      "Epoch 6/20\n",
      "512/512 [==============================] - 0s 188us/step - loss: 3.7433 - acc: 0.6094\n",
      "Epoch 7/20\n",
      "512/512 [==============================] - 0s 180us/step - loss: 3.4569 - acc: 0.6172\n",
      "Epoch 8/20\n",
      "512/512 [==============================] - 0s 176us/step - loss: 3.3990 - acc: 0.6250\n",
      "Epoch 9/20\n",
      "512/512 [==============================] - 0s 184us/step - loss: 3.3591 - acc: 0.6406\n",
      "Epoch 10/20\n",
      "512/512 [==============================] - 0s 176us/step - loss: 3.2929 - acc: 0.6523\n",
      "Epoch 11/20\n",
      "512/512 [==============================] - 0s 178us/step - loss: 3.2767 - acc: 0.6543\n",
      "Epoch 12/20\n",
      "512/512 [==============================] - 0s 183us/step - loss: 3.2312 - acc: 0.6504\n",
      "Epoch 13/20\n",
      "512/512 [==============================] - 0s 183us/step - loss: 3.2085 - acc: 0.6582\n",
      "Epoch 14/20\n",
      "512/512 [==============================] - 0s 188us/step - loss: 3.1961 - acc: 0.6699\n",
      "Epoch 15/20\n",
      "512/512 [==============================] - 0s 186us/step - loss: 3.1785 - acc: 0.6680\n",
      "Epoch 16/20\n",
      "512/512 [==============================] - 0s 208us/step - loss: 3.1603 - acc: 0.6797\n",
      "Epoch 17/20\n",
      "512/512 [==============================] - 0s 212us/step - loss: 3.1734 - acc: 0.6641\n",
      "Epoch 18/20\n",
      "512/512 [==============================] - 0s 200us/step - loss: 3.1533 - acc: 0.6738\n",
      "Epoch 19/20\n",
      "512/512 [==============================] - 0s 227us/step - loss: 3.1522 - acc: 0.6855\n",
      "Epoch 20/20\n",
      "512/512 [==============================] - 0s 204us/step - loss: 3.1534 - acc: 0.6719\n",
      "256/256 [==============================] - 0s 838us/step\n",
      "Epoch 1/20\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 3.3849 - acc: 0.5801\n",
      "Epoch 2/20\n",
      "512/512 [==============================] - 0s 100us/step - loss: 2.7250 - acc: 0.5098\n",
      "Epoch 3/20\n",
      "512/512 [==============================] - 0s 90us/step - loss: 2.4958 - acc: 0.5215\n",
      "Epoch 4/20\n",
      "512/512 [==============================] - 0s 95us/step - loss: 2.3875 - acc: 0.5430\n",
      "Epoch 5/20\n",
      "512/512 [==============================] - 0s 95us/step - loss: 2.2146 - acc: 0.5410\n",
      "Epoch 6/20\n",
      "512/512 [==============================] - 0s 90us/step - loss: 2.0896 - acc: 0.5371\n",
      "Epoch 7/20\n",
      "512/512 [==============================] - 0s 96us/step - loss: 1.9686 - acc: 0.5508\n",
      "Epoch 8/20\n",
      "512/512 [==============================] - 0s 98us/step - loss: 1.9091 - acc: 0.5625\n",
      "Epoch 9/20\n",
      "512/512 [==============================] - 0s 98us/step - loss: 1.7848 - acc: 0.5605\n",
      "Epoch 10/20\n",
      "512/512 [==============================] - 0s 91us/step - loss: 1.7070 - acc: 0.5469\n",
      "Epoch 11/20\n",
      "512/512 [==============================] - 0s 91us/step - loss: 1.6823 - acc: 0.5781\n",
      "Epoch 12/20\n",
      "512/512 [==============================] - 0s 94us/step - loss: 1.5699 - acc: 0.5488\n",
      "Epoch 13/20\n",
      "512/512 [==============================] - 0s 88us/step - loss: 1.5222 - acc: 0.5820\n",
      "Epoch 14/20\n",
      "512/512 [==============================] - 0s 96us/step - loss: 1.4421 - acc: 0.5762\n",
      "Epoch 15/20\n",
      "512/512 [==============================] - 0s 98us/step - loss: 1.4128 - acc: 0.5859\n",
      "Epoch 16/20\n",
      "512/512 [==============================] - 0s 100us/step - loss: 1.3321 - acc: 0.5879\n",
      "Epoch 17/20\n",
      "512/512 [==============================] - 0s 91us/step - loss: 1.2972 - acc: 0.5742\n",
      "Epoch 18/20\n",
      "512/512 [==============================] - 0s 96us/step - loss: 1.2163 - acc: 0.5898\n",
      "Epoch 19/20\n",
      "512/512 [==============================] - 0s 111us/step - loss: 1.2175 - acc: 0.5957\n",
      "Epoch 20/20\n",
      "512/512 [==============================] - 0s 103us/step - loss: 1.1375 - acc: 0.6152\n",
      "256/256 [==============================] - 0s 797us/step\n",
      "Epoch 1/20\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 5.7182 - acc: 0.5000\n",
      "Epoch 2/20\n",
      "512/512 [==============================] - 0s 94us/step - loss: 3.7817 - acc: 0.6055\n",
      "Epoch 3/20\n",
      "512/512 [==============================] - 0s 92us/step - loss: 3.6293 - acc: 0.6074\n",
      "Epoch 4/20\n",
      "512/512 [==============================] - 0s 98us/step - loss: 3.5603 - acc: 0.6172\n",
      "Epoch 5/20\n",
      "512/512 [==============================] - 0s 91us/step - loss: 3.4727 - acc: 0.6172\n",
      "Epoch 6/20\n",
      "512/512 [==============================] - 0s 91us/step - loss: 3.3911 - acc: 0.6270\n",
      "Epoch 7/20\n",
      "512/512 [==============================] - 0s 96us/step - loss: 3.3381 - acc: 0.6348\n",
      "Epoch 8/20\n",
      "512/512 [==============================] - 0s 100us/step - loss: 3.2797 - acc: 0.6406\n",
      "Epoch 9/20\n",
      "512/512 [==============================] - 0s 94us/step - loss: 3.2466 - acc: 0.6563\n",
      "Epoch 10/20\n",
      "512/512 [==============================] - 0s 93us/step - loss: 3.2167 - acc: 0.6484\n",
      "Epoch 11/20\n",
      "512/512 [==============================] - 0s 95us/step - loss: 3.1910 - acc: 0.6602\n",
      "Epoch 12/20\n",
      "512/512 [==============================] - 0s 101us/step - loss: 3.1643 - acc: 0.6484\n",
      "Epoch 13/20\n",
      "512/512 [==============================] - 0s 103us/step - loss: 3.1595 - acc: 0.6504\n",
      "Epoch 14/20\n",
      "512/512 [==============================] - 0s 102us/step - loss: 3.1387 - acc: 0.6719\n",
      "Epoch 15/20\n",
      "512/512 [==============================] - 0s 109us/step - loss: 3.1305 - acc: 0.6602\n",
      "Epoch 16/20\n",
      "512/512 [==============================] - 0s 102us/step - loss: 3.1206 - acc: 0.6719\n",
      "Epoch 17/20\n",
      "512/512 [==============================] - 0s 94us/step - loss: 3.1107 - acc: 0.6777\n",
      "Epoch 18/20\n",
      "512/512 [==============================] - 0s 105us/step - loss: 3.1184 - acc: 0.6699\n",
      "Epoch 19/20\n",
      "512/512 [==============================] - 0s 108us/step - loss: 3.1070 - acc: 0.6797\n",
      "Epoch 20/20\n",
      "512/512 [==============================] - 0s 109us/step - loss: 3.1223 - acc: 0.6660\n",
      "256/256 [==============================] - 0s 882us/step\n",
      "Epoch 1/20\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 5.3595 - acc: 0.6309\n",
      "Epoch 2/20\n",
      "512/512 [==============================] - 0s 105us/step - loss: 4.7563 - acc: 0.6387\n",
      "Epoch 3/20\n",
      "512/512 [==============================] - 0s 101us/step - loss: 3.7400 - acc: 0.6484\n",
      "Epoch 4/20\n",
      "512/512 [==============================] - 0s 99us/step - loss: 2.6491 - acc: 0.6348\n",
      "Epoch 5/20\n",
      "512/512 [==============================] - 0s 93us/step - loss: 1.7141 - acc: 0.6270\n",
      "Epoch 6/20\n",
      "512/512 [==============================] - 0s 92us/step - loss: 1.1555 - acc: 0.6309\n",
      "Epoch 7/20\n",
      "512/512 [==============================] - 0s 94us/step - loss: 0.8662 - acc: 0.6191\n",
      "Epoch 8/20\n",
      "512/512 [==============================] - 0s 93us/step - loss: 0.7732 - acc: 0.5254\n",
      "Epoch 9/20\n",
      "512/512 [==============================] - 0s 94us/step - loss: 0.7461 - acc: 0.5059\n",
      "Epoch 10/20\n",
      "512/512 [==============================] - 0s 90us/step - loss: 0.7390 - acc: 0.5137\n",
      "Epoch 11/20\n",
      "512/512 [==============================] - 0s 98us/step - loss: 0.7345 - acc: 0.5039\n",
      "Epoch 12/20\n",
      "512/512 [==============================] - 0s 94us/step - loss: 0.7295 - acc: 0.5488\n",
      "Epoch 13/20\n",
      "512/512 [==============================] - 0s 92us/step - loss: 0.7238 - acc: 0.6133\n",
      "Epoch 14/20\n",
      "512/512 [==============================] - 0s 91us/step - loss: 0.7218 - acc: 0.6348\n",
      "Epoch 15/20\n",
      "512/512 [==============================] - 0s 102us/step - loss: 0.7205 - acc: 0.6523\n",
      "Epoch 16/20\n",
      "512/512 [==============================] - 0s 107us/step - loss: 0.7177 - acc: 0.6602\n",
      "Epoch 17/20\n",
      "512/512 [==============================] - 0s 114us/step - loss: 0.7161 - acc: 0.6465\n",
      "Epoch 18/20\n",
      "512/512 [==============================] - 0s 95us/step - loss: 0.7116 - acc: 0.6641\n",
      "Epoch 19/20\n",
      "512/512 [==============================] - 0s 121us/step - loss: 0.7116 - acc: 0.6406\n",
      "Epoch 20/20\n",
      "512/512 [==============================] - 0s 106us/step - loss: 0.7089 - acc: 0.6660\n",
      "256/256 [==============================] - 0s 888us/step\n",
      "Epoch 1/20\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 5.3517 - acc: 0.6680\n",
      "Epoch 2/20\n",
      "512/512 [==============================] - 0s 45us/step - loss: 5.3517 - acc: 0.6680\n",
      "Epoch 3/20\n",
      "512/512 [==============================] - 0s 56us/step - loss: 5.3517 - acc: 0.6680\n",
      "Epoch 4/20\n",
      "512/512 [==============================] - 0s 55us/step - loss: 5.3517 - acc: 0.6680\n",
      "Epoch 5/20\n",
      "512/512 [==============================] - 0s 56us/step - loss: 5.3517 - acc: 0.6680\n",
      "Epoch 6/20\n",
      "512/512 [==============================] - 0s 51us/step - loss: 5.3517 - acc: 0.6680\n",
      "Epoch 7/20\n",
      "512/512 [==============================] - 0s 55us/step - loss: 5.3517 - acc: 0.6680\n",
      "Epoch 8/20\n",
      "512/512 [==============================] - 0s 54us/step - loss: 5.3517 - acc: 0.6680\n",
      "Epoch 9/20\n",
      "512/512 [==============================] - 0s 51us/step - loss: 5.3517 - acc: 0.6680\n",
      "Epoch 10/20\n",
      "512/512 [==============================] - 0s 55us/step - loss: 5.3517 - acc: 0.6680\n",
      "Epoch 11/20\n",
      "512/512 [==============================] - 0s 58us/step - loss: 5.3517 - acc: 0.6680\n",
      "Epoch 12/20\n",
      "512/512 [==============================] - 0s 60us/step - loss: 5.3517 - acc: 0.6680\n",
      "Epoch 13/20\n",
      "512/512 [==============================] - 0s 56us/step - loss: 5.3517 - acc: 0.6680\n",
      "Epoch 14/20\n",
      "512/512 [==============================] - 0s 55us/step - loss: 5.3517 - acc: 0.6680\n",
      "Epoch 15/20\n",
      "512/512 [==============================] - 0s 56us/step - loss: 5.3517 - acc: 0.6680\n",
      "Epoch 16/20\n",
      "512/512 [==============================] - 0s 58us/step - loss: 5.3517 - acc: 0.6680\n",
      "Epoch 17/20\n",
      "512/512 [==============================] - 0s 57us/step - loss: 5.3517 - acc: 0.6680\n",
      "Epoch 18/20\n",
      "512/512 [==============================] - 0s 55us/step - loss: 5.3517 - acc: 0.6680\n",
      "Epoch 19/20\n",
      "512/512 [==============================] - 0s 57us/step - loss: 5.3517 - acc: 0.6680\n",
      "Epoch 20/20\n",
      "512/512 [==============================] - 0s 59us/step - loss: 5.3517 - acc: 0.6680\n",
      "256/256 [==============================] - 0s 952us/step\n",
      "Epoch 1/20\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 10.3057 - acc: 0.3535\n",
      "Epoch 2/20\n",
      "512/512 [==============================] - 0s 51us/step - loss: 10.2548 - acc: 0.3535\n",
      "Epoch 3/20\n",
      "512/512 [==============================] - 0s 56us/step - loss: 9.8949 - acc: 0.3535\n",
      "Epoch 4/20\n",
      "512/512 [==============================] - 0s 56us/step - loss: 8.6186 - acc: 0.3535\n",
      "Epoch 5/20\n",
      "512/512 [==============================] - 0s 55us/step - loss: 6.8495 - acc: 0.3535\n",
      "Epoch 6/20\n",
      "512/512 [==============================] - 0s 55us/step - loss: 5.1945 - acc: 0.3574\n",
      "Epoch 7/20\n",
      "512/512 [==============================] - 0s 59us/step - loss: 4.1140 - acc: 0.3574\n",
      "Epoch 8/20\n",
      "512/512 [==============================] - 0s 57us/step - loss: 3.3174 - acc: 0.3672\n",
      "Epoch 9/20\n",
      "512/512 [==============================] - 0s 58us/step - loss: 2.6607 - acc: 0.3887\n",
      "Epoch 10/20\n",
      "512/512 [==============================] - 0s 59us/step - loss: 2.1775 - acc: 0.3984\n",
      "Epoch 11/20\n",
      "512/512 [==============================] - 0s 53us/step - loss: 1.7906 - acc: 0.4395\n",
      "Epoch 12/20\n",
      "512/512 [==============================] - 0s 54us/step - loss: 1.5031 - acc: 0.4766\n",
      "Epoch 13/20\n",
      "512/512 [==============================] - 0s 57us/step - loss: 1.2788 - acc: 0.4961\n",
      "Epoch 14/20\n",
      "512/512 [==============================] - 0s 55us/step - loss: 1.1096 - acc: 0.5000\n",
      "Epoch 15/20\n",
      "512/512 [==============================] - 0s 48us/step - loss: 0.9784 - acc: 0.5098\n",
      "Epoch 16/20\n",
      "512/512 [==============================] - 0s 56us/step - loss: 0.8745 - acc: 0.5371\n",
      "Epoch 17/20\n",
      "512/512 [==============================] - 0s 58us/step - loss: 0.8022 - acc: 0.5684\n",
      "Epoch 18/20\n",
      "512/512 [==============================] - 0s 49us/step - loss: 0.7500 - acc: 0.5840\n",
      "Epoch 19/20\n",
      "512/512 [==============================] - 0s 57us/step - loss: 0.7152 - acc: 0.6094\n",
      "Epoch 20/20\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.6958 - acc: 0.6172\n",
      "256/256 [==============================] - 0s 915us/step\n",
      "Epoch 1/20\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 5.7324 - acc: 0.6211\n",
      "Epoch 2/20\n",
      "512/512 [==============================] - 0s 58us/step - loss: 5.5759 - acc: 0.5898\n",
      "Epoch 3/20\n",
      "512/512 [==============================] - 0s 55us/step - loss: 5.4478 - acc: 0.5977\n",
      "Epoch 4/20\n",
      "512/512 [==============================] - 0s 50us/step - loss: 5.3421 - acc: 0.5879\n",
      "Epoch 5/20\n",
      "512/512 [==============================] - 0s 59us/step - loss: 5.3272 - acc: 0.5840\n",
      "Epoch 6/20\n",
      "512/512 [==============================] - 0s 48us/step - loss: 5.2522 - acc: 0.5879\n",
      "Epoch 7/20\n",
      "512/512 [==============================] - 0s 56us/step - loss: 5.1476 - acc: 0.5918\n",
      "Epoch 8/20\n",
      "512/512 [==============================] - 0s 52us/step - loss: 4.9837 - acc: 0.5820\n",
      "Epoch 9/20\n",
      "512/512 [==============================] - 0s 54us/step - loss: 4.5005 - acc: 0.5527\n",
      "Epoch 10/20\n",
      "512/512 [==============================] - 0s 54us/step - loss: 4.0199 - acc: 0.5430\n",
      "Epoch 11/20\n",
      "512/512 [==============================] - 0s 58us/step - loss: 3.7948 - acc: 0.5527\n",
      "Epoch 12/20\n",
      "512/512 [==============================] - 0s 58us/step - loss: 3.6111 - acc: 0.5566\n",
      "Epoch 13/20\n",
      "512/512 [==============================] - 0s 56us/step - loss: 3.3576 - acc: 0.5566\n",
      "Epoch 14/20\n",
      "512/512 [==============================] - 0s 54us/step - loss: 3.1552 - acc: 0.5566\n",
      "Epoch 15/20\n",
      "512/512 [==============================] - 0s 53us/step - loss: 2.9065 - acc: 0.5391\n",
      "Epoch 16/20\n",
      "512/512 [==============================] - 0s 57us/step - loss: 2.6184 - acc: 0.5410\n",
      "Epoch 17/20\n",
      "512/512 [==============================] - 0s 59us/step - loss: 2.4163 - acc: 0.5391\n",
      "Epoch 18/20\n",
      "512/512 [==============================] - 0s 58us/step - loss: 2.2277 - acc: 0.5488\n",
      "Epoch 19/20\n",
      "512/512 [==============================] - 0s 59us/step - loss: 1.8741 - acc: 0.5605\n",
      "Epoch 20/20\n",
      "512/512 [==============================] - 0s 51us/step - loss: 1.7141 - acc: 0.5391\n",
      "256/256 [==============================] - 0s 959us/step\n",
      "Epoch 1/20\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 5.2794 - acc: 0.6680\n",
      "Epoch 2/20\n",
      "512/512 [==============================] - 0s 41us/step - loss: 5.1750 - acc: 0.6660\n",
      "Epoch 3/20\n",
      "512/512 [==============================] - 0s 40us/step - loss: 5.0231 - acc: 0.6602\n",
      "Epoch 4/20\n",
      "512/512 [==============================] - 0s 36us/step - loss: 4.6024 - acc: 0.6699\n",
      "Epoch 5/20\n",
      "512/512 [==============================] - 0s 40us/step - loss: 3.3630 - acc: 0.6855\n",
      "Epoch 6/20\n",
      "512/512 [==============================] - 0s 42us/step - loss: 2.2603 - acc: 0.6289\n",
      "Epoch 7/20\n",
      "512/512 [==============================] - 0s 40us/step - loss: 1.8473 - acc: 0.6016\n",
      "Epoch 8/20\n",
      "512/512 [==============================] - 0s 39us/step - loss: 1.5749 - acc: 0.6543\n",
      "Epoch 9/20\n",
      "512/512 [==============================] - 0s 41us/step - loss: 1.4792 - acc: 0.6250\n",
      "Epoch 10/20\n",
      "512/512 [==============================] - 0s 32us/step - loss: 1.3998 - acc: 0.6387\n",
      "Epoch 11/20\n",
      "512/512 [==============================] - 0s 40us/step - loss: 1.3381 - acc: 0.6113\n",
      "Epoch 12/20\n",
      "512/512 [==============================] - 0s 41us/step - loss: 1.2599 - acc: 0.6230\n",
      "Epoch 13/20\n",
      "512/512 [==============================] - 0s 41us/step - loss: 1.2030 - acc: 0.6211\n",
      "Epoch 14/20\n",
      "512/512 [==============================] - 0s 39us/step - loss: 1.1705 - acc: 0.6230\n",
      "Epoch 15/20\n",
      "512/512 [==============================] - 0s 39us/step - loss: 1.1344 - acc: 0.6289\n",
      "Epoch 16/20\n",
      "512/512 [==============================] - 0s 39us/step - loss: 1.1089 - acc: 0.6523\n",
      "Epoch 17/20\n",
      "512/512 [==============================] - 0s 41us/step - loss: 1.0880 - acc: 0.6328\n",
      "Epoch 18/20\n",
      "512/512 [==============================] - 0s 42us/step - loss: 1.0596 - acc: 0.6367\n",
      "Epoch 19/20\n",
      "512/512 [==============================] - 0s 41us/step - loss: 1.0438 - acc: 0.6406\n",
      "Epoch 20/20\n",
      "512/512 [==============================] - 0s 40us/step - loss: 1.0231 - acc: 0.6602\n",
      "256/256 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 5.8728 - acc: 0.4844\n",
      "Epoch 2/20\n",
      "512/512 [==============================] - 0s 36us/step - loss: 4.8379 - acc: 0.5176\n",
      "Epoch 3/20\n",
      "512/512 [==============================] - 0s 38us/step - loss: 4.1089 - acc: 0.5430\n",
      "Epoch 4/20\n",
      "512/512 [==============================] - 0s 40us/step - loss: 3.7473 - acc: 0.5742\n",
      "Epoch 5/20\n",
      "512/512 [==============================] - 0s 40us/step - loss: 3.5553 - acc: 0.5781\n",
      "Epoch 6/20\n",
      "512/512 [==============================] - 0s 38us/step - loss: 3.2839 - acc: 0.5801\n",
      "Epoch 7/20\n",
      "512/512 [==============================] - 0s 40us/step - loss: 2.7145 - acc: 0.5566\n",
      "Epoch 8/20\n",
      "512/512 [==============================] - 0s 39us/step - loss: 2.6514 - acc: 0.4687\n",
      "Epoch 9/20\n",
      "512/512 [==============================] - 0s 37us/step - loss: 2.3517 - acc: 0.4785\n",
      "Epoch 10/20\n",
      "512/512 [==============================] - 0s 38us/step - loss: 2.2219 - acc: 0.5547\n",
      "Epoch 11/20\n",
      "512/512 [==============================] - 0s 38us/step - loss: 2.1090 - acc: 0.5645\n",
      "Epoch 12/20\n",
      "512/512 [==============================] - 0s 38us/step - loss: 2.0078 - acc: 0.5430\n",
      "Epoch 13/20\n",
      "512/512 [==============================] - 0s 40us/step - loss: 1.9463 - acc: 0.5430\n",
      "Epoch 14/20\n",
      "512/512 [==============================] - 0s 37us/step - loss: 1.8483 - acc: 0.5410\n",
      "Epoch 15/20\n",
      "512/512 [==============================] - 0s 36us/step - loss: 1.7899 - acc: 0.5273\n",
      "Epoch 16/20\n",
      "512/512 [==============================] - 0s 39us/step - loss: 1.7202 - acc: 0.5430\n",
      "Epoch 17/20\n",
      "512/512 [==============================] - 0s 34us/step - loss: 1.6725 - acc: 0.5391\n",
      "Epoch 18/20\n",
      "512/512 [==============================] - 0s 36us/step - loss: 1.6182 - acc: 0.5332\n",
      "Epoch 19/20\n",
      "512/512 [==============================] - 0s 42us/step - loss: 1.5653 - acc: 0.5488\n",
      "Epoch 20/20\n",
      "512/512 [==============================] - 0s 42us/step - loss: 1.5230 - acc: 0.5566\n",
      "256/256 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "512/512 [==============================] - 1s 2ms/step - loss: 10.1820 - acc: 0.3613\n",
      "Epoch 2/20\n",
      "512/512 [==============================] - 0s 37us/step - loss: 10.1820 - acc: 0.3613\n",
      "Epoch 3/20\n",
      "512/512 [==============================] - 0s 32us/step - loss: 10.1820 - acc: 0.3613\n",
      "Epoch 4/20\n",
      "512/512 [==============================] - 0s 40us/step - loss: 10.1820 - acc: 0.3613\n",
      "Epoch 5/20\n",
      "512/512 [==============================] - 0s 34us/step - loss: 10.1820 - acc: 0.3613\n",
      "Epoch 6/20\n",
      "512/512 [==============================] - 0s 44us/step - loss: 10.1820 - acc: 0.3613\n",
      "Epoch 7/20\n",
      "512/512 [==============================] - 0s 37us/step - loss: 10.1820 - acc: 0.3613\n",
      "Epoch 8/20\n",
      "512/512 [==============================] - 0s 40us/step - loss: 10.1820 - acc: 0.3613\n",
      "Epoch 9/20\n",
      "512/512 [==============================] - 0s 40us/step - loss: 10.1820 - acc: 0.3613\n",
      "Epoch 10/20\n",
      "512/512 [==============================] - 0s 36us/step - loss: 10.1820 - acc: 0.3613\n",
      "Epoch 11/20\n",
      "512/512 [==============================] - 0s 38us/step - loss: 10.1820 - acc: 0.3613\n",
      "Epoch 12/20\n",
      "512/512 [==============================] - 0s 37us/step - loss: 10.1820 - acc: 0.3613\n",
      "Epoch 13/20\n",
      "512/512 [==============================] - 0s 42us/step - loss: 10.1820 - acc: 0.3613\n",
      "Epoch 14/20\n",
      "512/512 [==============================] - 0s 39us/step - loss: 10.1820 - acc: 0.3613\n",
      "Epoch 15/20\n",
      "512/512 [==============================] - 0s 39us/step - loss: 10.1820 - acc: 0.3613\n",
      "Epoch 16/20\n",
      "512/512 [==============================] - 0s 34us/step - loss: 10.1820 - acc: 0.3613\n",
      "Epoch 17/20\n",
      "512/512 [==============================] - 0s 40us/step - loss: 10.1820 - acc: 0.3613\n",
      "Epoch 18/20\n",
      "512/512 [==============================] - 0s 36us/step - loss: 10.1820 - acc: 0.3613\n",
      "Epoch 19/20\n",
      "512/512 [==============================] - 0s 40us/step - loss: 10.1820 - acc: 0.3613\n",
      "Epoch 20/20\n",
      "512/512 [==============================] - 0s 43us/step - loss: 10.1820 - acc: 0.3613\n",
      "256/256 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "512/512 [==============================] - 1s 2ms/step - loss: 10.5352 - acc: 0.3340\n",
      "Epoch 2/20\n",
      "512/512 [==============================] - 0s 28us/step - loss: 10.4984 - acc: 0.3340\n",
      "Epoch 3/20\n",
      "512/512 [==============================] - 0s 33us/step - loss: 10.4566 - acc: 0.3320\n",
      "Epoch 4/20\n",
      "512/512 [==============================] - 0s 35us/step - loss: 10.3967 - acc: 0.3301\n",
      "Epoch 5/20\n",
      "512/512 [==============================] - 0s 34us/step - loss: 10.0825 - acc: 0.3242\n",
      "Epoch 6/20\n",
      "512/512 [==============================] - 0s 27us/step - loss: 9.1138 - acc: 0.3203\n",
      "Epoch 7/20\n",
      "512/512 [==============================] - 0s 32us/step - loss: 7.9979 - acc: 0.3633\n",
      "Epoch 8/20\n",
      "512/512 [==============================] - 0s 29us/step - loss: 7.8680 - acc: 0.4062\n",
      "Epoch 9/20\n",
      "512/512 [==============================] - 0s 29us/step - loss: 7.8014 - acc: 0.4199\n",
      "Epoch 10/20\n",
      "512/512 [==============================] - 0s 31us/step - loss: 7.6752 - acc: 0.4375\n",
      "Epoch 11/20\n",
      "512/512 [==============================] - 0s 31us/step - loss: 7.2976 - acc: 0.4570\n",
      "Epoch 12/20\n",
      "512/512 [==============================] - 0s 32us/step - loss: 6.4311 - acc: 0.4746\n",
      "Epoch 13/20\n",
      "512/512 [==============================] - 0s 34us/step - loss: 5.1683 - acc: 0.5547\n",
      "Epoch 14/20\n",
      "512/512 [==============================] - 0s 30us/step - loss: 4.9180 - acc: 0.6426\n",
      "Epoch 15/20\n",
      "512/512 [==============================] - 0s 33us/step - loss: 4.9634 - acc: 0.6602\n",
      "Epoch 16/20\n",
      "512/512 [==============================] - 0s 27us/step - loss: 5.0001 - acc: 0.6582\n",
      "Epoch 17/20\n",
      "512/512 [==============================] - 0s 33us/step - loss: 4.9849 - acc: 0.6562\n",
      "Epoch 18/20\n",
      "512/512 [==============================] - 0s 27us/step - loss: 4.9335 - acc: 0.6563\n",
      "Epoch 19/20\n",
      "512/512 [==============================] - 0s 30us/step - loss: 4.8563 - acc: 0.6562\n",
      "Epoch 20/20\n",
      "512/512 [==============================] - 0s 32us/step - loss: 4.8375 - acc: 0.6270\n",
      "256/256 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "512/512 [==============================] - 1s 2ms/step - loss: 5.6980 - acc: 0.6465\n",
      "Epoch 2/20\n",
      "512/512 [==============================] - 0s 32us/step - loss: 5.6980 - acc: 0.6465\n",
      "Epoch 3/20\n",
      "512/512 [==============================] - 0s 31us/step - loss: 5.6980 - acc: 0.6465\n",
      "Epoch 4/20\n",
      "512/512 [==============================] - 0s 32us/step - loss: 5.6980 - acc: 0.6465\n",
      "Epoch 5/20\n",
      "512/512 [==============================] - 0s 27us/step - loss: 5.6980 - acc: 0.6465\n",
      "Epoch 6/20\n",
      "512/512 [==============================] - 0s 32us/step - loss: 5.6980 - acc: 0.6465\n",
      "Epoch 7/20\n",
      "512/512 [==============================] - 0s 24us/step - loss: 5.6980 - acc: 0.6465\n",
      "Epoch 8/20\n",
      "512/512 [==============================] - 0s 33us/step - loss: 5.6980 - acc: 0.6465\n",
      "Epoch 9/20\n",
      "512/512 [==============================] - 0s 28us/step - loss: 5.6980 - acc: 0.6465\n",
      "Epoch 10/20\n",
      "512/512 [==============================] - 0s 33us/step - loss: 5.6980 - acc: 0.6465\n",
      "Epoch 11/20\n",
      "512/512 [==============================] - 0s 32us/step - loss: 5.6980 - acc: 0.6465\n",
      "Epoch 12/20\n",
      "512/512 [==============================] - 0s 26us/step - loss: 5.6980 - acc: 0.6465\n",
      "Epoch 13/20\n",
      "512/512 [==============================] - 0s 33us/step - loss: 5.6980 - acc: 0.6465\n",
      "Epoch 14/20\n",
      "512/512 [==============================] - 0s 25us/step - loss: 5.6980 - acc: 0.6465\n",
      "Epoch 15/20\n",
      "512/512 [==============================] - 0s 32us/step - loss: 5.6980 - acc: 0.6465\n",
      "Epoch 16/20\n",
      "512/512 [==============================] - 0s 30us/step - loss: 5.6980 - acc: 0.6465\n",
      "Epoch 17/20\n",
      "512/512 [==============================] - 0s 30us/step - loss: 5.6980 - acc: 0.6465\n",
      "Epoch 18/20\n",
      "512/512 [==============================] - 0s 27us/step - loss: 5.6980 - acc: 0.6465\n",
      "Epoch 19/20\n",
      "512/512 [==============================] - 0s 33us/step - loss: 5.6980 - acc: 0.6465\n",
      "Epoch 20/20\n",
      "512/512 [==============================] - 0s 30us/step - loss: 5.6980 - acc: 0.6465\n",
      "256/256 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "512/512 [==============================] - 1s 2ms/step - loss: 5.8239 - acc: 0.6387\n",
      "Epoch 2/20\n",
      "512/512 [==============================] - 0s 27us/step - loss: 5.8239 - acc: 0.6387\n",
      "Epoch 3/20\n",
      "512/512 [==============================] - 0s 25us/step - loss: 5.8239 - acc: 0.6387\n",
      "Epoch 4/20\n",
      "512/512 [==============================] - 0s 33us/step - loss: 5.8239 - acc: 0.6387\n",
      "Epoch 5/20\n",
      "512/512 [==============================] - 0s 33us/step - loss: 5.8239 - acc: 0.6387\n",
      "Epoch 6/20\n",
      "512/512 [==============================] - 0s 25us/step - loss: 5.8239 - acc: 0.6387\n",
      "Epoch 7/20\n",
      "512/512 [==============================] - 0s 32us/step - loss: 5.8239 - acc: 0.6387\n",
      "Epoch 8/20\n",
      "512/512 [==============================] - 0s 27us/step - loss: 5.8239 - acc: 0.6387\n",
      "Epoch 9/20\n",
      "512/512 [==============================] - 0s 33us/step - loss: 5.8239 - acc: 0.6387\n",
      "Epoch 10/20\n",
      "512/512 [==============================] - 0s 26us/step - loss: 5.8239 - acc: 0.6387\n",
      "Epoch 11/20\n",
      "512/512 [==============================] - 0s 36us/step - loss: 5.8239 - acc: 0.6387\n",
      "Epoch 12/20\n",
      "512/512 [==============================] - 0s 28us/step - loss: 5.8239 - acc: 0.6387\n",
      "Epoch 13/20\n",
      "512/512 [==============================] - 0s 35us/step - loss: 5.8239 - acc: 0.6387\n",
      "Epoch 14/20\n",
      "512/512 [==============================] - 0s 29us/step - loss: 5.8239 - acc: 0.6387\n",
      "Epoch 15/20\n",
      "512/512 [==============================] - 0s 29us/step - loss: 5.8239 - acc: 0.6387\n",
      "Epoch 16/20\n",
      "512/512 [==============================] - 0s 32us/step - loss: 5.8239 - acc: 0.6387\n",
      "Epoch 17/20\n",
      "512/512 [==============================] - 0s 28us/step - loss: 5.8239 - acc: 0.6387\n",
      "Epoch 18/20\n",
      "512/512 [==============================] - 0s 34us/step - loss: 5.8239 - acc: 0.6387\n",
      "Epoch 19/20\n",
      "512/512 [==============================] - 0s 29us/step - loss: 5.8239 - acc: 0.6387\n",
      "Epoch 20/20\n",
      "512/512 [==============================] - 0s 32us/step - loss: 5.8239 - acc: 0.6387\n",
      "256/256 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "512/512 [==============================] - 1s 2ms/step - loss: 4.7511 - acc: 0.6367\n",
      "Epoch 2/20\n",
      "512/512 [==============================] - 0s 29us/step - loss: 4.5545 - acc: 0.6367\n",
      "Epoch 3/20\n",
      "512/512 [==============================] - 0s 29us/step - loss: 4.2966 - acc: 0.6328\n",
      "Epoch 4/20\n",
      "512/512 [==============================] - 0s 24us/step - loss: 3.9728 - acc: 0.6309\n",
      "Epoch 5/20\n",
      "512/512 [==============================] - 0s 35us/step - loss: 3.5969 - acc: 0.6133\n",
      "Epoch 6/20\n",
      "512/512 [==============================] - 0s 23us/step - loss: 3.2616 - acc: 0.5742\n",
      "Epoch 7/20\n",
      "512/512 [==============================] - 0s 31us/step - loss: 2.9511 - acc: 0.5488\n",
      "Epoch 8/20\n",
      "512/512 [==============================] - 0s 23us/step - loss: 2.6279 - acc: 0.5742\n",
      "Epoch 9/20\n",
      "512/512 [==============================] - 0s 26us/step - loss: 2.4262 - acc: 0.5488\n",
      "Epoch 10/20\n",
      "512/512 [==============================] - 0s 26us/step - loss: 2.2671 - acc: 0.5234\n",
      "Epoch 11/20\n",
      "512/512 [==============================] - 0s 26us/step - loss: 2.1552 - acc: 0.5098\n",
      "Epoch 12/20\n",
      "512/512 [==============================] - 0s 28us/step - loss: 2.0283 - acc: 0.5176\n",
      "Epoch 13/20\n",
      "512/512 [==============================] - 0s 23us/step - loss: 1.9317 - acc: 0.5332\n",
      "Epoch 14/20\n",
      "512/512 [==============================] - 0s 32us/step - loss: 1.8196 - acc: 0.5352\n",
      "Epoch 15/20\n",
      "512/512 [==============================] - 0s 23us/step - loss: 1.7113 - acc: 0.5332\n",
      "Epoch 16/20\n",
      "512/512 [==============================] - 0s 31us/step - loss: 1.6068 - acc: 0.5391\n",
      "Epoch 17/20\n",
      "512/512 [==============================] - 0s 24us/step - loss: 1.5282 - acc: 0.5371\n",
      "Epoch 18/20\n",
      "512/512 [==============================] - 0s 23us/step - loss: 1.4468 - acc: 0.5586\n",
      "Epoch 19/20\n",
      "512/512 [==============================] - 0s 27us/step - loss: 1.3941 - acc: 0.5625\n",
      "Epoch 20/20\n",
      "512/512 [==============================] - 0s 25us/step - loss: 1.3252 - acc: 0.5801\n",
      "256/256 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "512/512 [==============================] - 1s 2ms/step - loss: 7.6249 - acc: 0.5039\n",
      "Epoch 2/20\n",
      "512/512 [==============================] - 0s 26us/step - loss: 7.5243 - acc: 0.5059\n",
      "Epoch 3/20\n",
      "512/512 [==============================] - 0s 31us/step - loss: 7.3972 - acc: 0.5117\n",
      "Epoch 4/20\n",
      "512/512 [==============================] - 0s 27us/step - loss: 7.2720 - acc: 0.5195\n",
      "Epoch 5/20\n",
      "512/512 [==============================] - 0s 31us/step - loss: 7.1721 - acc: 0.5293\n",
      "Epoch 6/20\n",
      "512/512 [==============================] - 0s 29us/step - loss: 7.0565 - acc: 0.5371\n",
      "Epoch 7/20\n",
      "512/512 [==============================] - 0s 32us/step - loss: 6.8302 - acc: 0.5449\n",
      "Epoch 8/20\n",
      "512/512 [==============================] - 0s 24us/step - loss: 6.6191 - acc: 0.5566\n",
      "Epoch 9/20\n",
      "512/512 [==============================] - 0s 27us/step - loss: 6.2921 - acc: 0.5723\n",
      "Epoch 10/20\n",
      "512/512 [==============================] - 0s 30us/step - loss: 5.9338 - acc: 0.5762\n",
      "Epoch 11/20\n",
      "512/512 [==============================] - 0s 23us/step - loss: 5.6926 - acc: 0.5996\n",
      "Epoch 12/20\n",
      "512/512 [==============================] - 0s 30us/step - loss: 5.6517 - acc: 0.6016\n",
      "Epoch 13/20\n",
      "512/512 [==============================] - 0s 24us/step - loss: 5.5782 - acc: 0.6094\n",
      "Epoch 14/20\n",
      "512/512 [==============================] - 0s 24us/step - loss: 5.5688 - acc: 0.6035\n",
      "Epoch 15/20\n",
      "512/512 [==============================] - 0s 30us/step - loss: 5.5272 - acc: 0.6055\n",
      "Epoch 16/20\n",
      "512/512 [==============================] - 0s 26us/step - loss: 5.4773 - acc: 0.6133\n",
      "Epoch 17/20\n",
      "512/512 [==============================] - 0s 30us/step - loss: 5.4726 - acc: 0.6074\n",
      "Epoch 18/20\n",
      "512/512 [==============================] - 0s 23us/step - loss: 5.4359 - acc: 0.6074\n",
      "Epoch 19/20\n",
      "512/512 [==============================] - 0s 23us/step - loss: 5.3924 - acc: 0.6074\n",
      "Epoch 20/20\n",
      "512/512 [==============================] - 0s 29us/step - loss: 5.3285 - acc: 0.6133\n",
      "256/256 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "512/512 [==============================] - 1s 2ms/step - loss: 6.7445 - acc: 0.4961\n",
      "Epoch 2/20\n",
      "512/512 [==============================] - 0s 24us/step - loss: 6.0078 - acc: 0.5098\n",
      "Epoch 3/20\n",
      "512/512 [==============================] - 0s 31us/step - loss: 5.1835 - acc: 0.5039\n",
      "Epoch 4/20\n",
      "512/512 [==============================] - 0s 25us/step - loss: 4.4020 - acc: 0.5332\n",
      "Epoch 5/20\n",
      "512/512 [==============================] - 0s 29us/step - loss: 4.2510 - acc: 0.5547\n",
      "Epoch 6/20\n",
      "512/512 [==============================] - 0s 23us/step - loss: 4.1286 - acc: 0.5762\n",
      "Epoch 7/20\n",
      "512/512 [==============================] - 0s 23us/step - loss: 3.9658 - acc: 0.5820\n",
      "Epoch 8/20\n",
      "512/512 [==============================] - 0s 31us/step - loss: 3.7757 - acc: 0.5664\n",
      "Epoch 9/20\n",
      "512/512 [==============================] - 0s 23us/step - loss: 3.6075 - acc: 0.5508\n",
      "Epoch 10/20\n",
      "512/512 [==============================] - 0s 30us/step - loss: 3.4887 - acc: 0.5625\n",
      "Epoch 11/20\n",
      "512/512 [==============================] - 0s 26us/step - loss: 3.3363 - acc: 0.5859\n",
      "Epoch 12/20\n",
      "512/512 [==============================] - 0s 23us/step - loss: 3.2048 - acc: 0.5840\n",
      "Epoch 13/20\n",
      "512/512 [==============================] - 0s 28us/step - loss: 3.0582 - acc: 0.5859\n",
      "Epoch 14/20\n",
      "512/512 [==============================] - 0s 25us/step - loss: 2.8542 - acc: 0.5977\n",
      "Epoch 15/20\n",
      "512/512 [==============================] - 0s 29us/step - loss: 2.6867 - acc: 0.6172\n",
      "Epoch 16/20\n",
      "512/512 [==============================] - 0s 23us/step - loss: 2.4912 - acc: 0.6074\n",
      "Epoch 17/20\n",
      "512/512 [==============================] - 0s 25us/step - loss: 2.3185 - acc: 0.6250\n",
      "Epoch 18/20\n",
      "512/512 [==============================] - 0s 33us/step - loss: 2.1478 - acc: 0.5996\n",
      "Epoch 19/20\n",
      "512/512 [==============================] - 0s 22us/step - loss: 2.0364 - acc: 0.5879\n",
      "Epoch 20/20\n",
      "512/512 [==============================] - 0s 40us/step - loss: 1.9312 - acc: 0.5820\n",
      "256/256 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 6.6033 - acc: 0.4023\n",
      "Epoch 2/20\n",
      "768/768 [==============================] - 0s 28us/step - loss: 6.2027 - acc: 0.4648\n",
      "Epoch 3/20\n",
      "768/768 [==============================] - 0s 26us/step - loss: 5.6829 - acc: 0.4727\n",
      "Epoch 4/20\n",
      "768/768 [==============================] - 0s 30us/step - loss: 4.9585 - acc: 0.5052\n",
      "Epoch 5/20\n",
      "768/768 [==============================] - 0s 26us/step - loss: 4.1068 - acc: 0.5794\n",
      "Epoch 6/20\n",
      "768/768 [==============================] - 0s 26us/step - loss: 3.1586 - acc: 0.6068\n",
      "Epoch 7/20\n",
      "768/768 [==============================] - 0s 31us/step - loss: 2.6414 - acc: 0.6289\n",
      "Epoch 8/20\n",
      "768/768 [==============================] - 0s 26us/step - loss: 2.4670 - acc: 0.6380\n",
      "Epoch 9/20\n",
      "768/768 [==============================] - 0s 33us/step - loss: 2.3296 - acc: 0.6224\n",
      "Epoch 10/20\n",
      "768/768 [==============================] - 0s 29us/step - loss: 2.1915 - acc: 0.6289\n",
      "Epoch 11/20\n",
      "768/768 [==============================] - 0s 34us/step - loss: 2.0866 - acc: 0.6380\n",
      "Epoch 12/20\n",
      "768/768 [==============================] - 0s 32us/step - loss: 1.9822 - acc: 0.6315\n",
      "Epoch 13/20\n",
      "768/768 [==============================] - 0s 27us/step - loss: 1.8965 - acc: 0.6289\n",
      "Epoch 14/20\n",
      "768/768 [==============================] - 0s 32us/step - loss: 1.8190 - acc: 0.6328\n",
      "Epoch 15/20\n",
      "768/768 [==============================] - 0s 30us/step - loss: 1.7439 - acc: 0.6419\n",
      "Epoch 16/20\n",
      "768/768 [==============================] - 0s 26us/step - loss: 1.6817 - acc: 0.6432\n",
      "Epoch 17/20\n",
      "768/768 [==============================] - 0s 30us/step - loss: 1.5997 - acc: 0.6328\n",
      "Epoch 18/20\n",
      "768/768 [==============================] - 0s 30us/step - loss: 1.5241 - acc: 0.6445\n",
      "Epoch 19/20\n",
      "768/768 [==============================] - 0s 27us/step - loss: 1.4746 - acc: 0.6484\n",
      "Epoch 20/20\n",
      "768/768 [==============================] - 0s 31us/step - loss: 1.4465 - acc: 0.6224\n",
      "Best: 0.653645838300387 using {'batch_size': 80, 'epochs': 20}\n",
      "Means: 0.5598958373690645, Stdev: 0.15580448574722938 with: {'batch_size': 10, 'epochs': 20}\n",
      "Means: 0.6380208393869301, Stdev: 0.02050523037618755 with: {'batch_size': 20, 'epochs': 20}\n",
      "Means: 0.5820312558983763, Stdev: 0.06994987677828778 with: {'batch_size': 40, 'epochs': 20}\n",
      "Means: 0.5208333345750967, Stdev: 0.13910979980141885 with: {'batch_size': 60, 'epochs': 20}\n",
      "Means: 0.653645838300387, Stdev: 0.02123633893418378 with: {'batch_size': 80, 'epochs': 20}\n",
      "Means: 0.631510405180355, Stdev: 0.05717316673766286 with: {'batch_size': 100, 'epochs': 20}\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# load dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.data.csv\", delimiter=\",\")\n",
    "\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_dim=8, activation='relu'))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "\n",
    "# define the grid search parameters\n",
    "# batch_size = [10, 20, 40, 60, 80, 100]\n",
    "# param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "# define the grid search parameters\n",
    "param_grid = {'batch_size': [10, 20, 40, 60, 80, 100],\n",
    "              'epochs': [20]}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X, Y)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pmABfjlvXbqi"
   },
   "source": [
    "## Epochs\n",
    "\n",
    "The number of training epochs has a large and direct affect on the accuracy, However, more epochs is almost always goign to better than less epochs. This means that if you tune this parameter at the beginning and try and maintain the same value all throughout your training, you're going to be waiting a long time for each iteration of GridSearch. I suggest picking a fixed moderat # of epochs all throughout your training and then Grid Searching this parameter at the very end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 26329
    },
    "colab_type": "code",
    "id": "bAmxP3N7TmFh",
    "outputId": "3ddb08c4-51ac-4eaa-ff39-143397024544",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 10.4975 - acc: 0.3415\n",
      "Epoch 2/20\n",
      "691/691 [==============================] - 0s 60us/step - loss: 10.4975 - acc: 0.3415\n",
      "Epoch 3/20\n",
      "691/691 [==============================] - 0s 56us/step - loss: 10.4975 - acc: 0.3415\n",
      "Epoch 4/20\n",
      "691/691 [==============================] - 0s 56us/step - loss: 10.4975 - acc: 0.3415\n",
      "Epoch 5/20\n",
      "691/691 [==============================] - 0s 53us/step - loss: 10.4975 - acc: 0.3415\n",
      "Epoch 6/20\n",
      "691/691 [==============================] - 0s 55us/step - loss: 10.4975 - acc: 0.3415\n",
      "Epoch 7/20\n",
      "691/691 [==============================] - 0s 55us/step - loss: 10.4975 - acc: 0.3415\n",
      "Epoch 8/20\n",
      "691/691 [==============================] - 0s 57us/step - loss: 10.4975 - acc: 0.3415\n",
      "Epoch 9/20\n",
      "691/691 [==============================] - 0s 55us/step - loss: 10.4975 - acc: 0.3415\n",
      "Epoch 10/20\n",
      "691/691 [==============================] - 0s 58us/step - loss: 10.4975 - acc: 0.3415\n",
      "Epoch 11/20\n",
      "691/691 [==============================] - 0s 55us/step - loss: 10.4975 - acc: 0.3415\n",
      "Epoch 12/20\n",
      "691/691 [==============================] - 0s 56us/step - loss: 10.4975 - acc: 0.3415\n",
      "Epoch 13/20\n",
      "691/691 [==============================] - 0s 56us/step - loss: 10.4975 - acc: 0.3415\n",
      "Epoch 14/20\n",
      "691/691 [==============================] - 0s 58us/step - loss: 10.4975 - acc: 0.3415\n",
      "Epoch 15/20\n",
      "691/691 [==============================] - 0s 57us/step - loss: 10.4975 - acc: 0.3415\n",
      "Epoch 16/20\n",
      "691/691 [==============================] - 0s 57us/step - loss: 10.4975 - acc: 0.3415\n",
      "Epoch 17/20\n",
      "691/691 [==============================] - 0s 54us/step - loss: 10.4975 - acc: 0.3415\n",
      "Epoch 18/20\n",
      "691/691 [==============================] - 0s 56us/step - loss: 10.4975 - acc: 0.3415\n",
      "Epoch 19/20\n",
      "691/691 [==============================] - 0s 56us/step - loss: 10.4975 - acc: 0.3415\n",
      "Epoch 20/20\n",
      "691/691 [==============================] - 0s 56us/step - loss: 10.4975 - acc: 0.3415\n",
      "77/77 [==============================] - 1s 15ms/step\n",
      "Epoch 1/20\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 7.7320 - acc: 0.3632\n",
      "Epoch 2/20\n",
      "691/691 [==============================] - 0s 52us/step - loss: 6.8491 - acc: 0.3922\n",
      "Epoch 3/20\n",
      "691/691 [==============================] - 0s 62us/step - loss: 6.0621 - acc: 0.4342\n",
      "Epoch 4/20\n",
      "691/691 [==============================] - 0s 56us/step - loss: 5.1061 - acc: 0.4805\n",
      "Epoch 5/20\n",
      "691/691 [==============================] - 0s 55us/step - loss: 4.1532 - acc: 0.5253\n",
      "Epoch 6/20\n",
      "691/691 [==============================] - 0s 54us/step - loss: 3.3529 - acc: 0.5528\n",
      "Epoch 7/20\n",
      "691/691 [==============================] - 0s 55us/step - loss: 2.8339 - acc: 0.5760\n",
      "Epoch 8/20\n",
      "691/691 [==============================] - 0s 55us/step - loss: 2.6280 - acc: 0.5441\n",
      "Epoch 9/20\n",
      "691/691 [==============================] - 0s 55us/step - loss: 2.5397 - acc: 0.5340\n",
      "Epoch 10/20\n",
      "691/691 [==============================] - 0s 53us/step - loss: 2.4500 - acc: 0.5557\n",
      "Epoch 11/20\n",
      "691/691 [==============================] - 0s 58us/step - loss: 2.3553 - acc: 0.5673\n",
      "Epoch 12/20\n",
      "691/691 [==============================] - 0s 53us/step - loss: 2.2720 - acc: 0.5644\n",
      "Epoch 13/20\n",
      "691/691 [==============================] - 0s 61us/step - loss: 2.1834 - acc: 0.5789\n",
      "Epoch 14/20\n",
      "691/691 [==============================] - 0s 54us/step - loss: 2.0884 - acc: 0.5789\n",
      "Epoch 15/20\n",
      "691/691 [==============================] - 0s 58us/step - loss: 2.0017 - acc: 0.5499\n",
      "Epoch 16/20\n",
      "691/691 [==============================] - 0s 58us/step - loss: 1.9147 - acc: 0.5687\n",
      "Epoch 17/20\n",
      "691/691 [==============================] - 0s 55us/step - loss: 1.8121 - acc: 0.5658\n",
      "Epoch 18/20\n",
      "691/691 [==============================] - 0s 59us/step - loss: 1.7248 - acc: 0.5716\n",
      "Epoch 19/20\n",
      "691/691 [==============================] - 0s 57us/step - loss: 1.6327 - acc: 0.5644\n",
      "Epoch 20/20\n",
      "691/691 [==============================] - 0s 56us/step - loss: 1.5534 - acc: 0.5702\n",
      "77/77 [==============================] - 1s 16ms/step\n",
      "Epoch 1/20\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 9.1860 - acc: 0.3676\n",
      "Epoch 2/20\n",
      "691/691 [==============================] - 0s 60us/step - loss: 7.9137 - acc: 0.3748\n",
      "Epoch 3/20\n",
      "691/691 [==============================] - 0s 56us/step - loss: 7.3843 - acc: 0.4009\n",
      "Epoch 4/20\n",
      "691/691 [==============================] - 0s 53us/step - loss: 7.3323 - acc: 0.4168\n",
      "Epoch 5/20\n",
      "691/691 [==============================] - 0s 56us/step - loss: 7.2196 - acc: 0.3965\n",
      "Epoch 6/20\n",
      "691/691 [==============================] - 0s 56us/step - loss: 7.1329 - acc: 0.3951\n",
      "Epoch 7/20\n",
      "691/691 [==============================] - 0s 55us/step - loss: 7.0576 - acc: 0.4139\n",
      "Epoch 8/20\n",
      "691/691 [==============================] - 0s 56us/step - loss: 6.9770 - acc: 0.4139\n",
      "Epoch 9/20\n",
      "691/691 [==============================] - 0s 55us/step - loss: 6.9182 - acc: 0.4168\n",
      "Epoch 10/20\n",
      "691/691 [==============================] - 0s 57us/step - loss: 6.8489 - acc: 0.4327\n",
      "Epoch 11/20\n",
      "691/691 [==============================] - 0s 59us/step - loss: 6.8204 - acc: 0.4052\n",
      "Epoch 12/20\n",
      "691/691 [==============================] - 0s 60us/step - loss: 6.7349 - acc: 0.4284\n",
      "Epoch 13/20\n",
      "691/691 [==============================] - 0s 53us/step - loss: 6.7006 - acc: 0.4240\n",
      "Epoch 14/20\n",
      "691/691 [==============================] - 0s 54us/step - loss: 6.6305 - acc: 0.4385\n",
      "Epoch 15/20\n",
      "691/691 [==============================] - 0s 57us/step - loss: 6.5757 - acc: 0.4255\n",
      "Epoch 16/20\n",
      "691/691 [==============================] - 0s 55us/step - loss: 6.5254 - acc: 0.4284\n",
      "Epoch 17/20\n",
      "691/691 [==============================] - 0s 54us/step - loss: 6.4788 - acc: 0.4515\n",
      "Epoch 18/20\n",
      "691/691 [==============================] - 0s 56us/step - loss: 6.4475 - acc: 0.4269\n",
      "Epoch 19/20\n",
      "691/691 [==============================] - 0s 57us/step - loss: 6.3840 - acc: 0.4674\n",
      "Epoch 20/20\n",
      "691/691 [==============================] - 0s 56us/step - loss: 6.2529 - acc: 0.4602\n",
      "77/77 [==============================] - 1s 16ms/step\n",
      "Epoch 1/20\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 2/20\n",
      "691/691 [==============================] - 0s 56us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 3/20\n",
      "691/691 [==============================] - 0s 58us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 4/20\n",
      "691/691 [==============================] - 0s 55us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 5/20\n",
      "691/691 [==============================] - 0s 53us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 6/20\n",
      "691/691 [==============================] - 0s 57us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 7/20\n",
      "691/691 [==============================] - 0s 58us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 8/20\n",
      "691/691 [==============================] - 0s 57us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 9/20\n",
      "691/691 [==============================] - 0s 59us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 10/20\n",
      "691/691 [==============================] - 0s 57us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 11/20\n",
      "691/691 [==============================] - 0s 58us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 12/20\n",
      "691/691 [==============================] - 0s 60us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 13/20\n",
      "691/691 [==============================] - 0s 60us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 14/20\n",
      "691/691 [==============================] - 0s 56us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 15/20\n",
      "691/691 [==============================] - 0s 56us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 16/20\n",
      "691/691 [==============================] - 0s 57us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 17/20\n",
      "691/691 [==============================] - 0s 58us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 18/20\n",
      "691/691 [==============================] - 0s 51us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 19/20\n",
      "691/691 [==============================] - 0s 63us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 20/20\n",
      "691/691 [==============================] - 0s 62us/step - loss: 10.4514 - acc: 0.3444\n",
      "77/77 [==============================] - 1s 16ms/step\n",
      "Epoch 1/20\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 3.9378 - acc: 0.5991\n",
      "Epoch 2/20\n",
      "691/691 [==============================] - 0s 57us/step - loss: 3.7685 - acc: 0.6049\n",
      "Epoch 3/20\n",
      "691/691 [==============================] - 0s 59us/step - loss: 3.6817 - acc: 0.6064\n",
      "Epoch 4/20\n",
      "691/691 [==============================] - 0s 55us/step - loss: 3.6086 - acc: 0.6049\n",
      "Epoch 5/20\n",
      "691/691 [==============================] - 0s 57us/step - loss: 3.5106 - acc: 0.6049\n",
      "Epoch 6/20\n",
      "691/691 [==============================] - 0s 62us/step - loss: 3.3872 - acc: 0.6078\n",
      "Epoch 7/20\n",
      "691/691 [==============================] - 0s 54us/step - loss: 3.1289 - acc: 0.6020\n",
      "Epoch 8/20\n",
      "691/691 [==============================] - 0s 52us/step - loss: 2.5604 - acc: 0.5369\n",
      "Epoch 9/20\n",
      "691/691 [==============================] - 0s 53us/step - loss: 2.0506 - acc: 0.5268\n",
      "Epoch 10/20\n",
      "691/691 [==============================] - 0s 56us/step - loss: 1.7345 - acc: 0.5644\n",
      "Epoch 11/20\n",
      "691/691 [==============================] - 0s 61us/step - loss: 1.4461 - acc: 0.5818\n",
      "Epoch 12/20\n",
      "691/691 [==============================] - 0s 55us/step - loss: 1.1063 - acc: 0.6136\n",
      "Epoch 13/20\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.9460 - acc: 0.6353\n",
      "Epoch 14/20\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.8940 - acc: 0.6237\n",
      "Epoch 15/20\n",
      "691/691 [==============================] - 0s 59us/step - loss: 0.8005 - acc: 0.6541\n",
      "Epoch 16/20\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.7562 - acc: 0.6657\n",
      "Epoch 17/20\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.7220 - acc: 0.6512\n",
      "Epoch 18/20\n",
      "691/691 [==============================] - 0s 61us/step - loss: 0.7159 - acc: 0.6425\n",
      "Epoch 19/20\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.7544 - acc: 0.6643\n",
      "Epoch 20/20\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.6784 - acc: 0.6874\n",
      "77/77 [==============================] - 1s 16ms/step\n",
      "Epoch 1/20\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 5.5515 - acc: 0.6556\n",
      "Epoch 2/20\n",
      "691/691 [==============================] - 0s 53us/step - loss: 5.5515 - acc: 0.6556\n",
      "Epoch 3/20\n",
      "691/691 [==============================] - 0s 57us/step - loss: 5.5515 - acc: 0.6556\n",
      "Epoch 4/20\n",
      "691/691 [==============================] - 0s 56us/step - loss: 5.5515 - acc: 0.6556\n",
      "Epoch 5/20\n",
      "691/691 [==============================] - 0s 54us/step - loss: 5.5515 - acc: 0.6556\n",
      "Epoch 6/20\n",
      "691/691 [==============================] - 0s 50us/step - loss: 5.5515 - acc: 0.6556\n",
      "Epoch 7/20\n",
      "691/691 [==============================] - 0s 60us/step - loss: 5.5515 - acc: 0.6556\n",
      "Epoch 8/20\n",
      "691/691 [==============================] - 0s 55us/step - loss: 5.5515 - acc: 0.6556\n",
      "Epoch 9/20\n",
      "691/691 [==============================] - 0s 51us/step - loss: 5.5515 - acc: 0.6556\n",
      "Epoch 10/20\n",
      "691/691 [==============================] - 0s 56us/step - loss: 5.5515 - acc: 0.6556\n",
      "Epoch 11/20\n",
      "691/691 [==============================] - 0s 57us/step - loss: 5.5515 - acc: 0.6556\n",
      "Epoch 12/20\n",
      "691/691 [==============================] - 0s 59us/step - loss: 5.5515 - acc: 0.6556\n",
      "Epoch 13/20\n",
      "691/691 [==============================] - 0s 53us/step - loss: 5.5515 - acc: 0.6556\n",
      "Epoch 14/20\n",
      "691/691 [==============================] - 0s 58us/step - loss: 5.5515 - acc: 0.6556\n",
      "Epoch 15/20\n",
      "691/691 [==============================] - 0s 53us/step - loss: 5.5515 - acc: 0.6556\n",
      "Epoch 16/20\n",
      "691/691 [==============================] - 0s 61us/step - loss: 5.5515 - acc: 0.6556\n",
      "Epoch 17/20\n",
      "691/691 [==============================] - 0s 58us/step - loss: 5.5515 - acc: 0.6556\n",
      "Epoch 18/20\n",
      "691/691 [==============================] - 0s 53us/step - loss: 5.5515 - acc: 0.6556\n",
      "Epoch 19/20\n",
      "691/691 [==============================] - 0s 57us/step - loss: 5.5515 - acc: 0.6556\n",
      "Epoch 20/20\n",
      "691/691 [==============================] - 0s 59us/step - loss: 5.5515 - acc: 0.6556\n",
      "77/77 [==============================] - 1s 16ms/step\n",
      "Epoch 1/20\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 5.3693 - acc: 0.4298\n",
      "Epoch 2/20\n",
      "691/691 [==============================] - 0s 56us/step - loss: 3.3925 - acc: 0.5528\n",
      "Epoch 3/20\n",
      "691/691 [==============================] - 0s 55us/step - loss: 3.3365 - acc: 0.5991\n",
      "Epoch 4/20\n",
      "691/691 [==============================] - 0s 57us/step - loss: 3.2099 - acc: 0.5499\n",
      "Epoch 5/20\n",
      "691/691 [==============================] - 0s 56us/step - loss: 3.1187 - acc: 0.5485\n",
      "Epoch 6/20\n",
      "691/691 [==============================] - 0s 56us/step - loss: 3.0578 - acc: 0.5745\n",
      "Epoch 7/20\n",
      "691/691 [==============================] - 0s 56us/step - loss: 2.9675 - acc: 0.5557\n",
      "Epoch 8/20\n",
      "691/691 [==============================] - 0s 57us/step - loss: 2.8974 - acc: 0.5427\n",
      "Epoch 9/20\n",
      "691/691 [==============================] - 0s 56us/step - loss: 2.7846 - acc: 0.5586\n",
      "Epoch 10/20\n",
      "691/691 [==============================] - 0s 63us/step - loss: 2.6928 - acc: 0.5499\n",
      "Epoch 11/20\n",
      "691/691 [==============================] - 0s 60us/step - loss: 2.6044 - acc: 0.5586\n",
      "Epoch 12/20\n",
      "691/691 [==============================] - 0s 51us/step - loss: 2.5023 - acc: 0.5427\n",
      "Epoch 13/20\n",
      "691/691 [==============================] - 0s 58us/step - loss: 2.4553 - acc: 0.5803\n",
      "Epoch 14/20\n",
      "691/691 [==============================] - 0s 55us/step - loss: 2.3098 - acc: 0.5326\n",
      "Epoch 15/20\n",
      "691/691 [==============================] - 0s 53us/step - loss: 2.1766 - acc: 0.5528\n",
      "Epoch 16/20\n",
      "691/691 [==============================] - 0s 53us/step - loss: 2.0831 - acc: 0.5441\n",
      "Epoch 17/20\n",
      "691/691 [==============================] - 0s 59us/step - loss: 1.9797 - acc: 0.5615\n",
      "Epoch 18/20\n",
      "691/691 [==============================] - 0s 57us/step - loss: 1.8826 - acc: 0.5832\n",
      "Epoch 19/20\n",
      "691/691 [==============================] - 0s 61us/step - loss: 1.7812 - acc: 0.5528\n",
      "Epoch 20/20\n",
      "691/691 [==============================] - 0s 58us/step - loss: 1.6859 - acc: 0.5789\n",
      "77/77 [==============================] - 1s 16ms/step\n",
      "Epoch 1/20\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 7.9624 - acc: 0.3517\n",
      "Epoch 2/20\n",
      "691/691 [==============================] - 0s 59us/step - loss: 7.3992 - acc: 0.3806\n",
      "Epoch 3/20\n",
      "691/691 [==============================] - 0s 55us/step - loss: 6.8158 - acc: 0.4139\n",
      "Epoch 4/20\n",
      "691/691 [==============================] - 0s 60us/step - loss: 5.8314 - acc: 0.4385\n",
      "Epoch 5/20\n",
      "691/691 [==============================] - 0s 54us/step - loss: 4.6070 - acc: 0.5239\n",
      "Epoch 6/20\n",
      "691/691 [==============================] - 0s 59us/step - loss: 3.7785 - acc: 0.6165\n",
      "Epoch 7/20\n",
      "691/691 [==============================] - 0s 52us/step - loss: 2.8592 - acc: 0.5818\n",
      "Epoch 8/20\n",
      "691/691 [==============================] - 0s 57us/step - loss: 2.1550 - acc: 0.5398\n",
      "Epoch 9/20\n",
      "691/691 [==============================] - 0s 55us/step - loss: 1.7330 - acc: 0.5876\n",
      "Epoch 10/20\n",
      "691/691 [==============================] - 0s 56us/step - loss: 1.5413 - acc: 0.5716\n",
      "Epoch 11/20\n",
      "691/691 [==============================] - 0s 58us/step - loss: 1.4935 - acc: 0.6122\n",
      "Epoch 12/20\n",
      "691/691 [==============================] - 0s 58us/step - loss: 1.3621 - acc: 0.5861\n",
      "Epoch 13/20\n",
      "691/691 [==============================] - 0s 58us/step - loss: 1.2794 - acc: 0.6078\n",
      "Epoch 14/20\n",
      "691/691 [==============================] - 0s 62us/step - loss: 1.2339 - acc: 0.5962\n",
      "Epoch 15/20\n",
      "691/691 [==============================] - 0s 58us/step - loss: 1.1812 - acc: 0.6049\n",
      "Epoch 16/20\n",
      "691/691 [==============================] - 0s 58us/step - loss: 1.0970 - acc: 0.6208\n",
      "Epoch 17/20\n",
      "691/691 [==============================] - 0s 52us/step - loss: 1.0536 - acc: 0.6208\n",
      "Epoch 18/20\n",
      "691/691 [==============================] - 0s 57us/step - loss: 1.0114 - acc: 0.6208\n",
      "Epoch 19/20\n",
      "691/691 [==============================] - 0s 60us/step - loss: 0.9997 - acc: 0.6339\n",
      "Epoch 20/20\n",
      "691/691 [==============================] - 0s 58us/step - loss: 0.9411 - acc: 0.6281\n",
      "77/77 [==============================] - 1s 16ms/step\n",
      "Epoch 1/20\n",
      "692/692 [==============================] - 3s 4ms/step - loss: 3.7957 - acc: 0.5737\n",
      "Epoch 2/20\n",
      "692/692 [==============================] - 0s 55us/step - loss: 2.6720 - acc: 0.5708\n",
      "Epoch 3/20\n",
      "692/692 [==============================] - 0s 58us/step - loss: 2.2299 - acc: 0.5506\n",
      "Epoch 4/20\n",
      "692/692 [==============================] - 0s 58us/step - loss: 2.0008 - acc: 0.5838\n",
      "Epoch 5/20\n",
      "692/692 [==============================] - 0s 61us/step - loss: 1.9234 - acc: 0.5939\n",
      "Epoch 6/20\n",
      "692/692 [==============================] - 0s 62us/step - loss: 1.8291 - acc: 0.5968\n",
      "Epoch 7/20\n",
      "692/692 [==============================] - 0s 53us/step - loss: 1.7352 - acc: 0.6055\n",
      "Epoch 8/20\n",
      "692/692 [==============================] - 0s 60us/step - loss: 1.6603 - acc: 0.5925\n",
      "Epoch 9/20\n",
      "692/692 [==============================] - 0s 58us/step - loss: 1.5907 - acc: 0.6199\n",
      "Epoch 10/20\n",
      "692/692 [==============================] - 0s 66us/step - loss: 1.5085 - acc: 0.6084\n",
      "Epoch 11/20\n",
      "692/692 [==============================] - 0s 56us/step - loss: 1.4571 - acc: 0.6214\n",
      "Epoch 12/20\n",
      "692/692 [==============================] - 0s 57us/step - loss: 1.4005 - acc: 0.5939\n",
      "Epoch 13/20\n",
      "692/692 [==============================] - 0s 58us/step - loss: 1.3316 - acc: 0.6387\n",
      "Epoch 14/20\n",
      "692/692 [==============================] - 0s 55us/step - loss: 1.2726 - acc: 0.5968\n",
      "Epoch 15/20\n",
      "692/692 [==============================] - 0s 60us/step - loss: 1.2221 - acc: 0.6416\n",
      "Epoch 16/20\n",
      "692/692 [==============================] - 0s 62us/step - loss: 1.1743 - acc: 0.6098\n",
      "Epoch 17/20\n",
      "692/692 [==============================] - 0s 54us/step - loss: 1.1272 - acc: 0.6358\n",
      "Epoch 18/20\n",
      "692/692 [==============================] - 0s 58us/step - loss: 1.0873 - acc: 0.6431\n",
      "Epoch 19/20\n",
      "692/692 [==============================] - 0s 61us/step - loss: 1.0444 - acc: 0.6315\n",
      "Epoch 20/20\n",
      "692/692 [==============================] - 0s 56us/step - loss: 1.0231 - acc: 0.6633\n",
      "76/76 [==============================] - 1s 17ms/step\n",
      "Epoch 1/20\n",
      "692/692 [==============================] - 3s 4ms/step - loss: 8.0512 - acc: 0.3627\n",
      "Epoch 2/20\n",
      "692/692 [==============================] - 0s 59us/step - loss: 4.3385 - acc: 0.4292\n",
      "Epoch 3/20\n",
      "692/692 [==============================] - 0s 58us/step - loss: 2.4901 - acc: 0.5607\n",
      "Epoch 4/20\n",
      "692/692 [==============================] - 0s 55us/step - loss: 2.3932 - acc: 0.6127\n",
      "Epoch 5/20\n",
      "692/692 [==============================] - 0s 57us/step - loss: 2.1316 - acc: 0.5809\n",
      "Epoch 6/20\n",
      "692/692 [==============================] - 0s 63us/step - loss: 1.9625 - acc: 0.5665\n",
      "Epoch 7/20\n",
      "692/692 [==============================] - 0s 52us/step - loss: 1.8426 - acc: 0.5766\n",
      "Epoch 8/20\n",
      "692/692 [==============================] - 0s 59us/step - loss: 1.7669 - acc: 0.5910\n",
      "Epoch 9/20\n",
      "692/692 [==============================] - 0s 55us/step - loss: 1.6838 - acc: 0.5910\n",
      "Epoch 10/20\n",
      "692/692 [==============================] - 0s 60us/step - loss: 1.6074 - acc: 0.6026\n",
      "Epoch 11/20\n",
      "692/692 [==============================] - 0s 61us/step - loss: 1.5567 - acc: 0.5997\n",
      "Epoch 12/20\n",
      "692/692 [==============================] - 0s 56us/step - loss: 1.4916 - acc: 0.6026\n",
      "Epoch 13/20\n",
      "692/692 [==============================] - 0s 61us/step - loss: 1.4373 - acc: 0.6171\n",
      "Epoch 14/20\n",
      "692/692 [==============================] - 0s 57us/step - loss: 1.3823 - acc: 0.6156\n",
      "Epoch 15/20\n",
      "692/692 [==============================] - 0s 56us/step - loss: 1.3355 - acc: 0.6416\n",
      "Epoch 16/20\n",
      "692/692 [==============================] - 0s 64us/step - loss: 1.2745 - acc: 0.6257\n",
      "Epoch 17/20\n",
      "692/692 [==============================] - 0s 57us/step - loss: 1.2330 - acc: 0.6445\n",
      "Epoch 18/20\n",
      "692/692 [==============================] - 0s 56us/step - loss: 1.1903 - acc: 0.6431\n",
      "Epoch 19/20\n",
      "692/692 [==============================] - 0s 59us/step - loss: 1.1615 - acc: 0.6329\n",
      "Epoch 20/20\n",
      "692/692 [==============================] - 0s 58us/step - loss: 1.1393 - acc: 0.6474\n",
      "76/76 [==============================] - 1s 17ms/step\n",
      "Epoch 1/40\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 2/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 3/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 4/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 5/40\n",
      "691/691 [==============================] - 0s 54us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 6/40\n",
      "691/691 [==============================] - 0s 54us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 7/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 8/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 9/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 10/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 11/40\n",
      "691/691 [==============================] - 0s 63us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 12/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 13/40\n",
      "691/691 [==============================] - 0s 63us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 14/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 15/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 16/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 17/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 18/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 19/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 20/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 21/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 22/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 23/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 24/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 25/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 26/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 27/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 28/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 29/40\n",
      "691/691 [==============================] - 0s 61us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 30/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 31/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 32/40\n",
      "691/691 [==============================] - 0s 61us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 33/40\n",
      "691/691 [==============================] - 0s 61us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 34/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 35/40\n",
      "691/691 [==============================] - 0s 61us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 36/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 37/40\n",
      "691/691 [==============================] - 0s 69us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 38/40\n",
      "691/691 [==============================] - 0s 62us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 39/40\n",
      "691/691 [==============================] - 0s 70us/step - loss: 5.5049 - acc: 0.6585\n",
      "Epoch 40/40\n",
      "691/691 [==============================] - 0s 69us/step - loss: 5.5049 - acc: 0.6585\n",
      "77/77 [==============================] - 1s 17ms/step\n",
      "Epoch 1/40\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 6.4743 - acc: 0.3835\n",
      "Epoch 2/40\n",
      "691/691 [==============================] - 0s 50us/step - loss: 5.8492 - acc: 0.4544\n",
      "Epoch 3/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 4.0824 - acc: 0.5137\n",
      "Epoch 4/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 3.0194 - acc: 0.5803\n",
      "Epoch 5/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 2.4433 - acc: 0.4964\n",
      "Epoch 6/40\n",
      "691/691 [==============================] - 0s 51us/step - loss: 2.1520 - acc: 0.5065\n",
      "Epoch 7/40\n",
      "691/691 [==============================] - 0s 51us/step - loss: 1.9167 - acc: 0.5224\n",
      "Epoch 8/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 1.7335 - acc: 0.5297\n",
      "Epoch 9/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 1.5552 - acc: 0.5470\n",
      "Epoch 10/40\n",
      "691/691 [==============================] - 0s 53us/step - loss: 1.3966 - acc: 0.5297\n",
      "Epoch 11/40\n",
      "691/691 [==============================] - 0s 53us/step - loss: 1.2824 - acc: 0.5456\n",
      "Epoch 12/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 1.2094 - acc: 0.5601\n",
      "Epoch 13/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 1.1230 - acc: 0.5586\n",
      "Epoch 14/40\n",
      "691/691 [==============================] - 0s 50us/step - loss: 1.0694 - acc: 0.5745\n",
      "Epoch 15/40\n",
      "691/691 [==============================] - 0s 65us/step - loss: 1.0436 - acc: 0.5803\n",
      "Epoch 16/40\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.9840 - acc: 0.6122\n",
      "Epoch 17/40\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.9218 - acc: 0.6020\n",
      "Epoch 18/40\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.9197 - acc: 0.6122\n",
      "Epoch 19/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.9007 - acc: 0.6223\n",
      "Epoch 20/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.8922 - acc: 0.6223\n",
      "Epoch 21/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.8629 - acc: 0.6049\n",
      "Epoch 22/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.8233 - acc: 0.6339\n",
      "Epoch 23/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.8107 - acc: 0.6527\n",
      "Epoch 24/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.8226 - acc: 0.6368\n",
      "Epoch 25/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.7847 - acc: 0.6541\n",
      "Epoch 26/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.7848 - acc: 0.6715\n",
      "Epoch 27/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.7778 - acc: 0.6585\n",
      "Epoch 28/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.7762 - acc: 0.6671\n",
      "Epoch 29/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.7548 - acc: 0.6498\n",
      "Epoch 30/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.7338 - acc: 0.6628\n",
      "Epoch 31/40\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.7316 - acc: 0.6657\n",
      "Epoch 32/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.7269 - acc: 0.6657\n",
      "Epoch 33/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.7246 - acc: 0.6527\n",
      "Epoch 34/40\n",
      "691/691 [==============================] - 0s 63us/step - loss: 0.7216 - acc: 0.6628\n",
      "Epoch 35/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.7498 - acc: 0.6512\n",
      "Epoch 36/40\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.6984 - acc: 0.6773\n",
      "Epoch 37/40\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.6977 - acc: 0.6643\n",
      "Epoch 38/40\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.6929 - acc: 0.6671\n",
      "Epoch 39/40\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.6802 - acc: 0.6802\n",
      "Epoch 40/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.6769 - acc: 0.6700\n",
      "77/77 [==============================] - 1s 17ms/step\n",
      "Epoch 1/40\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 2/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 3/40\n",
      "691/691 [==============================] - 0s 60us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 4/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 5/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 6/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 7/40\n",
      "691/691 [==============================] - 0s 62us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 8/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 9/40\n",
      "691/691 [==============================] - 0s 64us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 10/40\n",
      "691/691 [==============================] - 0s 61us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 11/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 12/40\n",
      "691/691 [==============================] - 0s 61us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 13/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 14/40\n",
      "691/691 [==============================] - 0s 64us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 15/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 16/40\n",
      "691/691 [==============================] - 0s 60us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 17/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 18/40\n",
      "691/691 [==============================] - 0s 60us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 19/40\n",
      "691/691 [==============================] - 0s 63us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 20/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 21/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 22/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 23/40\n",
      "691/691 [==============================] - 0s 62us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 24/40\n",
      "691/691 [==============================] - 0s 62us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 25/40\n",
      "691/691 [==============================] - 0s 69us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 26/40\n",
      "691/691 [==============================] - 0s 71us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 27/40\n",
      "691/691 [==============================] - 0s 65us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 28/40\n",
      "691/691 [==============================] - 0s 67us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 29/40\n",
      "691/691 [==============================] - 0s 66us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 30/40\n",
      "691/691 [==============================] - 0s 63us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 31/40\n",
      "691/691 [==============================] - 0s 64us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 32/40\n",
      "691/691 [==============================] - 0s 60us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 33/40\n",
      "691/691 [==============================] - 0s 66us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 34/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 35/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 36/40\n",
      "691/691 [==============================] - 0s 68us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 37/40\n",
      "691/691 [==============================] - 0s 71us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 38/40\n",
      "691/691 [==============================] - 0s 69us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 39/40\n",
      "691/691 [==============================] - 0s 66us/step - loss: 5.4582 - acc: 0.6614\n",
      "Epoch 40/40\n",
      "691/691 [==============================] - 0s 63us/step - loss: 5.4582 - acc: 0.6614\n",
      "77/77 [==============================] - 1s 17ms/step\n",
      "Epoch 1/40\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 8.5246 - acc: 0.3763\n",
      "Epoch 2/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 6.6465 - acc: 0.4428\n",
      "Epoch 3/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 5.7347 - acc: 0.5166\n",
      "Epoch 4/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 5.0884 - acc: 0.5630\n",
      "Epoch 5/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 4.3942 - acc: 0.5876\n",
      "Epoch 6/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 3.9989 - acc: 0.6151\n",
      "Epoch 7/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 3.7836 - acc: 0.6368\n",
      "Epoch 8/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 3.6451 - acc: 0.6339\n",
      "Epoch 9/40\n",
      "691/691 [==============================] - 0s 60us/step - loss: 3.3549 - acc: 0.6353\n",
      "Epoch 10/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 3.1442 - acc: 0.6281\n",
      "Epoch 11/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 3.0114 - acc: 0.6353\n",
      "Epoch 12/40\n",
      "691/691 [==============================] - 0s 60us/step - loss: 2.9354 - acc: 0.6498\n",
      "Epoch 13/40\n",
      "691/691 [==============================] - 0s 60us/step - loss: 2.8662 - acc: 0.6541\n",
      "Epoch 14/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 2.8101 - acc: 0.6570\n",
      "Epoch 15/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 2.7611 - acc: 0.6614\n",
      "Epoch 16/40\n",
      "691/691 [==============================] - 0s 60us/step - loss: 2.7042 - acc: 0.6585\n",
      "Epoch 17/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 2.6505 - acc: 0.6614\n",
      "Epoch 18/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 2.5934 - acc: 0.6715\n",
      "Epoch 19/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 2.5330 - acc: 0.6686\n",
      "Epoch 20/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 2.4788 - acc: 0.6700\n",
      "Epoch 21/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 2.4491 - acc: 0.6686\n",
      "Epoch 22/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 2.3911 - acc: 0.6715\n",
      "Epoch 23/40\n",
      "691/691 [==============================] - ETA: 0s - loss: 2.1636 - acc: 0.666 - 0s 54us/step - loss: 2.3512 - acc: 0.6585\n",
      "Epoch 24/40\n",
      "691/691 [==============================] - 0s 65us/step - loss: 2.3117 - acc: 0.6802\n",
      "Epoch 25/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 2.2603 - acc: 0.6512\n",
      "Epoch 26/40\n",
      "691/691 [==============================] - 0s 62us/step - loss: 2.2269 - acc: 0.6643\n",
      "Epoch 27/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 2.1714 - acc: 0.6643\n",
      "Epoch 28/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 2.1142 - acc: 0.6599\n",
      "Epoch 29/40\n",
      "691/691 [==============================] - 0s 65us/step - loss: 2.0661 - acc: 0.6657\n",
      "Epoch 30/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 1.9975 - acc: 0.6614\n",
      "Epoch 31/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 1.9600 - acc: 0.6585\n",
      "Epoch 32/40\n",
      "691/691 [==============================] - 0s 60us/step - loss: 1.8814 - acc: 0.6715\n",
      "Epoch 33/40\n",
      "691/691 [==============================] - 0s 61us/step - loss: 1.8218 - acc: 0.6686\n",
      "Epoch 34/40\n",
      "691/691 [==============================] - 0s 60us/step - loss: 1.7742 - acc: 0.6729\n",
      "Epoch 35/40\n",
      "691/691 [==============================] - 0s 60us/step - loss: 1.7008 - acc: 0.6787\n",
      "Epoch 36/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 1.6498 - acc: 0.6686\n",
      "Epoch 37/40\n",
      "691/691 [==============================] - 0s 62us/step - loss: 1.5716 - acc: 0.6657\n",
      "Epoch 38/40\n",
      "691/691 [==============================] - 0s 62us/step - loss: 1.5124 - acc: 0.6527\n",
      "Epoch 39/40\n",
      "691/691 [==============================] - 0s 62us/step - loss: 1.4623 - acc: 0.6498\n",
      "Epoch 40/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 1.4263 - acc: 0.6469\n",
      "77/77 [==============================] - 1s 17ms/step\n",
      "Epoch 1/40\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 4.3429 - acc: 0.5224\n",
      "Epoch 2/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 4.1614 - acc: 0.5123\n",
      "Epoch 3/40\n",
      "691/691 [==============================] - 0s 61us/step - loss: 4.0314 - acc: 0.5297\n",
      "Epoch 4/40\n",
      "691/691 [==============================] - 0s 60us/step - loss: 3.9083 - acc: 0.5022\n",
      "Epoch 5/40\n",
      "691/691 [==============================] - 0s 61us/step - loss: 3.7627 - acc: 0.5355\n",
      "Epoch 6/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 3.5642 - acc: 0.4891\n",
      "Epoch 7/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 3.4488 - acc: 0.4906\n",
      "Epoch 8/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 3.3264 - acc: 0.5152\n",
      "Epoch 9/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 3.2173 - acc: 0.5007\n",
      "Epoch 10/40\n",
      "691/691 [==============================] - 0s 60us/step - loss: 3.1169 - acc: 0.5253\n",
      "Epoch 11/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 2.9672 - acc: 0.5123\n",
      "Epoch 12/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 2.7642 - acc: 0.5268\n",
      "Epoch 13/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 2.5608 - acc: 0.5485\n",
      "Epoch 14/40\n",
      "691/691 [==============================] - 0s 54us/step - loss: 2.3230 - acc: 0.5499\n",
      "Epoch 15/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 2.0866 - acc: 0.5485\n",
      "Epoch 16/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 1.8303 - acc: 0.5557\n",
      "Epoch 17/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 1.6417 - acc: 0.5630\n",
      "Epoch 18/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 1.4633 - acc: 0.5803\n",
      "Epoch 19/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 1.3278 - acc: 0.5630\n",
      "Epoch 20/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 1.2706 - acc: 0.5673\n",
      "Epoch 21/40\n",
      "691/691 [==============================] - 0s 62us/step - loss: 1.1666 - acc: 0.5847\n",
      "Epoch 22/40\n",
      "691/691 [==============================] - 0s 62us/step - loss: 1.1177 - acc: 0.5774\n",
      "Epoch 23/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 1.0398 - acc: 0.5745\n",
      "Epoch 24/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 1.0129 - acc: 0.6194\n",
      "Epoch 25/40\n",
      "691/691 [==============================] - 0s 60us/step - loss: 0.9858 - acc: 0.6035\n",
      "Epoch 26/40\n",
      "691/691 [==============================] - 0s 60us/step - loss: 0.9025 - acc: 0.5933\n",
      "Epoch 27/40\n",
      "691/691 [==============================] - 0s 63us/step - loss: 0.8668 - acc: 0.6368\n",
      "Epoch 28/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.8314 - acc: 0.6339\n",
      "Epoch 29/40\n",
      "691/691 [==============================] - 0s 60us/step - loss: 0.8229 - acc: 0.6252\n",
      "Epoch 30/40\n",
      "691/691 [==============================] - 0s 61us/step - loss: 0.7967 - acc: 0.6498\n",
      "Epoch 31/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.7942 - acc: 0.6208\n",
      "Epoch 32/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 0.7711 - acc: 0.6425\n",
      "Epoch 33/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 0.7526 - acc: 0.6425\n",
      "Epoch 34/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 0.7290 - acc: 0.6686\n",
      "Epoch 35/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.7280 - acc: 0.6570\n",
      "Epoch 36/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.7052 - acc: 0.6729\n",
      "Epoch 37/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.7077 - acc: 0.6570\n",
      "Epoch 38/40\n",
      "691/691 [==============================] - 0s 61us/step - loss: 0.7149 - acc: 0.6614\n",
      "Epoch 39/40\n",
      "691/691 [==============================] - 0s 60us/step - loss: 0.6950 - acc: 0.6831\n",
      "Epoch 40/40\n",
      "691/691 [==============================] - 0s 61us/step - loss: 0.6920 - acc: 0.6729\n",
      "77/77 [==============================] - 1s 18ms/step\n",
      "Epoch 1/40\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 5.6678 - acc: 0.5499\n",
      "Epoch 2/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 4.9995 - acc: 0.5731\n",
      "Epoch 3/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 4.7835 - acc: 0.6006\n",
      "Epoch 4/40\n",
      "691/691 [==============================] - 0s 53us/step - loss: 4.7649 - acc: 0.6093\n",
      "Epoch 5/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 4.6884 - acc: 0.6078\n",
      "Epoch 6/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 4.6219 - acc: 0.5962\n",
      "Epoch 7/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 4.5713 - acc: 0.5948\n",
      "Epoch 8/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 4.5242 - acc: 0.6006\n",
      "Epoch 9/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 4.4620 - acc: 0.6035\n",
      "Epoch 10/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 4.3860 - acc: 0.6064\n",
      "Epoch 11/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 4.3025 - acc: 0.6049\n",
      "Epoch 12/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 4.2202 - acc: 0.6107\n",
      "Epoch 13/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 4.1383 - acc: 0.6078\n",
      "Epoch 14/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 4.0384 - acc: 0.6107\n",
      "Epoch 15/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 3.9323 - acc: 0.6165\n",
      "Epoch 16/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 3.8511 - acc: 0.6281\n",
      "Epoch 17/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 3.7790 - acc: 0.6295\n",
      "Epoch 18/40\n",
      "691/691 [==============================] - 0s 60us/step - loss: 3.7363 - acc: 0.6324\n",
      "Epoch 19/40\n",
      "691/691 [==============================] - 0s 61us/step - loss: 3.7004 - acc: 0.6339\n",
      "Epoch 20/40\n",
      "691/691 [==============================] - 0s 62us/step - loss: 3.6710 - acc: 0.6310\n",
      "Epoch 21/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 3.6486 - acc: 0.6252\n",
      "Epoch 22/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 3.6259 - acc: 0.6252\n",
      "Epoch 23/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 3.6015 - acc: 0.6179\n",
      "Epoch 24/40\n",
      "691/691 [==============================] - 0s 61us/step - loss: 3.5780 - acc: 0.6165\n",
      "Epoch 25/40\n",
      "691/691 [==============================] - 0s 60us/step - loss: 3.5577 - acc: 0.6179\n",
      "Epoch 26/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 3.5370 - acc: 0.6208\n",
      "Epoch 27/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 3.5239 - acc: 0.6223\n",
      "Epoch 28/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 3.5042 - acc: 0.6136\n",
      "Epoch 29/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 3.4838 - acc: 0.6151\n",
      "Epoch 30/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 3.4496 - acc: 0.6122\n",
      "Epoch 31/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 3.4090 - acc: 0.6165\n",
      "Epoch 32/40\n",
      "691/691 [==============================] - 0s 60us/step - loss: 3.3079 - acc: 0.6179\n",
      "Epoch 33/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 2.8692 - acc: 0.5673\n",
      "Epoch 34/40\n",
      "691/691 [==============================] - 0s 60us/step - loss: 2.0198 - acc: 0.5340\n",
      "Epoch 35/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 1.4965 - acc: 0.5731\n",
      "Epoch 36/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 1.2745 - acc: 0.5528\n",
      "Epoch 37/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 1.2034 - acc: 0.5962\n",
      "Epoch 38/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 1.1505 - acc: 0.6208\n",
      "Epoch 39/40\n",
      "691/691 [==============================] - 0s 63us/step - loss: 1.0972 - acc: 0.6165\n",
      "Epoch 40/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 1.0757 - acc: 0.6368\n",
      "77/77 [==============================] - 1s 18ms/step\n",
      "Epoch 1/40\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 5.9171 - acc: 0.6310\n",
      "Epoch 2/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 5.9148 - acc: 0.6310\n",
      "Epoch 3/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 5.9137 - acc: 0.6310\n",
      "Epoch 4/40\n",
      "691/691 [==============================] - 0s 53us/step - loss: 5.9132 - acc: 0.6310\n",
      "Epoch 5/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 5.9130 - acc: 0.6310\n",
      "Epoch 6/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 5.9127 - acc: 0.6310\n",
      "Epoch 7/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 5.9119 - acc: 0.6310\n",
      "Epoch 8/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 5.9116 - acc: 0.6310\n",
      "Epoch 9/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 5.9113 - acc: 0.6310\n",
      "Epoch 10/40\n",
      "691/691 [==============================] - 0s 54us/step - loss: 5.9109 - acc: 0.6310\n",
      "Epoch 11/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 5.9105 - acc: 0.6310\n",
      "Epoch 12/40\n",
      "691/691 [==============================] - 0s 54us/step - loss: 5.9104 - acc: 0.6310\n",
      "Epoch 13/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 5.9100 - acc: 0.6310\n",
      "Epoch 14/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 5.9099 - acc: 0.6310\n",
      "Epoch 15/40\n",
      "691/691 [==============================] - 0s 69us/step - loss: 5.9095 - acc: 0.6310\n",
      "Epoch 16/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 5.9091 - acc: 0.6310\n",
      "Epoch 17/40\n",
      "691/691 [==============================] - 0s 53us/step - loss: 5.9094 - acc: 0.6310\n",
      "Epoch 18/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 5.9094 - acc: 0.6310\n",
      "Epoch 19/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 5.9092 - acc: 0.6310\n",
      "Epoch 20/40\n",
      "691/691 [==============================] - 0s 62us/step - loss: 5.9093 - acc: 0.6310\n",
      "Epoch 21/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 5.9080 - acc: 0.6310\n",
      "Epoch 22/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 5.9078 - acc: 0.6310\n",
      "Epoch 23/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 5.9078 - acc: 0.6310\n",
      "Epoch 24/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 5.9074 - acc: 0.6310\n",
      "Epoch 25/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 5.9074 - acc: 0.6310\n",
      "Epoch 26/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 5.9072 - acc: 0.6310\n",
      "Epoch 27/40\n",
      "691/691 [==============================] - 0s 54us/step - loss: 5.9070 - acc: 0.6310\n",
      "Epoch 28/40\n",
      "691/691 [==============================] - 0s 54us/step - loss: 5.9069 - acc: 0.6310\n",
      "Epoch 29/40\n",
      "691/691 [==============================] - 0s 54us/step - loss: 5.9068 - acc: 0.6310\n",
      "Epoch 30/40\n",
      "691/691 [==============================] - 0s 54us/step - loss: 5.9068 - acc: 0.6310\n",
      "Epoch 31/40\n",
      "691/691 [==============================] - 0s 54us/step - loss: 5.9066 - acc: 0.6310\n",
      "Epoch 32/40\n",
      "691/691 [==============================] - 0s 54us/step - loss: 5.9068 - acc: 0.6310\n",
      "Epoch 33/40\n",
      "691/691 [==============================] - 0s 54us/step - loss: 5.9062 - acc: 0.6310\n",
      "Epoch 34/40\n",
      "691/691 [==============================] - 0s 60us/step - loss: 5.9062 - acc: 0.6310\n",
      "Epoch 35/40\n",
      "691/691 [==============================] - 0s 54us/step - loss: 5.9059 - acc: 0.6310\n",
      "Epoch 36/40\n",
      "691/691 [==============================] - 0s 54us/step - loss: 5.9058 - acc: 0.6310\n",
      "Epoch 37/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 5.9058 - acc: 0.6310\n",
      "Epoch 38/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 5.9057 - acc: 0.6310\n",
      "Epoch 39/40\n",
      "691/691 [==============================] - 0s 53us/step - loss: 5.9056 - acc: 0.6310\n",
      "Epoch 40/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 5.9054 - acc: 0.6310\n",
      "77/77 [==============================] - 1s 17ms/step\n",
      "Epoch 1/40\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 5.5279 - acc: 0.6483\n",
      "Epoch 2/40\n",
      "691/691 [==============================] - 0s 62us/step - loss: 5.1535 - acc: 0.6483\n",
      "Epoch 3/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 4.2728 - acc: 0.6295\n",
      "Epoch 4/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 3.5692 - acc: 0.5253\n",
      "Epoch 5/40\n",
      "691/691 [==============================] - 0s 53us/step - loss: 2.6677 - acc: 0.5224\n",
      "Epoch 6/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 1.8743 - acc: 0.5456\n",
      "Epoch 7/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 1.4519 - acc: 0.5514\n",
      "Epoch 8/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 1.3037 - acc: 0.5861\n",
      "Epoch 9/40\n",
      "691/691 [==============================] - 0s 53us/step - loss: 1.1977 - acc: 0.5760\n",
      "Epoch 10/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 1.0920 - acc: 0.6339\n",
      "Epoch 11/40\n",
      "691/691 [==============================] - 0s 54us/step - loss: 1.0026 - acc: 0.6122\n",
      "Epoch 12/40\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.9442 - acc: 0.6179\n",
      "Epoch 13/40\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.8990 - acc: 0.6411\n",
      "Epoch 14/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.8641 - acc: 0.6469\n",
      "Epoch 15/40\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.8672 - acc: 0.6179\n",
      "Epoch 16/40\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.8031 - acc: 0.6614\n",
      "Epoch 17/40\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.8154 - acc: 0.6353\n",
      "Epoch 18/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.7672 - acc: 0.6643\n",
      "Epoch 19/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.7473 - acc: 0.6628\n",
      "Epoch 20/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 0.7433 - acc: 0.6715\n",
      "Epoch 21/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.7309 - acc: 0.6657\n",
      "Epoch 22/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 0.7141 - acc: 0.6744\n",
      "Epoch 23/40\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.7092 - acc: 0.6831\n",
      "Epoch 24/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 0.7208 - acc: 0.6715\n",
      "Epoch 25/40\n",
      "691/691 [==============================] - 0s 63us/step - loss: 0.7088 - acc: 0.6773\n",
      "Epoch 26/40\n",
      "691/691 [==============================] - 0s 61us/step - loss: 0.6984 - acc: 0.6700\n",
      "Epoch 27/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.6852 - acc: 0.6860\n",
      "Epoch 28/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.6680 - acc: 0.6860\n",
      "Epoch 29/40\n",
      "691/691 [==============================] - 0s 63us/step - loss: 0.6729 - acc: 0.6802\n",
      "Epoch 30/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 0.6772 - acc: 0.6744\n",
      "Epoch 31/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.6681 - acc: 0.6831\n",
      "Epoch 32/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.6469 - acc: 0.6946\n",
      "Epoch 33/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.6514 - acc: 0.6946\n",
      "Epoch 34/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.6388 - acc: 0.6918\n",
      "Epoch 35/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.6386 - acc: 0.6918\n",
      "Epoch 36/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.6334 - acc: 0.6990\n",
      "Epoch 37/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.6335 - acc: 0.7033\n",
      "Epoch 38/40\n",
      "691/691 [==============================] - 0s 65us/step - loss: 0.6263 - acc: 0.6903\n",
      "Epoch 39/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.6218 - acc: 0.6990\n",
      "Epoch 40/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.6161 - acc: 0.7019\n",
      "77/77 [==============================] - 1s 18ms/step\n",
      "Epoch 1/40\n",
      "692/692 [==============================] - 3s 5ms/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 2/40\n",
      "692/692 [==============================] - 0s 65us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 3/40\n",
      "692/692 [==============================] - 0s 60us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 4/40\n",
      "692/692 [==============================] - 0s 53us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 5/40\n",
      "692/692 [==============================] - 0s 56us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 6/40\n",
      "692/692 [==============================] - 0s 57us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 7/40\n",
      "692/692 [==============================] - 0s 56us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 8/40\n",
      "692/692 [==============================] - 0s 56us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 9/40\n",
      "692/692 [==============================] - 0s 59us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 10/40\n",
      "692/692 [==============================] - 0s 57us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 11/40\n",
      "692/692 [==============================] - 0s 56us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 12/40\n",
      "692/692 [==============================] - 0s 57us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 13/40\n",
      "692/692 [==============================] - 0s 64us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 14/40\n",
      "692/692 [==============================] - 0s 57us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 15/40\n",
      "692/692 [==============================] - 0s 57us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 16/40\n",
      "692/692 [==============================] - 0s 57us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 17/40\n",
      "692/692 [==============================] - 0s 58us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 18/40\n",
      "692/692 [==============================] - 0s 62us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 19/40\n",
      "692/692 [==============================] - 0s 58us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 20/40\n",
      "692/692 [==============================] - 0s 58us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 21/40\n",
      "692/692 [==============================] - 0s 62us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 22/40\n",
      "692/692 [==============================] - 0s 56us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 23/40\n",
      "692/692 [==============================] - 0s 56us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 24/40\n",
      "692/692 [==============================] - 0s 55us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 25/40\n",
      "692/692 [==============================] - 0s 58us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 26/40\n",
      "692/692 [==============================] - 0s 63us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 27/40\n",
      "692/692 [==============================] - 0s 60us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 28/40\n",
      "692/692 [==============================] - 0s 56us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 29/40\n",
      "692/692 [==============================] - 0s 55us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 30/40\n",
      "692/692 [==============================] - 0s 55us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 31/40\n",
      "692/692 [==============================] - 0s 59us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 32/40\n",
      "692/692 [==============================] - 0s 56us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 33/40\n",
      "692/692 [==============================] - 0s 57us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 34/40\n",
      "692/692 [==============================] - 0s 56us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 35/40\n",
      "692/692 [==============================] - 0s 57us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 36/40\n",
      "692/692 [==============================] - 0s 61us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 37/40\n",
      "692/692 [==============================] - 0s 57us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 38/40\n",
      "692/692 [==============================] - 0s 55us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 39/40\n",
      "692/692 [==============================] - 0s 57us/step - loss: 5.6833 - acc: 0.6474\n",
      "Epoch 40/40\n",
      "692/692 [==============================] - 0s 55us/step - loss: 5.6833 - acc: 0.6474\n",
      "76/76 [==============================] - 1s 18ms/step\n",
      "Epoch 1/40\n",
      "692/692 [==============================] - 3s 5ms/step - loss: 10.3953 - acc: 0.3454\n",
      "Epoch 2/40\n",
      "692/692 [==============================] - 0s 62us/step - loss: 10.3936 - acc: 0.3454\n",
      "Epoch 3/40\n",
      "692/692 [==============================] - 0s 60us/step - loss: 10.3937 - acc: 0.3468\n",
      "Epoch 4/40\n",
      "692/692 [==============================] - 0s 55us/step - loss: 10.3932 - acc: 0.3483\n",
      "Epoch 5/40\n",
      "692/692 [==============================] - 0s 57us/step - loss: 10.3930 - acc: 0.3483\n",
      "Epoch 6/40\n",
      "692/692 [==============================] - 0s 57us/step - loss: 10.3929 - acc: 0.3468\n",
      "Epoch 7/40\n",
      "692/692 [==============================] - 0s 57us/step - loss: 10.3927 - acc: 0.3468\n",
      "Epoch 8/40\n",
      "692/692 [==============================] - 0s 53us/step - loss: 10.3928 - acc: 0.3468\n",
      "Epoch 9/40\n",
      "692/692 [==============================] - 0s 57us/step - loss: 10.3926 - acc: 0.3468\n",
      "Epoch 10/40\n",
      "692/692 [==============================] - 0s 56us/step - loss: 10.3924 - acc: 0.3468\n",
      "Epoch 11/40\n",
      "692/692 [==============================] - 0s 59us/step - loss: 10.3927 - acc: 0.3468\n",
      "Epoch 12/40\n",
      "692/692 [==============================] - 0s 57us/step - loss: 10.3925 - acc: 0.3468\n",
      "Epoch 13/40\n",
      "692/692 [==============================] - 0s 59us/step - loss: 10.3924 - acc: 0.3468\n",
      "Epoch 14/40\n",
      "692/692 [==============================] - 0s 59us/step - loss: 10.3925 - acc: 0.3468\n",
      "Epoch 15/40\n",
      "692/692 [==============================] - 0s 54us/step - loss: 10.3924 - acc: 0.3483\n",
      "Epoch 16/40\n",
      "692/692 [==============================] - 0s 55us/step - loss: 10.3922 - acc: 0.3483\n",
      "Epoch 17/40\n",
      "692/692 [==============================] - 0s 56us/step - loss: 10.3923 - acc: 0.3468\n",
      "Epoch 18/40\n",
      "692/692 [==============================] - 0s 55us/step - loss: 10.3924 - acc: 0.3468\n",
      "Epoch 19/40\n",
      "692/692 [==============================] - 0s 59us/step - loss: 10.3925 - acc: 0.3468\n",
      "Epoch 20/40\n",
      "692/692 [==============================] - 0s 60us/step - loss: 10.3923 - acc: 0.3468\n",
      "Epoch 21/40\n",
      "692/692 [==============================] - 0s 59us/step - loss: 10.3927 - acc: 0.3468\n",
      "Epoch 22/40\n",
      "692/692 [==============================] - 0s 51us/step - loss: 10.3924 - acc: 0.3468\n",
      "Epoch 23/40\n",
      "692/692 [==============================] - 0s 54us/step - loss: 10.3922 - acc: 0.3468\n",
      "Epoch 24/40\n",
      "692/692 [==============================] - 0s 56us/step - loss: 10.3921 - acc: 0.3468\n",
      "Epoch 25/40\n",
      "692/692 [==============================] - 0s 59us/step - loss: 10.3922 - acc: 0.3468\n",
      "Epoch 26/40\n",
      "692/692 [==============================] - 0s 57us/step - loss: 10.3922 - acc: 0.3468\n",
      "Epoch 27/40\n",
      "692/692 [==============================] - 0s 55us/step - loss: 10.3922 - acc: 0.3468\n",
      "Epoch 28/40\n",
      "692/692 [==============================] - 0s 58us/step - loss: 10.3920 - acc: 0.3468\n",
      "Epoch 29/40\n",
      "692/692 [==============================] - 0s 53us/step - loss: 10.3923 - acc: 0.3468\n",
      "Epoch 30/40\n",
      "692/692 [==============================] - 0s 58us/step - loss: 10.3921 - acc: 0.3468\n",
      "Epoch 31/40\n",
      "692/692 [==============================] - 0s 54us/step - loss: 10.3921 - acc: 0.3468\n",
      "Epoch 32/40\n",
      "692/692 [==============================] - 0s 57us/step - loss: 10.3921 - acc: 0.3468\n",
      "Epoch 33/40\n",
      "692/692 [==============================] - 0s 57us/step - loss: 10.3920 - acc: 0.3468\n",
      "Epoch 34/40\n",
      "692/692 [==============================] - 0s 55us/step - loss: 10.3920 - acc: 0.3483\n",
      "Epoch 35/40\n",
      "692/692 [==============================] - 0s 59us/step - loss: 10.3920 - acc: 0.3483\n",
      "Epoch 36/40\n",
      "692/692 [==============================] - 0s 58us/step - loss: 10.3921 - acc: 0.3468\n",
      "Epoch 37/40\n",
      "692/692 [==============================] - 0s 59us/step - loss: 10.3920 - acc: 0.3468\n",
      "Epoch 38/40\n",
      "692/692 [==============================] - 0s 57us/step - loss: 10.3920 - acc: 0.3468\n",
      "Epoch 39/40\n",
      "692/692 [==============================] - 0s 54us/step - loss: 10.3921 - acc: 0.3468\n",
      "Epoch 40/40\n",
      "692/692 [==============================] - 0s 59us/step - loss: 10.3920 - acc: 0.3483\n",
      "76/76 [==============================] - 1s 18ms/step\n",
      "Epoch 1/60\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 10.2110 - acc: 0.3415\n",
      "Epoch 2/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 9.4085 - acc: 0.3444\n",
      "Epoch 3/60\n",
      "691/691 [==============================] - 0s 63us/step - loss: 7.6273 - acc: 0.3763\n",
      "Epoch 4/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 5.6370 - acc: 0.4573\n",
      "Epoch 5/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 3.6731 - acc: 0.5673\n",
      "Epoch 6/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 2.9613 - acc: 0.6599\n",
      "Epoch 7/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 2.4132 - acc: 0.6411\n",
      "Epoch 8/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 2.1197 - acc: 0.6237\n",
      "Epoch 9/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 1.9736 - acc: 0.6368\n",
      "Epoch 10/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 1.8854 - acc: 0.6368\n",
      "Epoch 11/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 1.7993 - acc: 0.6498\n",
      "Epoch 12/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 1.7317 - acc: 0.6498\n",
      "Epoch 13/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 1.6194 - acc: 0.6643\n",
      "Epoch 14/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 1.5478 - acc: 0.6657\n",
      "Epoch 15/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 1.4717 - acc: 0.6874\n",
      "Epoch 16/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 1.3894 - acc: 0.6657\n",
      "Epoch 17/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 1.3191 - acc: 0.6845\n",
      "Epoch 18/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 1.2463 - acc: 0.6744\n",
      "Epoch 19/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 1.1971 - acc: 0.6758\n",
      "Epoch 20/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 1.1491 - acc: 0.6700\n",
      "Epoch 21/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 1.1171 - acc: 0.6628\n",
      "Epoch 22/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 1.0735 - acc: 0.6773\n",
      "Epoch 23/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 1.0500 - acc: 0.6614\n",
      "Epoch 24/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 1.0163 - acc: 0.6686\n",
      "Epoch 25/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.9744 - acc: 0.6483\n",
      "Epoch 26/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.9493 - acc: 0.6628\n",
      "Epoch 27/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 0.9246 - acc: 0.6816\n",
      "Epoch 28/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 0.9040 - acc: 0.6744\n",
      "Epoch 29/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 0.8862 - acc: 0.6744\n",
      "Epoch 30/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 0.8514 - acc: 0.6729\n",
      "Epoch 31/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 0.8516 - acc: 0.6860\n",
      "Epoch 32/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 0.8208 - acc: 0.6787\n",
      "Epoch 33/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 0.8063 - acc: 0.6816\n",
      "Epoch 34/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.8136 - acc: 0.6657\n",
      "Epoch 35/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 0.7848 - acc: 0.6758\n",
      "Epoch 36/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.7700 - acc: 0.6816\n",
      "Epoch 37/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 0.7544 - acc: 0.6860\n",
      "Epoch 38/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.7462 - acc: 0.6932\n",
      "Epoch 39/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.7588 - acc: 0.6961\n",
      "Epoch 40/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 0.7367 - acc: 0.6787\n",
      "Epoch 41/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.7214 - acc: 0.6845\n",
      "Epoch 42/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.7134 - acc: 0.6874\n",
      "Epoch 43/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.7100 - acc: 0.6831\n",
      "Epoch 44/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.7048 - acc: 0.6874\n",
      "Epoch 45/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 0.6934 - acc: 0.6874\n",
      "Epoch 46/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 0.6944 - acc: 0.6946\n",
      "Epoch 47/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.6968 - acc: 0.6946\n",
      "Epoch 48/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 0.7107 - acc: 0.6874\n",
      "Epoch 49/60\n",
      "691/691 [==============================] - 0s 63us/step - loss: 0.6898 - acc: 0.6845\n",
      "Epoch 50/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.6750 - acc: 0.7048\n",
      "Epoch 51/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.6726 - acc: 0.7091\n",
      "Epoch 52/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.6887 - acc: 0.6874\n",
      "Epoch 53/60\n",
      "691/691 [==============================] - 0s 64us/step - loss: 0.7030 - acc: 0.6700\n",
      "Epoch 54/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 0.6869 - acc: 0.6802\n",
      "Epoch 55/60\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.6636 - acc: 0.7106\n",
      "Epoch 56/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 0.6568 - acc: 0.7091\n",
      "Epoch 57/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.6627 - acc: 0.7091\n",
      "Epoch 58/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 0.6636 - acc: 0.7077\n",
      "Epoch 59/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.6840 - acc: 0.7033\n",
      "Epoch 60/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.6938 - acc: 0.7019\n",
      "77/77 [==============================] - 1s 18ms/step\n",
      "Epoch 1/60\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 8.8583 - acc: 0.3647\n",
      "Epoch 2/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 6.8270 - acc: 0.4588\n",
      "Epoch 3/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 6.0914 - acc: 0.5137\n",
      "Epoch 4/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 5.3587 - acc: 0.5369\n",
      "Epoch 5/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 3.8326 - acc: 0.5774\n",
      "Epoch 6/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 2.9734 - acc: 0.6237\n",
      "Epoch 7/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 2.7991 - acc: 0.6411\n",
      "Epoch 8/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 2.6595 - acc: 0.6252\n",
      "Epoch 9/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 2.5637 - acc: 0.6324\n",
      "Epoch 10/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 2.4828 - acc: 0.6368\n",
      "Epoch 11/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 2.4074 - acc: 0.6382\n",
      "Epoch 12/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 2.3271 - acc: 0.6469\n",
      "Epoch 13/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 2.2517 - acc: 0.6498\n",
      "Epoch 14/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 2.1765 - acc: 0.6440\n",
      "Epoch 15/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 2.0834 - acc: 0.6527\n",
      "Epoch 16/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 2.0161 - acc: 0.6585\n",
      "Epoch 17/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 1.9348 - acc: 0.6498\n",
      "Epoch 18/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 1.8307 - acc: 0.6599\n",
      "Epoch 19/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 1.7573 - acc: 0.6541\n",
      "Epoch 20/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 1.6775 - acc: 0.6556\n",
      "Epoch 21/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 1.6173 - acc: 0.6729\n",
      "Epoch 22/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 1.5532 - acc: 0.6556\n",
      "Epoch 23/60\n",
      "691/691 [==============================] - 0s 63us/step - loss: 1.4995 - acc: 0.6570\n",
      "Epoch 24/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 1.4583 - acc: 0.6657\n",
      "Epoch 25/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 1.4217 - acc: 0.6382\n",
      "Epoch 26/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 1.4260 - acc: 0.6700\n",
      "Epoch 27/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 1.3202 - acc: 0.6310\n",
      "Epoch 28/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 1.2822 - acc: 0.6700\n",
      "Epoch 29/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 1.2106 - acc: 0.6483\n",
      "Epoch 30/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 1.1723 - acc: 0.6686\n",
      "Epoch 31/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 1.1339 - acc: 0.6585\n",
      "Epoch 32/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 1.0994 - acc: 0.6469\n",
      "Epoch 33/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 1.0528 - acc: 0.6541\n",
      "Epoch 34/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 1.0059 - acc: 0.6527\n",
      "Epoch 35/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.9818 - acc: 0.6628\n",
      "Epoch 36/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 0.9562 - acc: 0.6541\n",
      "Epoch 37/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.9303 - acc: 0.6628\n",
      "Epoch 38/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.9074 - acc: 0.6599\n",
      "Epoch 39/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 0.8899 - acc: 0.6614\n",
      "Epoch 40/60\n",
      "691/691 [==============================] - 0s 63us/step - loss: 0.8726 - acc: 0.6700\n",
      "Epoch 41/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 0.8534 - acc: 0.6758\n",
      "Epoch 42/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 0.8400 - acc: 0.6729\n",
      "Epoch 43/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 0.8319 - acc: 0.6831\n",
      "Epoch 44/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.8227 - acc: 0.6729\n",
      "Epoch 45/60\n",
      "691/691 [==============================] - 0s 64us/step - loss: 0.8095 - acc: 0.6570\n",
      "Epoch 46/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 0.8002 - acc: 0.6628\n",
      "Epoch 47/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 0.7789 - acc: 0.6831\n",
      "Epoch 48/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.7690 - acc: 0.6715\n",
      "Epoch 49/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.7582 - acc: 0.6831\n",
      "Epoch 50/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 0.7665 - acc: 0.6758\n",
      "Epoch 51/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.7410 - acc: 0.6831\n",
      "Epoch 52/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.7406 - acc: 0.6715\n",
      "Epoch 53/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 0.7272 - acc: 0.6845\n",
      "Epoch 54/60\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.7127 - acc: 0.6990\n",
      "Epoch 55/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.7167 - acc: 0.6889\n",
      "Epoch 56/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 0.7093 - acc: 0.6889\n",
      "Epoch 57/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.6981 - acc: 0.6874\n",
      "Epoch 58/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.6891 - acc: 0.6831\n",
      "Epoch 59/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 0.6831 - acc: 0.6860\n",
      "Epoch 60/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 0.6813 - acc: 0.7004\n",
      "77/77 [==============================] - 1s 19ms/step\n",
      "Epoch 1/60\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 6.5542 - acc: 0.3980\n",
      "Epoch 2/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 3.4555 - acc: 0.5673\n",
      "Epoch 3/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 3.0501 - acc: 0.6324\n",
      "Epoch 4/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 2.3214 - acc: 0.5731\n",
      "Epoch 5/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 2.0176 - acc: 0.5789\n",
      "Epoch 6/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 1.8546 - acc: 0.5962\n",
      "Epoch 7/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 1.7633 - acc: 0.5745\n",
      "Epoch 8/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 1.6644 - acc: 0.5904\n",
      "Epoch 9/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 1.5728 - acc: 0.5933\n",
      "Epoch 10/60\n",
      "691/691 [==============================] - 0s 64us/step - loss: 1.4774 - acc: 0.5818\n",
      "Epoch 11/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 1.4185 - acc: 0.5991\n",
      "Epoch 12/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 1.3545 - acc: 0.5789\n",
      "Epoch 13/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 1.2878 - acc: 0.6223\n",
      "Epoch 14/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 1.2159 - acc: 0.5832\n",
      "Epoch 15/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 1.1677 - acc: 0.6107\n",
      "Epoch 16/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 1.1096 - acc: 0.5962\n",
      "Epoch 17/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 1.0605 - acc: 0.5890\n",
      "Epoch 18/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 1.0200 - acc: 0.6136\n",
      "Epoch 19/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.9840 - acc: 0.6151\n",
      "Epoch 20/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 0.9433 - acc: 0.6194\n",
      "Epoch 21/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 0.9332 - acc: 0.6208\n",
      "Epoch 22/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.8988 - acc: 0.6324\n",
      "Epoch 23/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.8959 - acc: 0.6252\n",
      "Epoch 24/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 0.8722 - acc: 0.6469\n",
      "Epoch 25/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.8509 - acc: 0.6440\n",
      "Epoch 26/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 0.8409 - acc: 0.6483\n",
      "Epoch 27/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.8277 - acc: 0.6541\n",
      "Epoch 28/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 0.8282 - acc: 0.6498\n",
      "Epoch 29/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 0.8102 - acc: 0.6483\n",
      "Epoch 30/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.7993 - acc: 0.6585\n",
      "Epoch 31/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 0.7926 - acc: 0.6628\n",
      "Epoch 32/60\n",
      "691/691 [==============================] - ETA: 0s - loss: 0.8208 - acc: 0.716 - 0s 61us/step - loss: 0.7919 - acc: 0.6628\n",
      "Epoch 33/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.7832 - acc: 0.6527\n",
      "Epoch 34/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 0.7690 - acc: 0.6614\n",
      "Epoch 35/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.7769 - acc: 0.6454\n",
      "Epoch 36/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.7765 - acc: 0.6585\n",
      "Epoch 37/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 0.7694 - acc: 0.6599\n",
      "Epoch 38/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 0.7800 - acc: 0.6512\n",
      "Epoch 39/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 0.7493 - acc: 0.6686\n",
      "Epoch 40/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 0.7565 - acc: 0.6671\n",
      "Epoch 41/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.7498 - acc: 0.6729\n",
      "Epoch 42/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 0.7393 - acc: 0.6671\n",
      "Epoch 43/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.7238 - acc: 0.6729\n",
      "Epoch 44/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.7286 - acc: 0.6686\n",
      "Epoch 45/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.7268 - acc: 0.6671\n",
      "Epoch 46/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.7165 - acc: 0.6671\n",
      "Epoch 47/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.7240 - acc: 0.6831\n",
      "Epoch 48/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 0.7071 - acc: 0.6729\n",
      "Epoch 49/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.7046 - acc: 0.6744\n",
      "Epoch 50/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 0.7088 - acc: 0.6700\n",
      "Epoch 51/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.6903 - acc: 0.6860\n",
      "Epoch 52/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.6841 - acc: 0.6845\n",
      "Epoch 53/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 0.6905 - acc: 0.6831\n",
      "Epoch 54/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.7017 - acc: 0.6816\n",
      "Epoch 55/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 0.7334 - acc: 0.6628\n",
      "Epoch 56/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 0.7147 - acc: 0.6831\n",
      "Epoch 57/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.6902 - acc: 0.6773\n",
      "Epoch 58/60\n",
      "691/691 [==============================] - 0s 63us/step - loss: 0.6833 - acc: 0.6845\n",
      "Epoch 59/60\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.6790 - acc: 0.6932\n",
      "Epoch 60/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 0.6892 - acc: 0.6845\n",
      "77/77 [==============================] - 1s 18ms/step\n",
      "Epoch 1/60\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 4.7289 - acc: 0.5673\n",
      "Epoch 2/60\n",
      "691/691 [==============================] - 0s 64us/step - loss: 4.5194 - acc: 0.5658\n",
      "Epoch 3/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 4.3215 - acc: 0.5847\n",
      "Epoch 4/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 4.1829 - acc: 0.5760\n",
      "Epoch 5/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 4.0421 - acc: 0.5832\n",
      "Epoch 6/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 3.9388 - acc: 0.5890\n",
      "Epoch 7/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 3.8491 - acc: 0.5933\n",
      "Epoch 8/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 3.7834 - acc: 0.5933\n",
      "Epoch 9/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 3.7147 - acc: 0.6006\n",
      "Epoch 10/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 3.6171 - acc: 0.5962\n",
      "Epoch 11/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 3.4830 - acc: 0.5890\n",
      "Epoch 12/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 3.0776 - acc: 0.5803\n",
      "Epoch 13/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 2.5607 - acc: 0.5210\n",
      "Epoch 14/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 2.2463 - acc: 0.5832\n",
      "Epoch 15/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 2.0311 - acc: 0.5658\n",
      "Epoch 16/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 1.9172 - acc: 0.5687\n",
      "Epoch 17/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 1.7887 - acc: 0.6020\n",
      "Epoch 18/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 1.5539 - acc: 0.6064\n",
      "Epoch 19/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 1.4420 - acc: 0.5991\n",
      "Epoch 20/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 1.3692 - acc: 0.6310\n",
      "Epoch 21/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 1.2828 - acc: 0.6223\n",
      "Epoch 22/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 1.2067 - acc: 0.6324\n",
      "Epoch 23/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 1.1387 - acc: 0.6281\n",
      "Epoch 24/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 1.0931 - acc: 0.6397\n",
      "Epoch 25/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 1.0383 - acc: 0.6483\n",
      "Epoch 26/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 1.0034 - acc: 0.6527\n",
      "Epoch 27/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 0.9676 - acc: 0.6628\n",
      "Epoch 28/60\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.9368 - acc: 0.6614\n",
      "Epoch 29/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.9101 - acc: 0.6527\n",
      "Epoch 30/60\n",
      "691/691 [==============================] - 0s 64us/step - loss: 0.8801 - acc: 0.6744\n",
      "Epoch 31/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.8064 - acc: 0.6802\n",
      "Epoch 32/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 0.7498 - acc: 0.6773\n",
      "Epoch 33/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.6647 - acc: 0.6932\n",
      "Epoch 34/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 0.6253 - acc: 0.6874\n",
      "Epoch 35/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 0.6280 - acc: 0.7004\n",
      "Epoch 36/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.6101 - acc: 0.6946\n",
      "Epoch 37/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 0.6209 - acc: 0.6845\n",
      "Epoch 38/60\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.5876 - acc: 0.7149\n",
      "Epoch 39/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 0.5890 - acc: 0.6990\n",
      "Epoch 40/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.5960 - acc: 0.7004\n",
      "Epoch 41/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 0.5831 - acc: 0.7062\n",
      "Epoch 42/60\n",
      "691/691 [==============================] - 0s 64us/step - loss: 0.5751 - acc: 0.7120\n",
      "Epoch 43/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.5763 - acc: 0.7019\n",
      "Epoch 44/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 0.5762 - acc: 0.7048\n",
      "Epoch 45/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.5744 - acc: 0.7091\n",
      "Epoch 46/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.5831 - acc: 0.6961\n",
      "Epoch 47/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 0.5681 - acc: 0.7192\n",
      "Epoch 48/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.5683 - acc: 0.7149\n",
      "Epoch 49/60\n",
      "691/691 [==============================] - 0s 68us/step - loss: 0.5708 - acc: 0.7207\n",
      "Epoch 50/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.5732 - acc: 0.7091\n",
      "Epoch 51/60\n",
      "691/691 [==============================] - 0s 64us/step - loss: 0.5803 - acc: 0.7004\n",
      "Epoch 52/60\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.5825 - acc: 0.7062\n",
      "Epoch 53/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.5684 - acc: 0.7077\n",
      "Epoch 54/60\n",
      "691/691 [==============================] - 0s 63us/step - loss: 0.5705 - acc: 0.7164\n",
      "Epoch 55/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.5589 - acc: 0.7135\n",
      "Epoch 56/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.5807 - acc: 0.7192\n",
      "Epoch 57/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.5833 - acc: 0.7135\n",
      "Epoch 58/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 0.6008 - acc: 0.6961\n",
      "Epoch 59/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.5656 - acc: 0.7149\n",
      "Epoch 60/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.5616 - acc: 0.7207\n",
      "77/77 [==============================] - 1s 19ms/step\n",
      "Epoch 1/60\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 5.3550 - acc: 0.6469\n",
      "Epoch 2/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 5.2823 - acc: 0.6411\n",
      "Epoch 3/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 5.1552 - acc: 0.6368\n",
      "Epoch 4/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 5.0760 - acc: 0.6382\n",
      "Epoch 5/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 5.0388 - acc: 0.6411\n",
      "Epoch 6/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 5.0050 - acc: 0.6498\n",
      "Epoch 7/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 5.0006 - acc: 0.6469\n",
      "Epoch 8/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 4.9778 - acc: 0.6498\n",
      "Epoch 9/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 4.9683 - acc: 0.6498\n",
      "Epoch 10/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 4.9680 - acc: 0.6512\n",
      "Epoch 11/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 4.9589 - acc: 0.6498\n",
      "Epoch 12/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 4.9623 - acc: 0.6483\n",
      "Epoch 13/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 4.9710 - acc: 0.6556\n",
      "Epoch 14/60\n",
      "691/691 [==============================] - ETA: 0s - loss: 4.7574 - acc: 0.650 - 0s 60us/step - loss: 4.9591 - acc: 0.6454\n",
      "Epoch 15/60\n",
      "691/691 [==============================] - 0s 63us/step - loss: 4.9588 - acc: 0.6469\n",
      "Epoch 16/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 4.9325 - acc: 0.6527\n",
      "Epoch 17/60\n",
      "691/691 [==============================] - 0s 63us/step - loss: 4.9300 - acc: 0.6498\n",
      "Epoch 18/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 4.9204 - acc: 0.6483\n",
      "Epoch 19/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 4.9184 - acc: 0.6454\n",
      "Epoch 20/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 4.9093 - acc: 0.6440\n",
      "Epoch 21/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 4.9116 - acc: 0.6527\n",
      "Epoch 22/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 4.9156 - acc: 0.6483\n",
      "Epoch 23/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 4.9079 - acc: 0.6512\n",
      "Epoch 24/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 4.9226 - acc: 0.6469\n",
      "Epoch 25/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 4.8832 - acc: 0.6498\n",
      "Epoch 26/60\n",
      "691/691 [==============================] - 0s 63us/step - loss: 4.8829 - acc: 0.6483\n",
      "Epoch 27/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 4.8749 - acc: 0.6527\n",
      "Epoch 28/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 4.8708 - acc: 0.6527\n",
      "Epoch 29/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 4.8616 - acc: 0.6498\n",
      "Epoch 30/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 4.8668 - acc: 0.6469\n",
      "Epoch 31/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 4.8415 - acc: 0.6498\n",
      "Epoch 32/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 4.8362 - acc: 0.6512\n",
      "Epoch 33/60\n",
      "691/691 [==============================] - 0s 63us/step - loss: 4.8366 - acc: 0.6483\n",
      "Epoch 34/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 4.8196 - acc: 0.6498\n",
      "Epoch 35/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 4.8125 - acc: 0.6483\n",
      "Epoch 36/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 4.8100 - acc: 0.6483\n",
      "Epoch 37/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 4.7905 - acc: 0.6498\n",
      "Epoch 38/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 4.7759 - acc: 0.6527\n",
      "Epoch 39/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 4.7776 - acc: 0.6512\n",
      "Epoch 40/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 4.7537 - acc: 0.6498\n",
      "Epoch 41/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 4.7201 - acc: 0.6527\n",
      "Epoch 42/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 4.6886 - acc: 0.6527\n",
      "Epoch 43/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 4.6927 - acc: 0.6454\n",
      "Epoch 44/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 4.6554 - acc: 0.6570\n",
      "Epoch 45/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 4.6314 - acc: 0.6512\n",
      "Epoch 46/60\n",
      "691/691 [==============================] - 0s 63us/step - loss: 4.6068 - acc: 0.6498\n",
      "Epoch 47/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 4.5785 - acc: 0.6541\n",
      "Epoch 48/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 4.5670 - acc: 0.6512\n",
      "Epoch 49/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 4.5885 - acc: 0.6440\n",
      "Epoch 50/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 4.4772 - acc: 0.6440\n",
      "Epoch 51/60\n",
      "691/691 [==============================] - 0s 67us/step - loss: 4.4108 - acc: 0.6440\n",
      "Epoch 52/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 4.3257 - acc: 0.6469\n",
      "Epoch 53/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 4.2276 - acc: 0.6440\n",
      "Epoch 54/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 3.9778 - acc: 0.6469\n",
      "Epoch 55/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 3.5528 - acc: 0.6425\n",
      "Epoch 56/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 2.9774 - acc: 0.6556\n",
      "Epoch 57/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 2.4152 - acc: 0.6570\n",
      "Epoch 58/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 2.1574 - acc: 0.6469\n",
      "Epoch 59/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 1.9599 - acc: 0.6657\n",
      "Epoch 60/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 1.7715 - acc: 0.6816\n",
      "77/77 [==============================] - 1s 19ms/step\n",
      "Epoch 1/60\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 3.4165 - acc: 0.6237\n",
      "Epoch 2/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 3.2266 - acc: 0.6556\n",
      "Epoch 3/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 2.8406 - acc: 0.5615\n",
      "Epoch 4/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 2.3487 - acc: 0.6093\n",
      "Epoch 5/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 2.2536 - acc: 0.6136\n",
      "Epoch 6/60\n",
      "691/691 [==============================] - 0s 63us/step - loss: 2.2216 - acc: 0.6353\n",
      "Epoch 7/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 2.1194 - acc: 0.5861\n",
      "Epoch 8/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 2.0070 - acc: 0.6310\n",
      "Epoch 9/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 1.9415 - acc: 0.6194\n",
      "Epoch 10/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 1.8739 - acc: 0.6223\n",
      "Epoch 11/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 1.8271 - acc: 0.6223\n",
      "Epoch 12/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 1.7427 - acc: 0.6035\n",
      "Epoch 13/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 1.6695 - acc: 0.6237\n",
      "Epoch 14/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 1.6191 - acc: 0.6324\n",
      "Epoch 15/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 1.5816 - acc: 0.6252\n",
      "Epoch 16/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 1.5099 - acc: 0.6194\n",
      "Epoch 17/60\n",
      "691/691 [==============================] - 0s 64us/step - loss: 1.4914 - acc: 0.6310\n",
      "Epoch 18/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 1.4079 - acc: 0.6382\n",
      "Epoch 19/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 1.3655 - acc: 0.6194\n",
      "Epoch 20/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 1.3107 - acc: 0.6686\n",
      "Epoch 21/60\n",
      "691/691 [==============================] - 0s 63us/step - loss: 1.2392 - acc: 0.6368\n",
      "Epoch 22/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 1.2149 - acc: 0.6643\n",
      "Epoch 23/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 1.1889 - acc: 0.6512\n",
      "Epoch 24/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 1.1303 - acc: 0.6368\n",
      "Epoch 25/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 1.1018 - acc: 0.6483\n",
      "Epoch 26/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 1.0595 - acc: 0.6700\n",
      "Epoch 27/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 1.0515 - acc: 0.6440\n",
      "Epoch 28/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 1.0047 - acc: 0.6671\n",
      "Epoch 29/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.9892 - acc: 0.6715\n",
      "Epoch 30/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 0.9776 - acc: 0.6541\n",
      "Epoch 31/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.9587 - acc: 0.6599\n",
      "Epoch 32/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 0.9487 - acc: 0.6671\n",
      "Epoch 33/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.9702 - acc: 0.6628\n",
      "Epoch 34/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 0.9417 - acc: 0.6469\n",
      "Epoch 35/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.9311 - acc: 0.6614\n",
      "Epoch 36/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 0.9198 - acc: 0.6657\n",
      "Epoch 37/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.8976 - acc: 0.6599\n",
      "Epoch 38/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 0.8898 - acc: 0.6628\n",
      "Epoch 39/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.9147 - acc: 0.6556\n",
      "Epoch 40/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 0.8923 - acc: 0.6628\n",
      "Epoch 41/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.8922 - acc: 0.6498\n",
      "Epoch 42/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 0.8601 - acc: 0.6411\n",
      "Epoch 43/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.8649 - acc: 0.6657\n",
      "Epoch 44/60\n",
      "691/691 [==============================] - 0s 63us/step - loss: 0.8490 - acc: 0.6744\n",
      "Epoch 45/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.8551 - acc: 0.6512\n",
      "Epoch 46/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 0.8245 - acc: 0.6425\n",
      "Epoch 47/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.8290 - acc: 0.6599\n",
      "Epoch 48/60\n",
      "691/691 [==============================] - 0s 63us/step - loss: 0.8176 - acc: 0.6744\n",
      "Epoch 49/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.8039 - acc: 0.6628\n",
      "Epoch 50/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 0.8053 - acc: 0.6585\n",
      "Epoch 51/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.7909 - acc: 0.6758\n",
      "Epoch 52/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 0.7856 - acc: 0.6599\n",
      "Epoch 53/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.7801 - acc: 0.6773\n",
      "Epoch 54/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 0.7734 - acc: 0.6599\n",
      "Epoch 55/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.7831 - acc: 0.6599\n",
      "Epoch 56/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 0.7920 - acc: 0.6498\n",
      "Epoch 57/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.7763 - acc: 0.6541\n",
      "Epoch 58/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 0.7686 - acc: 0.6454\n",
      "Epoch 59/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.7474 - acc: 0.6700\n",
      "Epoch 60/60\n",
      "691/691 [==============================] - 0s 64us/step - loss: 0.7441 - acc: 0.6556\n",
      "77/77 [==============================] - 1s 19ms/step\n",
      "Epoch 1/60\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 5.8714 - acc: 0.6324\n",
      "Epoch 2/60\n",
      "691/691 [==============================] - 0s 65us/step - loss: 5.3324 - acc: 0.6324\n",
      "Epoch 3/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 3.4355 - acc: 0.5760\n",
      "Epoch 4/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 2.5899 - acc: 0.4805\n",
      "Epoch 5/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 2.0849 - acc: 0.5210\n",
      "Epoch 6/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 1.9249 - acc: 0.5239\n",
      "Epoch 7/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 1.8250 - acc: 0.5369\n",
      "Epoch 8/60\n",
      "691/691 [==============================] - 0s 63us/step - loss: 1.6145 - acc: 0.5355\n",
      "Epoch 9/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 1.5692 - acc: 0.5514\n",
      "Epoch 10/60\n",
      "691/691 [==============================] - 0s 63us/step - loss: 1.4738 - acc: 0.5658\n",
      "Epoch 11/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 1.4208 - acc: 0.5601\n",
      "Epoch 12/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 1.3545 - acc: 0.5557\n",
      "Epoch 13/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 1.3301 - acc: 0.5687\n",
      "Epoch 14/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 1.2714 - acc: 0.5586\n",
      "Epoch 15/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 1.2358 - acc: 0.5890\n",
      "Epoch 16/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 1.1803 - acc: 0.5630\n",
      "Epoch 17/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 1.1562 - acc: 0.5890\n",
      "Epoch 18/60\n",
      "691/691 [==============================] - 0s 66us/step - loss: 1.1147 - acc: 0.5774\n",
      "Epoch 19/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 1.1026 - acc: 0.5818\n",
      "Epoch 20/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 1.0462 - acc: 0.5933\n",
      "Epoch 21/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 1.0468 - acc: 0.5948\n",
      "Epoch 22/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 1.0166 - acc: 0.6006\n",
      "Epoch 23/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 0.9647 - acc: 0.6049\n",
      "Epoch 24/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 0.9415 - acc: 0.5962\n",
      "Epoch 25/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.9238 - acc: 0.6064\n",
      "Epoch 26/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 0.9019 - acc: 0.6064\n",
      "Epoch 27/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 0.8873 - acc: 0.6136\n",
      "Epoch 28/60\n",
      "691/691 [==============================] - 0s 63us/step - loss: 0.8650 - acc: 0.6078\n",
      "Epoch 29/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.8427 - acc: 0.6223\n",
      "Epoch 30/60\n",
      "691/691 [==============================] - 0s 65us/step - loss: 0.8240 - acc: 0.6223\n",
      "Epoch 31/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.8251 - acc: 0.6295\n",
      "Epoch 32/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 0.8040 - acc: 0.6237\n",
      "Epoch 33/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.7912 - acc: 0.6223\n",
      "Epoch 34/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 0.7669 - acc: 0.6223\n",
      "Epoch 35/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.7560 - acc: 0.6324\n",
      "Epoch 36/60\n",
      "691/691 [==============================] - 0s 63us/step - loss: 0.7502 - acc: 0.6368\n",
      "Epoch 37/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.7989 - acc: 0.6035\n",
      "Epoch 38/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 0.7321 - acc: 0.6382\n",
      "Epoch 39/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.7088 - acc: 0.6469\n",
      "Epoch 40/60\n",
      "691/691 [==============================] - 0s 65us/step - loss: 0.7004 - acc: 0.6266\n",
      "Epoch 41/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.7201 - acc: 0.6339\n",
      "Epoch 42/60\n",
      "691/691 [==============================] - 0s 64us/step - loss: 0.7160 - acc: 0.6310\n",
      "Epoch 43/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.6844 - acc: 0.6425\n",
      "Epoch 44/60\n",
      "691/691 [==============================] - 0s 63us/step - loss: 0.7150 - acc: 0.6179\n",
      "Epoch 45/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 0.6870 - acc: 0.6266\n",
      "Epoch 46/60\n",
      "691/691 [==============================] - 0s 63us/step - loss: 0.6715 - acc: 0.6469\n",
      "Epoch 47/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 0.6665 - acc: 0.6440\n",
      "Epoch 48/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 0.6667 - acc: 0.6469\n",
      "Epoch 49/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.6601 - acc: 0.6425\n",
      "Epoch 50/60\n",
      "691/691 [==============================] - 0s 65us/step - loss: 0.6570 - acc: 0.6498\n",
      "Epoch 51/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 0.6663 - acc: 0.6498\n",
      "Epoch 52/60\n",
      "691/691 [==============================] - 0s 65us/step - loss: 0.6617 - acc: 0.6411\n",
      "Epoch 53/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.6483 - acc: 0.6570\n",
      "Epoch 54/60\n",
      "691/691 [==============================] - 0s 63us/step - loss: 0.6452 - acc: 0.6454\n",
      "Epoch 55/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.6459 - acc: 0.6498\n",
      "Epoch 56/60\n",
      "691/691 [==============================] - 0s 64us/step - loss: 0.6618 - acc: 0.6541\n",
      "Epoch 57/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 0.6440 - acc: 0.6425\n",
      "Epoch 58/60\n",
      "691/691 [==============================] - 0s 63us/step - loss: 0.6396 - acc: 0.6368\n",
      "Epoch 59/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.6420 - acc: 0.6614\n",
      "Epoch 60/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 0.6360 - acc: 0.6397\n",
      "77/77 [==============================] - 2s 20ms/step\n",
      "Epoch 1/60\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 2/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 3/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 4/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 5/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 6/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 7/60\n",
      "691/691 [==============================] - 0s 64us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 8/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 9/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 10/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 11/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 12/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 13/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 14/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 15/60\n",
      "691/691 [==============================] - 0s 64us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 16/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 17/60\n",
      "691/691 [==============================] - 0s 63us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 18/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 19/60\n",
      "691/691 [==============================] - 0s 64us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 20/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 21/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 22/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 23/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 24/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 25/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 26/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 27/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 28/60\n",
      "691/691 [==============================] - 0s 66us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 29/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 30/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 31/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 32/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 33/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 34/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 35/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 36/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 37/60\n",
      "691/691 [==============================] - 0s 67us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 38/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 39/60\n",
      "691/691 [==============================] - 0s 68us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 40/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 41/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 42/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 43/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 44/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 45/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 46/60\n",
      "691/691 [==============================] - 0s 64us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 47/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 48/60\n",
      "691/691 [==============================] - 0s 63us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 49/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 50/60\n",
      "691/691 [==============================] - 0s 66us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 51/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 52/60\n",
      "691/691 [==============================] - 0s 64us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 53/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 54/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 55/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 56/60\n",
      "691/691 [==============================] - 0s 64us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 57/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 58/60\n",
      "691/691 [==============================] - 0s 64us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 59/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 5.6682 - acc: 0.6483\n",
      "Epoch 60/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 5.6682 - acc: 0.6483\n",
      "77/77 [==============================] - 1s 19ms/step\n",
      "Epoch 1/60\n",
      "692/692 [==============================] - 4s 5ms/step - loss: 7.1965 - acc: 0.3974\n",
      "Epoch 2/60\n",
      "692/692 [==============================] - 0s 56us/step - loss: 6.3978 - acc: 0.4118\n",
      "Epoch 3/60\n",
      "692/692 [==============================] - 0s 64us/step - loss: 5.8744 - acc: 0.4379\n",
      "Epoch 4/60\n",
      "692/692 [==============================] - 0s 56us/step - loss: 5.3387 - acc: 0.4610\n",
      "Epoch 5/60\n",
      "692/692 [==============================] - 0s 60us/step - loss: 4.5642 - acc: 0.4957\n",
      "Epoch 6/60\n",
      "692/692 [==============================] - 0s 58us/step - loss: 3.4208 - acc: 0.5361\n",
      "Epoch 7/60\n",
      "692/692 [==============================] - 0s 64us/step - loss: 2.7693 - acc: 0.5838\n",
      "Epoch 8/60\n",
      "692/692 [==============================] - 0s 56us/step - loss: 2.3008 - acc: 0.5491\n",
      "Epoch 9/60\n",
      "692/692 [==============================] - 0s 65us/step - loss: 2.1151 - acc: 0.5072\n",
      "Epoch 10/60\n",
      "692/692 [==============================] - 0s 57us/step - loss: 1.9715 - acc: 0.5376\n",
      "Epoch 11/60\n",
      "692/692 [==============================] - 0s 60us/step - loss: 1.8306 - acc: 0.5303\n",
      "Epoch 12/60\n",
      "692/692 [==============================] - 0s 53us/step - loss: 1.7311 - acc: 0.5376\n",
      "Epoch 13/60\n",
      "692/692 [==============================] - 0s 63us/step - loss: 1.6498 - acc: 0.5578\n",
      "Epoch 14/60\n",
      "692/692 [==============================] - 0s 55us/step - loss: 1.5932 - acc: 0.5477\n",
      "Epoch 15/60\n",
      "692/692 [==============================] - 0s 56us/step - loss: 1.5247 - acc: 0.5708\n",
      "Epoch 16/60\n",
      "692/692 [==============================] - 0s 62us/step - loss: 1.4627 - acc: 0.5390\n",
      "Epoch 17/60\n",
      "692/692 [==============================] - 0s 54us/step - loss: 1.4121 - acc: 0.5564\n",
      "Epoch 18/60\n",
      "692/692 [==============================] - 0s 59us/step - loss: 1.3627 - acc: 0.5853\n",
      "Epoch 19/60\n",
      "692/692 [==============================] - 0s 55us/step - loss: 1.3190 - acc: 0.5795\n",
      "Epoch 20/60\n",
      "692/692 [==============================] - 0s 65us/step - loss: 1.2780 - acc: 0.5939\n",
      "Epoch 21/60\n",
      "692/692 [==============================] - 0s 55us/step - loss: 1.2498 - acc: 0.5896\n",
      "Epoch 22/60\n",
      "692/692 [==============================] - 0s 60us/step - loss: 1.2101 - acc: 0.5838\n",
      "Epoch 23/60\n",
      "692/692 [==============================] - 0s 60us/step - loss: 1.1685 - acc: 0.5954\n",
      "Epoch 24/60\n",
      "692/692 [==============================] - 0s 53us/step - loss: 1.1507 - acc: 0.5679\n",
      "Epoch 25/60\n",
      "692/692 [==============================] - 0s 66us/step - loss: 1.1212 - acc: 0.6243\n",
      "Epoch 26/60\n",
      "692/692 [==============================] - 0s 54us/step - loss: 1.0762 - acc: 0.5983\n",
      "Epoch 27/60\n",
      "692/692 [==============================] - 0s 65us/step - loss: 1.0432 - acc: 0.6243\n",
      "Epoch 28/60\n",
      "692/692 [==============================] - 0s 54us/step - loss: 1.0289 - acc: 0.6156\n",
      "Epoch 29/60\n",
      "692/692 [==============================] - 0s 64us/step - loss: 0.9990 - acc: 0.6460\n",
      "Epoch 30/60\n",
      "692/692 [==============================] - 0s 55us/step - loss: 0.9821 - acc: 0.6228\n",
      "Epoch 31/60\n",
      "692/692 [==============================] - 0s 61us/step - loss: 0.9508 - acc: 0.6185\n",
      "Epoch 32/60\n",
      "692/692 [==============================] - 0s 59us/step - loss: 0.9286 - acc: 0.6416\n",
      "Epoch 33/60\n",
      "692/692 [==============================] - 0s 57us/step - loss: 0.9133 - acc: 0.6460\n",
      "Epoch 34/60\n",
      "692/692 [==============================] - 0s 64us/step - loss: 0.8914 - acc: 0.6460\n",
      "Epoch 35/60\n",
      "692/692 [==============================] - 0s 54us/step - loss: 0.8739 - acc: 0.6431\n",
      "Epoch 36/60\n",
      "692/692 [==============================] - 0s 61us/step - loss: 0.8480 - acc: 0.6488\n",
      "Epoch 37/60\n",
      "692/692 [==============================] - 0s 54us/step - loss: 0.8344 - acc: 0.6329\n",
      "Epoch 38/60\n",
      "692/692 [==============================] - 0s 61us/step - loss: 0.8311 - acc: 0.6662\n",
      "Epoch 39/60\n",
      "692/692 [==============================] - 0s 58us/step - loss: 0.8085 - acc: 0.6647\n",
      "Epoch 40/60\n",
      "692/692 [==============================] - 0s 56us/step - loss: 0.8026 - acc: 0.6590\n",
      "Epoch 41/60\n",
      "692/692 [==============================] - 0s 62us/step - loss: 0.7875 - acc: 0.6431\n",
      "Epoch 42/60\n",
      "692/692 [==============================] - 0s 53us/step - loss: 0.7756 - acc: 0.6792\n",
      "Epoch 43/60\n",
      "692/692 [==============================] - 0s 65us/step - loss: 0.7563 - acc: 0.6604\n",
      "Epoch 44/60\n",
      "692/692 [==============================] - 0s 53us/step - loss: 0.7442 - acc: 0.6864\n",
      "Epoch 45/60\n",
      "692/692 [==============================] - 0s 61us/step - loss: 0.7408 - acc: 0.6575\n",
      "Epoch 46/60\n",
      "692/692 [==============================] - 0s 57us/step - loss: 0.7544 - acc: 0.6965\n",
      "Epoch 47/60\n",
      "692/692 [==============================] - 0s 56us/step - loss: 0.7411 - acc: 0.6676\n",
      "Epoch 48/60\n",
      "692/692 [==============================] - 0s 62us/step - loss: 0.7166 - acc: 0.6777\n",
      "Epoch 49/60\n",
      "692/692 [==============================] - 0s 56us/step - loss: 0.7068 - acc: 0.6908\n",
      "Epoch 50/60\n",
      "692/692 [==============================] - 0s 66us/step - loss: 0.6952 - acc: 0.6965\n",
      "Epoch 51/60\n",
      "692/692 [==============================] - 0s 52us/step - loss: 0.6943 - acc: 0.6908\n",
      "Epoch 52/60\n",
      "692/692 [==============================] - 0s 62us/step - loss: 0.6868 - acc: 0.7038\n",
      "Epoch 53/60\n",
      "692/692 [==============================] - 0s 57us/step - loss: 0.6816 - acc: 0.6936\n",
      "Epoch 54/60\n",
      "692/692 [==============================] - 0s 60us/step - loss: 0.6721 - acc: 0.6951\n",
      "Epoch 55/60\n",
      "692/692 [==============================] - 0s 57us/step - loss: 0.6701 - acc: 0.6965\n",
      "Epoch 56/60\n",
      "692/692 [==============================] - 0s 58us/step - loss: 0.6645 - acc: 0.6965\n",
      "Epoch 57/60\n",
      "692/692 [==============================] - 0s 65us/step - loss: 0.6541 - acc: 0.6994\n",
      "Epoch 58/60\n",
      "692/692 [==============================] - 0s 56us/step - loss: 0.6555 - acc: 0.6994\n",
      "Epoch 59/60\n",
      "692/692 [==============================] - 0s 63us/step - loss: 0.6633 - acc: 0.6951\n",
      "Epoch 60/60\n",
      "692/692 [==============================] - 0s 55us/step - loss: 0.6525 - acc: 0.7110\n",
      "76/76 [==============================] - 2s 20ms/step\n",
      "Epoch 1/60\n",
      "692/692 [==============================] - 4s 5ms/step - loss: 5.1464 - acc: 0.6474\n",
      "Epoch 2/60\n",
      "692/692 [==============================] - 0s 54us/step - loss: 4.8034 - acc: 0.6460\n",
      "Epoch 3/60\n",
      "692/692 [==============================] - 0s 57us/step - loss: 4.0863 - acc: 0.6286\n",
      "Epoch 4/60\n",
      "692/692 [==============================] - 0s 56us/step - loss: 2.8793 - acc: 0.6156\n",
      "Epoch 5/60\n",
      "692/692 [==============================] - 0s 63us/step - loss: 2.3177 - acc: 0.5751\n",
      "Epoch 6/60\n",
      "692/692 [==============================] - 0s 54us/step - loss: 1.9852 - acc: 0.6012\n",
      "Epoch 7/60\n",
      "692/692 [==============================] - 0s 60us/step - loss: 1.8063 - acc: 0.6387\n",
      "Epoch 8/60\n",
      "692/692 [==============================] - 0s 56us/step - loss: 1.6873 - acc: 0.6185\n",
      "Epoch 9/60\n",
      "692/692 [==============================] - 0s 60us/step - loss: 1.6110 - acc: 0.6344\n",
      "Epoch 10/60\n",
      "692/692 [==============================] - 0s 58us/step - loss: 1.5094 - acc: 0.6445\n",
      "Epoch 11/60\n",
      "692/692 [==============================] - 0s 56us/step - loss: 1.4203 - acc: 0.6402\n",
      "Epoch 12/60\n",
      "692/692 [==============================] - 0s 64us/step - loss: 1.3314 - acc: 0.6358\n",
      "Epoch 13/60\n",
      "692/692 [==============================] - 0s 54us/step - loss: 1.2492 - acc: 0.6315\n",
      "Epoch 14/60\n",
      "692/692 [==============================] - 0s 60us/step - loss: 1.1659 - acc: 0.6373\n",
      "Epoch 15/60\n",
      "692/692 [==============================] - 0s 55us/step - loss: 1.0925 - acc: 0.6272\n",
      "Epoch 16/60\n",
      "692/692 [==============================] - 0s 56us/step - loss: 1.0407 - acc: 0.6286\n",
      "Epoch 17/60\n",
      "692/692 [==============================] - 0s 61us/step - loss: 0.9991 - acc: 0.6243\n",
      "Epoch 18/60\n",
      "692/692 [==============================] - 0s 57us/step - loss: 0.9630 - acc: 0.6185\n",
      "Epoch 19/60\n",
      "692/692 [==============================] - 0s 67us/step - loss: 0.9349 - acc: 0.6199\n",
      "Epoch 20/60\n",
      "692/692 [==============================] - 0s 56us/step - loss: 0.9115 - acc: 0.6214\n",
      "Epoch 21/60\n",
      "692/692 [==============================] - 0s 58us/step - loss: 0.9020 - acc: 0.6171\n",
      "Epoch 22/60\n",
      "692/692 [==============================] - 0s 58us/step - loss: 0.8746 - acc: 0.6301\n",
      "Epoch 23/60\n",
      "692/692 [==============================] - 0s 53us/step - loss: 0.8534 - acc: 0.6329\n",
      "Epoch 24/60\n",
      "692/692 [==============================] - 0s 64us/step - loss: 0.8436 - acc: 0.6214\n",
      "Epoch 25/60\n",
      "692/692 [==============================] - 0s 54us/step - loss: 0.8230 - acc: 0.6387\n",
      "Epoch 26/60\n",
      "692/692 [==============================] - 0s 62us/step - loss: 0.8059 - acc: 0.6257\n",
      "Epoch 27/60\n",
      "692/692 [==============================] - 0s 55us/step - loss: 0.7875 - acc: 0.6329\n",
      "Epoch 28/60\n",
      "692/692 [==============================] - 0s 55us/step - loss: 0.7753 - acc: 0.6460\n",
      "Epoch 29/60\n",
      "692/692 [==============================] - 0s 63us/step - loss: 0.7769 - acc: 0.6662\n",
      "Epoch 30/60\n",
      "692/692 [==============================] - 0s 55us/step - loss: 0.7693 - acc: 0.6387\n",
      "Epoch 31/60\n",
      "692/692 [==============================] - 0s 63us/step - loss: 0.7443 - acc: 0.6618\n",
      "Epoch 32/60\n",
      "692/692 [==============================] - 0s 56us/step - loss: 0.7326 - acc: 0.6546\n",
      "Epoch 33/60\n",
      "692/692 [==============================] - 0s 61us/step - loss: 0.7309 - acc: 0.6662\n",
      "Epoch 34/60\n",
      "692/692 [==============================] - 0s 61us/step - loss: 0.7238 - acc: 0.6517\n",
      "Epoch 35/60\n",
      "692/692 [==============================] - 0s 52us/step - loss: 0.7141 - acc: 0.6604\n",
      "Epoch 36/60\n",
      "692/692 [==============================] - 0s 61us/step - loss: 0.7060 - acc: 0.6691\n",
      "Epoch 37/60\n",
      "692/692 [==============================] - 0s 55us/step - loss: 0.7040 - acc: 0.6618\n",
      "Epoch 38/60\n",
      "692/692 [==============================] - 0s 61us/step - loss: 0.6942 - acc: 0.6647\n",
      "Epoch 39/60\n",
      "692/692 [==============================] - 0s 59us/step - loss: 0.6947 - acc: 0.6705\n",
      "Epoch 40/60\n",
      "692/692 [==============================] - 0s 59us/step - loss: 0.6926 - acc: 0.6546\n",
      "Epoch 41/60\n",
      "692/692 [==============================] - 0s 63us/step - loss: 0.6825 - acc: 0.6647\n",
      "Epoch 42/60\n",
      "692/692 [==============================] - 0s 55us/step - loss: 0.6824 - acc: 0.6676\n",
      "Epoch 43/60\n",
      "692/692 [==============================] - 0s 65us/step - loss: 0.6751 - acc: 0.6647\n",
      "Epoch 44/60\n",
      "692/692 [==============================] - 0s 56us/step - loss: 0.6734 - acc: 0.6662\n",
      "Epoch 45/60\n",
      "692/692 [==============================] - 0s 55us/step - loss: 0.6679 - acc: 0.6720\n",
      "Epoch 46/60\n",
      "692/692 [==============================] - 0s 63us/step - loss: 0.6651 - acc: 0.6734\n",
      "Epoch 47/60\n",
      "692/692 [==============================] - 0s 56us/step - loss: 0.6638 - acc: 0.6633\n",
      "Epoch 48/60\n",
      "692/692 [==============================] - 0s 63us/step - loss: 0.6628 - acc: 0.6691\n",
      "Epoch 49/60\n",
      "692/692 [==============================] - 0s 55us/step - loss: 0.6593 - acc: 0.6662\n",
      "Epoch 50/60\n",
      "692/692 [==============================] - 0s 55us/step - loss: 0.6573 - acc: 0.6749\n",
      "Epoch 51/60\n",
      "692/692 [==============================] - 0s 64us/step - loss: 0.6551 - acc: 0.6546\n",
      "Epoch 52/60\n",
      "692/692 [==============================] - 0s 54us/step - loss: 0.6543 - acc: 0.6647\n",
      "Epoch 53/60\n",
      "692/692 [==============================] - 0s 63us/step - loss: 0.6505 - acc: 0.6575\n",
      "Epoch 54/60\n",
      "692/692 [==============================] - 0s 61us/step - loss: 0.6489 - acc: 0.6590\n",
      "Epoch 55/60\n",
      "692/692 [==============================] - 0s 56us/step - loss: 0.6458 - acc: 0.6792\n",
      "Epoch 56/60\n",
      "692/692 [==============================] - 0s 60us/step - loss: 0.6432 - acc: 0.6575\n",
      "Epoch 57/60\n",
      "692/692 [==============================] - 0s 56us/step - loss: 0.6442 - acc: 0.6618\n",
      "Epoch 58/60\n",
      "692/692 [==============================] - 0s 63us/step - loss: 0.6368 - acc: 0.6792\n",
      "Epoch 59/60\n",
      "692/692 [==============================] - 0s 58us/step - loss: 0.6346 - acc: 0.6720\n",
      "Epoch 60/60\n",
      "692/692 [==============================] - 0s 62us/step - loss: 0.6380 - acc: 0.6590\n",
      "76/76 [==============================] - 2s 20ms/step\n",
      "Epoch 1/20\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 5.4028 - acc: 0.6585\n",
      "Epoch 2/20\n",
      "691/691 [==============================] - 0s 41us/step - loss: 5.3475 - acc: 0.6585\n",
      "Epoch 3/20\n",
      "691/691 [==============================] - 0s 45us/step - loss: 5.2847 - acc: 0.6585\n",
      "Epoch 4/20\n",
      "691/691 [==============================] - 0s 46us/step - loss: 5.1043 - acc: 0.6599\n",
      "Epoch 5/20\n",
      "691/691 [==============================] - 0s 42us/step - loss: 4.5814 - acc: 0.6585\n",
      "Epoch 6/20\n",
      "691/691 [==============================] - 0s 47us/step - loss: 3.7669 - acc: 0.6440\n",
      "Epoch 7/20\n",
      "691/691 [==============================] - 0s 49us/step - loss: 3.4510 - acc: 0.5919\n",
      "Epoch 8/20\n",
      "691/691 [==============================] - 0s 41us/step - loss: 3.3997 - acc: 0.5847\n",
      "Epoch 9/20\n",
      "691/691 [==============================] - 0s 44us/step - loss: 3.1065 - acc: 0.6151\n",
      "Epoch 10/20\n",
      "691/691 [==============================] - 0s 52us/step - loss: 2.9275 - acc: 0.5977\n",
      "Epoch 11/20\n",
      "691/691 [==============================] - 0s 40us/step - loss: 2.7971 - acc: 0.5485\n",
      "Epoch 12/20\n",
      "691/691 [==============================] - 0s 42us/step - loss: 2.7502 - acc: 0.5658\n",
      "Epoch 13/20\n",
      "691/691 [==============================] - 0s 50us/step - loss: 2.6954 - acc: 0.5716\n",
      "Epoch 14/20\n",
      "691/691 [==============================] - 0s 45us/step - loss: 2.6850 - acc: 0.5644\n",
      "Epoch 15/20\n",
      "691/691 [==============================] - 0s 42us/step - loss: 2.6356 - acc: 0.5658\n",
      "Epoch 16/20\n",
      "691/691 [==============================] - 0s 46us/step - loss: 2.6097 - acc: 0.5731\n",
      "Epoch 17/20\n",
      "691/691 [==============================] - 0s 47us/step - loss: 2.5347 - acc: 0.5673\n",
      "Epoch 18/20\n",
      "691/691 [==============================] - 0s 44us/step - loss: 2.5157 - acc: 0.5557\n",
      "Epoch 19/20\n",
      "691/691 [==============================] - 0s 44us/step - loss: 2.4608 - acc: 0.5673\n",
      "Epoch 20/20\n",
      "691/691 [==============================] - 0s 51us/step - loss: 2.3989 - acc: 0.5630\n",
      "77/77 [==============================] - 2s 20ms/step\n",
      "Epoch 1/20\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 10.2496 - acc: 0.3560\n",
      "Epoch 2/20\n",
      "691/691 [==============================] - 0s 42us/step - loss: 10.2410 - acc: 0.3560\n",
      "Epoch 3/20\n",
      "691/691 [==============================] - 0s 48us/step - loss: 10.2280 - acc: 0.3560\n",
      "Epoch 4/20\n",
      "691/691 [==============================] - 0s 45us/step - loss: 10.2163 - acc: 0.3560\n",
      "Epoch 5/20\n",
      "691/691 [==============================] - 0s 45us/step - loss: 10.1937 - acc: 0.3560\n",
      "Epoch 6/20\n",
      "691/691 [==============================] - 0s 48us/step - loss: 10.1685 - acc: 0.3560\n",
      "Epoch 7/20\n",
      "691/691 [==============================] - 0s 43us/step - loss: 10.1112 - acc: 0.3560\n",
      "Epoch 8/20\n",
      "691/691 [==============================] - 0s 44us/step - loss: 9.9195 - acc: 0.3560\n",
      "Epoch 9/20\n",
      "691/691 [==============================] - 0s 52us/step - loss: 8.2401 - acc: 0.3589\n",
      "Epoch 10/20\n",
      "691/691 [==============================] - 0s 44us/step - loss: 4.1205 - acc: 0.4023\n",
      "Epoch 11/20\n",
      "691/691 [==============================] - 0s 46us/step - loss: 3.3588 - acc: 0.5861\n",
      "Epoch 12/20\n",
      "691/691 [==============================] - 0s 48us/step - loss: 3.3917 - acc: 0.6049\n",
      "Epoch 13/20\n",
      "691/691 [==============================] - 0s 46us/step - loss: 3.0557 - acc: 0.5658\n",
      "Epoch 14/20\n",
      "691/691 [==============================] - 0s 47us/step - loss: 2.9702 - acc: 0.5123\n",
      "Epoch 15/20\n",
      "691/691 [==============================] - 0s 49us/step - loss: 2.9382 - acc: 0.5123\n",
      "Epoch 16/20\n",
      "691/691 [==============================] - 0s 46us/step - loss: 2.8493 - acc: 0.5195\n",
      "Epoch 17/20\n",
      "691/691 [==============================] - 0s 50us/step - loss: 2.8089 - acc: 0.5398\n",
      "Epoch 18/20\n",
      "691/691 [==============================] - 0s 43us/step - loss: 2.7446 - acc: 0.5297\n",
      "Epoch 19/20\n",
      "691/691 [==============================] - 0s 44us/step - loss: 2.6903 - acc: 0.5166\n",
      "Epoch 20/20\n",
      "691/691 [==============================] - 0s 50us/step - loss: 2.6396 - acc: 0.5123\n",
      "77/77 [==============================] - 2s 21ms/step\n",
      "Epoch 1/20\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 6.3624 - acc: 0.5716\n",
      "Epoch 2/20\n",
      "691/691 [==============================] - 0s 43us/step - loss: 6.1814 - acc: 0.5904\n",
      "Epoch 3/20\n",
      "691/691 [==============================] - 0s 45us/step - loss: 5.9764 - acc: 0.5962\n",
      "Epoch 4/20\n",
      "691/691 [==============================] - 0s 50us/step - loss: 5.6396 - acc: 0.6035\n",
      "Epoch 5/20\n",
      "691/691 [==============================] - 0s 42us/step - loss: 5.4160 - acc: 0.6310\n",
      "Epoch 6/20\n",
      "691/691 [==============================] - 0s 42us/step - loss: 5.3747 - acc: 0.6339\n",
      "Epoch 7/20\n",
      "691/691 [==============================] - 0s 49us/step - loss: 5.3844 - acc: 0.6411\n",
      "Epoch 8/20\n",
      "691/691 [==============================] - 0s 45us/step - loss: 5.3719 - acc: 0.6440\n",
      "Epoch 9/20\n",
      "691/691 [==============================] - 0s 43us/step - loss: 5.3628 - acc: 0.6469\n",
      "Epoch 10/20\n",
      "691/691 [==============================] - 0s 40us/step - loss: 5.3474 - acc: 0.6483\n",
      "Epoch 11/20\n",
      "691/691 [==============================] - 0s 51us/step - loss: 5.2819 - acc: 0.6498\n",
      "Epoch 12/20\n",
      "691/691 [==============================] - 0s 44us/step - loss: 5.2476 - acc: 0.6454\n",
      "Epoch 13/20\n",
      "691/691 [==============================] - 0s 42us/step - loss: 5.1981 - acc: 0.6440\n",
      "Epoch 14/20\n",
      "691/691 [==============================] - 0s 46us/step - loss: 5.1679 - acc: 0.6454\n",
      "Epoch 15/20\n",
      "691/691 [==============================] - 0s 49us/step - loss: 5.1630 - acc: 0.6454\n",
      "Epoch 16/20\n",
      "691/691 [==============================] - 0s 40us/step - loss: 5.1555 - acc: 0.6425\n",
      "Epoch 17/20\n",
      "691/691 [==============================] - 0s 43us/step - loss: 5.1422 - acc: 0.6425\n",
      "Epoch 18/20\n",
      "691/691 [==============================] - 0s 51us/step - loss: 5.1328 - acc: 0.6440\n",
      "Epoch 19/20\n",
      "691/691 [==============================] - 0s 45us/step - loss: 5.1212 - acc: 0.6483\n",
      "Epoch 20/20\n",
      "691/691 [==============================] - 0s 40us/step - loss: 5.1362 - acc: 0.6397\n",
      "77/77 [==============================] - 2s 20ms/step\n",
      "Epoch 1/20\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 4.4877 - acc: 0.6411\n",
      "Epoch 2/20\n",
      "691/691 [==============================] - 0s 45us/step - loss: 3.8061 - acc: 0.5876\n",
      "Epoch 3/20\n",
      "691/691 [==============================] - 0s 42us/step - loss: 3.6882 - acc: 0.5832\n",
      "Epoch 4/20\n",
      "691/691 [==============================] - 0s 47us/step - loss: 3.5751 - acc: 0.6035\n",
      "Epoch 5/20\n",
      "691/691 [==============================] - 0s 44us/step - loss: 3.3852 - acc: 0.5470\n",
      "Epoch 6/20\n",
      "691/691 [==============================] - 0s 47us/step - loss: 2.9477 - acc: 0.5384\n",
      "Epoch 7/20\n",
      "691/691 [==============================] - 0s 47us/step - loss: 2.2691 - acc: 0.4935\n",
      "Epoch 8/20\n",
      "691/691 [==============================] - 0s 40us/step - loss: 1.9784 - acc: 0.4703\n",
      "Epoch 9/20\n",
      "691/691 [==============================] - 0s 44us/step - loss: 1.6894 - acc: 0.5123\n",
      "Epoch 10/20\n",
      "691/691 [==============================] - 0s 49us/step - loss: 1.5623 - acc: 0.5311\n",
      "Epoch 11/20\n",
      "691/691 [==============================] - 0s 45us/step - loss: 1.4761 - acc: 0.5832\n",
      "Epoch 12/20\n",
      "691/691 [==============================] - 0s 42us/step - loss: 1.3981 - acc: 0.5716\n",
      "Epoch 13/20\n",
      "691/691 [==============================] - 0s 46us/step - loss: 1.3359 - acc: 0.5774\n",
      "Epoch 14/20\n",
      "691/691 [==============================] - 0s 47us/step - loss: 1.2882 - acc: 0.6035\n",
      "Epoch 15/20\n",
      "691/691 [==============================] - 0s 44us/step - loss: 1.2473 - acc: 0.5789\n",
      "Epoch 16/20\n",
      "691/691 [==============================] - 0s 42us/step - loss: 1.2253 - acc: 0.6107\n",
      "Epoch 17/20\n",
      "691/691 [==============================] - 0s 49us/step - loss: 1.2178 - acc: 0.5832\n",
      "Epoch 18/20\n",
      "691/691 [==============================] - 0s 48us/step - loss: 1.1651 - acc: 0.6078\n",
      "Epoch 19/20\n",
      "691/691 [==============================] - 0s 42us/step - loss: 1.1238 - acc: 0.6165\n",
      "Epoch 20/20\n",
      "691/691 [==============================] - 0s 42us/step - loss: 1.1079 - acc: 0.6093\n",
      "77/77 [==============================] - 2s 21ms/step\n",
      "Epoch 1/20\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 10.1083 - acc: 0.3517\n",
      "Epoch 2/20\n",
      "691/691 [==============================] - 0s 44us/step - loss: 10.0341 - acc: 0.3589\n",
      "Epoch 3/20\n",
      "691/691 [==============================] - 0s 43us/step - loss: 9.8246 - acc: 0.3560\n",
      "Epoch 4/20\n",
      "691/691 [==============================] - 0s 49us/step - loss: 9.1165 - acc: 0.3647\n",
      "Epoch 5/20\n",
      "691/691 [==============================] - 0s 45us/step - loss: 7.4960 - acc: 0.3907\n",
      "Epoch 6/20\n",
      "691/691 [==============================] - 0s 43us/step - loss: 5.1088 - acc: 0.4616\n",
      "Epoch 7/20\n",
      "691/691 [==============================] - 0s 53us/step - loss: 3.8552 - acc: 0.5673\n",
      "Epoch 8/20\n",
      "691/691 [==============================] - 0s 43us/step - loss: 3.5610 - acc: 0.6006\n",
      "Epoch 9/20\n",
      "691/691 [==============================] - 0s 44us/step - loss: 3.4961 - acc: 0.6136\n",
      "Epoch 10/20\n",
      "691/691 [==============================] - 0s 56us/step - loss: 3.2321 - acc: 0.5962\n",
      "Epoch 11/20\n",
      "691/691 [==============================] - 0s 47us/step - loss: 2.9968 - acc: 0.5818\n",
      "Epoch 12/20\n",
      "691/691 [==============================] - 0s 43us/step - loss: 2.7431 - acc: 0.5890\n",
      "Epoch 13/20\n",
      "691/691 [==============================] - 0s 49us/step - loss: 2.5514 - acc: 0.5904\n",
      "Epoch 14/20\n",
      "691/691 [==============================] - 0s 48us/step - loss: 2.4174 - acc: 0.6165\n",
      "Epoch 15/20\n",
      "691/691 [==============================] - 0s 46us/step - loss: 2.3324 - acc: 0.6093\n",
      "Epoch 16/20\n",
      "691/691 [==============================] - 0s 43us/step - loss: 2.2356 - acc: 0.6179\n",
      "Epoch 17/20\n",
      "691/691 [==============================] - 0s 45us/step - loss: 2.1439 - acc: 0.6310\n",
      "Epoch 18/20\n",
      "691/691 [==============================] - 0s 54us/step - loss: 2.0550 - acc: 0.6324\n",
      "Epoch 19/20\n",
      "691/691 [==============================] - 0s 48us/step - loss: 1.9730 - acc: 0.6382\n",
      "Epoch 20/20\n",
      "691/691 [==============================] - 0s 42us/step - loss: 1.8950 - acc: 0.6454\n",
      "77/77 [==============================] - 2s 21ms/step\n",
      "Epoch 1/20\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 2/20\n",
      "691/691 [==============================] - 0s 44us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 3/20\n",
      "691/691 [==============================] - 0s 46us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 4/20\n",
      "691/691 [==============================] - 0s 52us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 5/20\n",
      "691/691 [==============================] - 0s 49us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 6/20\n",
      "691/691 [==============================] - 0s 41us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 7/20\n",
      "691/691 [==============================] - 0s 54us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 8/20\n",
      "691/691 [==============================] - 0s 45us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 9/20\n",
      "691/691 [==============================] - 0s 40us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 10/20\n",
      "691/691 [==============================] - 0s 50us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 11/20\n",
      "691/691 [==============================] - 0s 47us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 12/20\n",
      "691/691 [==============================] - 0s 46us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 13/20\n",
      "691/691 [==============================] - 0s 42us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 14/20\n",
      "691/691 [==============================] - 0s 52us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 15/20\n",
      "691/691 [==============================] - 0s 47us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 16/20\n",
      "691/691 [==============================] - 0s 41us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 17/20\n",
      "691/691 [==============================] - 0s 42us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 18/20\n",
      "691/691 [==============================] - 0s 52us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 19/20\n",
      "691/691 [==============================] - 0s 45us/step - loss: 10.4514 - acc: 0.3444\n",
      "Epoch 20/20\n",
      "691/691 [==============================] - 0s 43us/step - loss: 10.4514 - acc: 0.3444\n",
      "77/77 [==============================] - 2s 21ms/step\n",
      "Epoch 1/20\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 2/20\n",
      "691/691 [==============================] - 0s 43us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 3/20\n",
      "691/691 [==============================] - 0s 43us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 4/20\n",
      "691/691 [==============================] - 0s 47us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 5/20\n",
      "691/691 [==============================] - 0s 43us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 6/20\n",
      "691/691 [==============================] - 0s 45us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 7/20\n",
      "691/691 [==============================] - 0s 48us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 8/20\n",
      "691/691 [==============================] - 0s 41us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 9/20\n",
      "691/691 [==============================] - 0s 43us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 10/20\n",
      "691/691 [==============================] - 0s 50us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 11/20\n",
      "691/691 [==============================] - 0s 43us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 12/20\n",
      "691/691 [==============================] - 0s 43us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 13/20\n",
      "691/691 [==============================] - 0s 49us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 14/20\n",
      "691/691 [==============================] - 0s 51us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 15/20\n",
      "691/691 [==============================] - 0s 45us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 16/20\n",
      "691/691 [==============================] - 0s 44us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 17/20\n",
      "691/691 [==============================] - 0s 45us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 18/20\n",
      "691/691 [==============================] - 0s 52us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 19/20\n",
      "691/691 [==============================] - 0s 46us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 20/20\n",
      "691/691 [==============================] - 0s 46us/step - loss: 10.0822 - acc: 0.3676\n",
      "77/77 [==============================] - 2s 21ms/step\n",
      "Epoch 1/20\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 5.3726 - acc: 0.6368\n",
      "Epoch 2/20\n",
      "691/691 [==============================] - 0s 44us/step - loss: 5.0725 - acc: 0.6339\n",
      "Epoch 3/20\n",
      "691/691 [==============================] - 0s 43us/step - loss: 4.6321 - acc: 0.5919\n",
      "Epoch 4/20\n",
      "691/691 [==============================] - 0s 53us/step - loss: 4.2341 - acc: 0.5051\n",
      "Epoch 5/20\n",
      "691/691 [==============================] - 0s 45us/step - loss: 4.0163 - acc: 0.4631\n",
      "Epoch 6/20\n",
      "691/691 [==============================] - 0s 47us/step - loss: 3.7535 - acc: 0.5109\n",
      "Epoch 7/20\n",
      "691/691 [==============================] - 0s 46us/step - loss: 3.5565 - acc: 0.5080\n",
      "Epoch 8/20\n",
      "691/691 [==============================] - 0s 44us/step - loss: 3.3400 - acc: 0.4805\n",
      "Epoch 9/20\n",
      "691/691 [==============================] - 0s 46us/step - loss: 3.1060 - acc: 0.4703\n",
      "Epoch 10/20\n",
      "691/691 [==============================] - 0s 47us/step - loss: 2.7936 - acc: 0.5007\n",
      "Epoch 11/20\n",
      "691/691 [==============================] - 0s 54us/step - loss: 2.4730 - acc: 0.5412\n",
      "Epoch 12/20\n",
      "691/691 [==============================] - 0s 45us/step - loss: 2.2165 - acc: 0.4949\n",
      "Epoch 13/20\n",
      "691/691 [==============================] - 0s 47us/step - loss: 1.9694 - acc: 0.5297\n",
      "Epoch 14/20\n",
      "691/691 [==============================] - 0s 52us/step - loss: 1.8049 - acc: 0.5369\n",
      "Epoch 15/20\n",
      "691/691 [==============================] - 0s 42us/step - loss: 1.6854 - acc: 0.5326\n",
      "Epoch 16/20\n",
      "691/691 [==============================] - 0s 45us/step - loss: 1.5482 - acc: 0.5326\n",
      "Epoch 17/20\n",
      "691/691 [==============================] - 0s 50us/step - loss: 1.4427 - acc: 0.5384\n",
      "Epoch 18/20\n",
      "691/691 [==============================] - 0s 47us/step - loss: 1.3430 - acc: 0.5470\n",
      "Epoch 19/20\n",
      "691/691 [==============================] - 0s 43us/step - loss: 1.2495 - acc: 0.5615\n",
      "Epoch 20/20\n",
      "691/691 [==============================] - 0s 49us/step - loss: 1.1936 - acc: 0.5528\n",
      "77/77 [==============================] - 2s 22ms/step\n",
      "Epoch 1/20\n",
      "692/692 [==============================] - 4s 6ms/step - loss: 3.8093 - acc: 0.6344\n",
      "Epoch 2/20\n",
      "692/692 [==============================] - 0s 41us/step - loss: 3.4868 - acc: 0.5925\n",
      "Epoch 3/20\n",
      "692/692 [==============================] - 0s 48us/step - loss: 3.2674 - acc: 0.5867\n",
      "Epoch 4/20\n",
      "692/692 [==============================] - 0s 50us/step - loss: 2.8960 - acc: 0.5867\n",
      "Epoch 5/20\n",
      "692/692 [==============================] - 0s 44us/step - loss: 2.3032 - acc: 0.5896\n",
      "Epoch 6/20\n",
      "692/692 [==============================] - 0s 44us/step - loss: 1.8543 - acc: 0.5795\n",
      "Epoch 7/20\n",
      "692/692 [==============================] - 0s 54us/step - loss: 1.7025 - acc: 0.5737\n",
      "Epoch 8/20\n",
      "692/692 [==============================] - 0s 47us/step - loss: 1.6522 - acc: 0.5549\n",
      "Epoch 9/20\n",
      "692/692 [==============================] - 0s 44us/step - loss: 1.5797 - acc: 0.5737\n",
      "Epoch 10/20\n",
      "692/692 [==============================] - 0s 46us/step - loss: 1.5236 - acc: 0.5780\n",
      "Epoch 11/20\n",
      "692/692 [==============================] - 0s 55us/step - loss: 1.4755 - acc: 0.5780\n",
      "Epoch 12/20\n",
      "692/692 [==============================] - 0s 46us/step - loss: 1.4327 - acc: 0.5751\n",
      "Epoch 13/20\n",
      "692/692 [==============================] - 0s 41us/step - loss: 1.3874 - acc: 0.5650\n",
      "Epoch 14/20\n",
      "692/692 [==============================] - 0s 45us/step - loss: 1.3596 - acc: 0.5824\n",
      "Epoch 15/20\n",
      "692/692 [==============================] - 0s 53us/step - loss: 1.3299 - acc: 0.5780\n",
      "Epoch 16/20\n",
      "692/692 [==============================] - 0s 61us/step - loss: 1.2949 - acc: 0.5853\n",
      "Epoch 17/20\n",
      "692/692 [==============================] - 0s 43us/step - loss: 1.2523 - acc: 0.5679\n",
      "Epoch 18/20\n",
      "692/692 [==============================] - 0s 45us/step - loss: 1.2157 - acc: 0.5824\n",
      "Epoch 19/20\n",
      "692/692 [==============================] - 0s 55us/step - loss: 1.1744 - acc: 0.5650\n",
      "Epoch 20/20\n",
      "692/692 [==============================] - 0s 53us/step - loss: 1.1433 - acc: 0.5780\n",
      "76/76 [==============================] - 2s 21ms/step\n",
      "Epoch 1/20\n",
      "692/692 [==============================] - 4s 6ms/step - loss: 5.9784 - acc: 0.4711\n",
      "Epoch 2/20\n",
      "692/692 [==============================] - 0s 49us/step - loss: 5.5996 - acc: 0.5087\n",
      "Epoch 3/20\n",
      "692/692 [==============================] - 0s 47us/step - loss: 4.8735 - acc: 0.5361\n",
      "Epoch 4/20\n",
      "692/692 [==============================] - 0s 57us/step - loss: 3.5406 - acc: 0.5679\n",
      "Epoch 5/20\n",
      "692/692 [==============================] - 0s 47us/step - loss: 2.7974 - acc: 0.6416\n",
      "Epoch 6/20\n",
      "692/692 [==============================] - 0s 48us/step - loss: 2.5784 - acc: 0.6373\n",
      "Epoch 7/20\n",
      "692/692 [==============================] - 0s 51us/step - loss: 2.5024 - acc: 0.6199\n",
      "Epoch 8/20\n",
      "692/692 [==============================] - 0s 48us/step - loss: 2.3975 - acc: 0.6185\n",
      "Epoch 9/20\n",
      "692/692 [==============================] - 0s 43us/step - loss: 2.2944 - acc: 0.6329\n",
      "Epoch 10/20\n",
      "692/692 [==============================] - 0s 48us/step - loss: 2.2243 - acc: 0.6286\n",
      "Epoch 11/20\n",
      "692/692 [==============================] - 0s 50us/step - loss: 2.1522 - acc: 0.6185\n",
      "Epoch 12/20\n",
      "692/692 [==============================] - 0s 45us/step - loss: 2.1041 - acc: 0.6257\n",
      "Epoch 13/20\n",
      "692/692 [==============================] - 0s 44us/step - loss: 2.0295 - acc: 0.6127\n",
      "Epoch 14/20\n",
      "692/692 [==============================] - 0s 52us/step - loss: 1.9844 - acc: 0.6127\n",
      "Epoch 15/20\n",
      "692/692 [==============================] - 0s 47us/step - loss: 1.9355 - acc: 0.6084\n",
      "Epoch 16/20\n",
      "692/692 [==============================] - 0s 44us/step - loss: 1.8607 - acc: 0.6084\n",
      "Epoch 17/20\n",
      "692/692 [==============================] - 0s 54us/step - loss: 1.7958 - acc: 0.6040\n",
      "Epoch 18/20\n",
      "692/692 [==============================] - 0s 53us/step - loss: 1.7511 - acc: 0.6098\n",
      "Epoch 19/20\n",
      "692/692 [==============================] - 0s 48us/step - loss: 1.6888 - acc: 0.6098\n",
      "Epoch 20/20\n",
      "692/692 [==============================] - 0s 46us/step - loss: 1.6586 - acc: 0.6084\n",
      "76/76 [==============================] - 2s 23ms/step\n",
      "Epoch 1/40\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 6.3738 - acc: 0.3329\n",
      "Epoch 2/40\n",
      "691/691 [==============================] - 0s 44us/step - loss: 4.0138 - acc: 0.3575\n",
      "Epoch 3/40\n",
      "691/691 [==============================] - 0s 42us/step - loss: 2.4879 - acc: 0.4124\n",
      "Epoch 4/40\n",
      "691/691 [==============================] - 0s 53us/step - loss: 1.9004 - acc: 0.5297\n",
      "Epoch 5/40\n",
      "691/691 [==============================] - 0s 48us/step - loss: 1.7430 - acc: 0.5789\n",
      "Epoch 6/40\n",
      "691/691 [==============================] - 0s 44us/step - loss: 1.5176 - acc: 0.5760\n",
      "Epoch 7/40\n",
      "691/691 [==============================] - 0s 43us/step - loss: 1.3824 - acc: 0.5036\n",
      "Epoch 8/40\n",
      "691/691 [==============================] - 0s 53us/step - loss: 1.3408 - acc: 0.4689\n",
      "Epoch 9/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 1.2899 - acc: 0.5282\n",
      "Epoch 10/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 1.2191 - acc: 0.5528\n",
      "Epoch 11/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 1.1254 - acc: 0.5326\n",
      "Epoch 12/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 1.0041 - acc: 0.5152\n",
      "Epoch 13/40\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.9638 - acc: 0.5311\n",
      "Epoch 14/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.9267 - acc: 0.5398\n",
      "Epoch 15/40\n",
      "691/691 [==============================] - 0s 43us/step - loss: 0.9074 - acc: 0.5572\n",
      "Epoch 16/40\n",
      "691/691 [==============================] - ETA: 0s - loss: 0.9298 - acc: 0.512 - 0s 50us/step - loss: 0.8901 - acc: 0.5557\n",
      "Epoch 17/40\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.8698 - acc: 0.5673\n",
      "Epoch 18/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 0.8596 - acc: 0.5644\n",
      "Epoch 19/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.8463 - acc: 0.5630\n",
      "Epoch 20/40\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.8410 - acc: 0.5760\n",
      "Epoch 21/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.8226 - acc: 0.5774\n",
      "Epoch 22/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 0.8143 - acc: 0.5702\n",
      "Epoch 23/40\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.8089 - acc: 0.5977\n",
      "Epoch 24/40\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.7983 - acc: 0.5832\n",
      "Epoch 25/40\n",
      "691/691 [==============================] - 0s 49us/step - loss: 0.7894 - acc: 0.5702\n",
      "Epoch 26/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 0.7909 - acc: 0.5847\n",
      "Epoch 27/40\n",
      "691/691 [==============================] - 0s 42us/step - loss: 0.7773 - acc: 0.5890\n",
      "Epoch 28/40\n",
      "691/691 [==============================] - 0s 64us/step - loss: 0.7695 - acc: 0.5687\n",
      "Epoch 29/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.7610 - acc: 0.5948\n",
      "Epoch 30/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 0.7621 - acc: 0.5948\n",
      "Epoch 31/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.7550 - acc: 0.6006\n",
      "Epoch 32/40\n",
      "691/691 [==============================] - 0s 44us/step - loss: 0.7505 - acc: 0.5991\n",
      "Epoch 33/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.7407 - acc: 0.6049\n",
      "Epoch 34/40\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.7326 - acc: 0.6122\n",
      "Epoch 35/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 0.7304 - acc: 0.6006\n",
      "Epoch 36/40\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.7186 - acc: 0.6078\n",
      "Epoch 37/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 0.7157 - acc: 0.6194\n",
      "Epoch 38/40\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.7186 - acc: 0.6179\n",
      "Epoch 39/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.7058 - acc: 0.6107\n",
      "Epoch 40/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.7029 - acc: 0.6179\n",
      "77/77 [==============================] - 2s 22ms/step\n",
      "Epoch 1/40\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 2.5470 - acc: 0.5398\n",
      "Epoch 2/40\n",
      "691/691 [==============================] - 0s 44us/step - loss: 2.1588 - acc: 0.5355\n",
      "Epoch 3/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 1.9439 - acc: 0.5615\n",
      "Epoch 4/40\n",
      "691/691 [==============================] - 0s 50us/step - loss: 1.8118 - acc: 0.5803\n",
      "Epoch 5/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 1.6633 - acc: 0.5933\n",
      "Epoch 6/40\n",
      "691/691 [==============================] - 0s 43us/step - loss: 1.5426 - acc: 0.6035\n",
      "Epoch 7/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 1.4453 - acc: 0.5890\n",
      "Epoch 8/40\n",
      "691/691 [==============================] - 0s 48us/step - loss: 1.3417 - acc: 0.6324\n",
      "Epoch 9/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 1.2770 - acc: 0.6093\n",
      "Epoch 10/40\n",
      "691/691 [==============================] - 0s 44us/step - loss: 1.2364 - acc: 0.6469\n",
      "Epoch 11/40\n",
      "691/691 [==============================] - ETA: 0s - loss: 1.2430 - acc: 0.612 - 0s 51us/step - loss: 1.1671 - acc: 0.6483\n",
      "Epoch 12/40\n",
      "691/691 [==============================] - 0s 43us/step - loss: 1.1236 - acc: 0.6440\n",
      "Epoch 13/40\n",
      "691/691 [==============================] - 0s 44us/step - loss: 1.0997 - acc: 0.6744\n",
      "Epoch 14/40\n",
      "691/691 [==============================] - 0s 49us/step - loss: 1.0634 - acc: 0.6570\n",
      "Epoch 15/40\n",
      "691/691 [==============================] - 0s 50us/step - loss: 1.0549 - acc: 0.6729\n",
      "Epoch 16/40\n",
      "691/691 [==============================] - 0s 47us/step - loss: 1.0235 - acc: 0.6483\n",
      "Epoch 17/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 0.9910 - acc: 0.6599\n",
      "Epoch 18/40\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.9716 - acc: 0.6700\n",
      "Epoch 19/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 0.9545 - acc: 0.6758\n",
      "Epoch 20/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 0.9466 - acc: 0.6729\n",
      "Epoch 21/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.9448 - acc: 0.6541\n",
      "Epoch 22/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.9561 - acc: 0.6787\n",
      "Epoch 23/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 0.9045 - acc: 0.6643\n",
      "Epoch 24/40\n",
      "691/691 [==============================] - 0s 42us/step - loss: 0.9113 - acc: 0.6831\n",
      "Epoch 25/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.8845 - acc: 0.6816\n",
      "Epoch 26/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.8717 - acc: 0.6671\n",
      "Epoch 27/40\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.8595 - acc: 0.6802\n",
      "Epoch 28/40\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.8679 - acc: 0.6816\n",
      "Epoch 29/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.8599 - acc: 0.6758\n",
      "Epoch 30/40\n",
      "691/691 [==============================] - 0s 49us/step - loss: 0.8391 - acc: 0.6787\n",
      "Epoch 31/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 0.8387 - acc: 0.6816\n",
      "Epoch 32/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.8179 - acc: 0.6816\n",
      "Epoch 33/40\n",
      "691/691 [==============================] - 0s 62us/step - loss: 0.8162 - acc: 0.6773\n",
      "Epoch 34/40\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.8036 - acc: 0.6787\n",
      "Epoch 35/40\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.8031 - acc: 0.6715\n",
      "Epoch 36/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.7969 - acc: 0.6903\n",
      "Epoch 37/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.7960 - acc: 0.6889\n",
      "Epoch 38/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.7964 - acc: 0.6671\n",
      "Epoch 39/40\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.7832 - acc: 0.6831\n",
      "Epoch 40/40\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.7800 - acc: 0.6961\n",
      "77/77 [==============================] - 2s 23ms/step\n",
      "Epoch 1/40\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 5.0728 - acc: 0.6585\n",
      "Epoch 2/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 5.0831 - acc: 0.6527\n",
      "Epoch 3/40\n",
      "691/691 [==============================] - 0s 44us/step - loss: 5.0493 - acc: 0.6541\n",
      "Epoch 4/40\n",
      "691/691 [==============================] - 0s 51us/step - loss: 5.0415 - acc: 0.6512\n",
      "Epoch 5/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 5.0312 - acc: 0.6512\n",
      "Epoch 6/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 5.0213 - acc: 0.6512\n",
      "Epoch 7/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 5.0123 - acc: 0.6527\n",
      "Epoch 8/40\n",
      "691/691 [==============================] - 0s 50us/step - loss: 4.9984 - acc: 0.6541\n",
      "Epoch 9/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 4.9880 - acc: 0.6556\n",
      "Epoch 10/40\n",
      "691/691 [==============================] - 0s 50us/step - loss: 4.9717 - acc: 0.6541\n",
      "Epoch 11/40\n",
      "691/691 [==============================] - 0s 53us/step - loss: 4.9572 - acc: 0.6556\n",
      "Epoch 12/40\n",
      "691/691 [==============================] - 0s 50us/step - loss: 4.9232 - acc: 0.6498\n",
      "Epoch 13/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 4.8877 - acc: 0.6498\n",
      "Epoch 14/40\n",
      "691/691 [==============================] - 0s 47us/step - loss: 4.8556 - acc: 0.6498\n",
      "Epoch 15/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 4.8095 - acc: 0.6483\n",
      "Epoch 16/40\n",
      "691/691 [==============================] - 0s 48us/step - loss: 4.7617 - acc: 0.6483\n",
      "Epoch 17/40\n",
      "691/691 [==============================] - 0s 51us/step - loss: 4.6987 - acc: 0.6483\n",
      "Epoch 18/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 4.6443 - acc: 0.6469\n",
      "Epoch 19/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 4.5781 - acc: 0.6527\n",
      "Epoch 20/40\n",
      "691/691 [==============================] - 0s 49us/step - loss: 4.5260 - acc: 0.6527\n",
      "Epoch 21/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 4.4604 - acc: 0.6527\n",
      "Epoch 22/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 4.3651 - acc: 0.6556\n",
      "Epoch 23/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 4.2486 - acc: 0.6498\n",
      "Epoch 24/40\n",
      "691/691 [==============================] - 0s 49us/step - loss: 4.0471 - acc: 0.6541\n",
      "Epoch 25/40\n",
      "691/691 [==============================] - 0s 54us/step - loss: 3.8526 - acc: 0.6512\n",
      "Epoch 26/40\n",
      "691/691 [==============================] - 0s 44us/step - loss: 3.5881 - acc: 0.6686\n",
      "Epoch 27/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 2.7083 - acc: 0.6657\n",
      "Epoch 28/40\n",
      "691/691 [==============================] - 0s 47us/step - loss: 1.5441 - acc: 0.6657\n",
      "Epoch 29/40\n",
      "691/691 [==============================] - 0s 65us/step - loss: 1.3281 - acc: 0.6816\n",
      "Epoch 30/40\n",
      "691/691 [==============================] - 0s 54us/step - loss: 1.2443 - acc: 0.6657\n",
      "Epoch 31/40\n",
      "691/691 [==============================] - 0s 54us/step - loss: 1.1234 - acc: 0.6874\n",
      "Epoch 32/40\n",
      "691/691 [==============================] - 0s 43us/step - loss: 1.0717 - acc: 0.6802\n",
      "Epoch 33/40\n",
      "691/691 [==============================] - 0s 48us/step - loss: 1.0228 - acc: 0.6802\n",
      "Epoch 34/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.9749 - acc: 0.6729\n",
      "Epoch 35/40\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.9449 - acc: 0.6773\n",
      "Epoch 36/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.9114 - acc: 0.6816\n",
      "Epoch 37/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 0.8849 - acc: 0.6585\n",
      "Epoch 38/40\n",
      "691/691 [==============================] - 0s 42us/step - loss: 0.8624 - acc: 0.6758\n",
      "Epoch 39/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.8454 - acc: 0.6614\n",
      "Epoch 40/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.8075 - acc: 0.6758\n",
      "77/77 [==============================] - 2s 22ms/step\n",
      "Epoch 1/40\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 7.0909 - acc: 0.3488\n",
      "Epoch 2/40\n",
      "691/691 [==============================] - 0s 44us/step - loss: 5.1764 - acc: 0.4023\n",
      "Epoch 3/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 4.0448 - acc: 0.4790\n",
      "Epoch 4/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 3.7560 - acc: 0.5297\n",
      "Epoch 5/40\n",
      "691/691 [==============================] - 0s 49us/step - loss: 3.5750 - acc: 0.5369\n",
      "Epoch 6/40\n",
      "691/691 [==============================] - 0s 48us/step - loss: 3.2935 - acc: 0.5137\n",
      "Epoch 7/40\n",
      "691/691 [==============================] - 0s 49us/step - loss: 3.0587 - acc: 0.4978\n",
      "Epoch 8/40\n",
      "691/691 [==============================] - 0s 54us/step - loss: 2.8489 - acc: 0.4949\n",
      "Epoch 9/40\n",
      "691/691 [==============================] - 0s 44us/step - loss: 2.6680 - acc: 0.5094\n",
      "Epoch 10/40\n",
      "691/691 [==============================] - 0s 48us/step - loss: 2.4984 - acc: 0.5080\n",
      "Epoch 11/40\n",
      "691/691 [==============================] - 0s 48us/step - loss: 2.3833 - acc: 0.4863\n",
      "Epoch 12/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 2.2615 - acc: 0.4790\n",
      "Epoch 13/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 2.1750 - acc: 0.4747\n",
      "Epoch 14/40\n",
      "691/691 [==============================] - 0s 44us/step - loss: 2.0946 - acc: 0.4761\n",
      "Epoch 15/40\n",
      "691/691 [==============================] - 0s 47us/step - loss: 2.0265 - acc: 0.4964\n",
      "Epoch 16/40\n",
      "691/691 [==============================] - 0s 50us/step - loss: 1.9251 - acc: 0.4920\n",
      "Epoch 17/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 1.8236 - acc: 0.4891\n",
      "Epoch 18/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 1.6723 - acc: 0.4790\n",
      "Epoch 19/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 1.6090 - acc: 0.4920\n",
      "Epoch 20/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 1.4968 - acc: 0.4834\n",
      "Epoch 21/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 1.4369 - acc: 0.4906\n",
      "Epoch 22/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 1.3857 - acc: 0.5080\n",
      "Epoch 23/40\n",
      "691/691 [==============================] - 0s 51us/step - loss: 1.3181 - acc: 0.4747\n",
      "Epoch 24/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 1.2363 - acc: 0.5109\n",
      "Epoch 25/40\n",
      "691/691 [==============================] - 0s 50us/step - loss: 1.1847 - acc: 0.4848\n",
      "Epoch 26/40\n",
      "691/691 [==============================] - 0s 50us/step - loss: 1.1506 - acc: 0.4935\n",
      "Epoch 27/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 1.1271 - acc: 0.5441\n",
      "Epoch 28/40\n",
      "691/691 [==============================] - 0s 43us/step - loss: 1.0757 - acc: 0.5080\n",
      "Epoch 29/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 1.0551 - acc: 0.5543\n",
      "Epoch 30/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 1.0230 - acc: 0.5166\n",
      "Epoch 31/40\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.9863 - acc: 0.5470\n",
      "Epoch 32/40\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.9652 - acc: 0.5630\n",
      "Epoch 33/40\n",
      "691/691 [==============================] - 0s 44us/step - loss: 0.9415 - acc: 0.5687\n",
      "Epoch 34/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 0.9285 - acc: 0.5702\n",
      "Epoch 35/40\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.8902 - acc: 0.5847\n",
      "Epoch 36/40\n",
      "691/691 [==============================] - 0s 49us/step - loss: 0.8757 - acc: 0.5861\n",
      "Epoch 37/40\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.8557 - acc: 0.6020\n",
      "Epoch 38/40\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.8398 - acc: 0.6107\n",
      "Epoch 39/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.8252 - acc: 0.6179\n",
      "Epoch 40/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.8179 - acc: 0.6223\n",
      "77/77 [==============================] - 2s 23ms/step\n",
      "Epoch 1/40\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 2/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 3/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 4/40\n",
      "691/691 [==============================] - 0s 51us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 5/40\n",
      "691/691 [==============================] - 0s 44us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 6/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 7/40\n",
      "691/691 [==============================] - 0s 44us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 8/40\n",
      "691/691 [==============================] - 0s 53us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 9/40\n",
      "691/691 [==============================] - 0s 42us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 10/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 11/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 12/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 13/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 14/40\n",
      "691/691 [==============================] - 0s 42us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 15/40\n",
      "691/691 [==============================] - 0s 51us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 16/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 17/40\n",
      "691/691 [==============================] - 0s 51us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 18/40\n",
      "691/691 [==============================] - 0s 43us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 19/40\n",
      "691/691 [==============================] - 0s 44us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 20/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 21/40\n",
      "691/691 [==============================] - 0s 48us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 22/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 23/40\n",
      "691/691 [==============================] - 0s 48us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 24/40\n",
      "691/691 [==============================] - 0s 53us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 25/40\n",
      "691/691 [==============================] - 0s 54us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 26/40\n",
      "691/691 [==============================] - 0s 51us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 27/40\n",
      "691/691 [==============================] - 0s 53us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 28/40\n",
      "691/691 [==============================] - 0s 44us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 29/40\n",
      "691/691 [==============================] - 0s 43us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 30/40\n",
      "691/691 [==============================] - 0s 43us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 31/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 32/40\n",
      "691/691 [==============================] - 0s 54us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 33/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 34/40\n",
      "691/691 [==============================] - 0s 47us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 35/40\n",
      "691/691 [==============================] - 0s 43us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 36/40\n",
      "691/691 [==============================] - 0s 47us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 37/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 38/40\n",
      "691/691 [==============================] - 0s 53us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 39/40\n",
      "691/691 [==============================] - 0s 47us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 40/40\n",
      "691/691 [==============================] - 0s 41us/step - loss: 5.6215 - acc: 0.6512\n",
      "77/77 [==============================] - 2s 22ms/step\n",
      "Epoch 1/40\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 10.3952 - acc: 0.3444\n",
      "Epoch 2/40\n",
      "691/691 [==============================] - 0s 51us/step - loss: 10.3803 - acc: 0.3444\n",
      "Epoch 3/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 10.3701 - acc: 0.3444\n",
      "Epoch 4/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 10.3325 - acc: 0.3444\n",
      "Epoch 5/40\n",
      "691/691 [==============================] - 0s 50us/step - loss: 10.3042 - acc: 0.3430\n",
      "Epoch 6/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 10.2960 - acc: 0.3444\n",
      "Epoch 7/40\n",
      "691/691 [==============================] - 0s 43us/step - loss: 10.2846 - acc: 0.3444\n",
      "Epoch 8/40\n",
      "691/691 [==============================] - 0s 50us/step - loss: 10.2830 - acc: 0.3430\n",
      "Epoch 9/40\n",
      "691/691 [==============================] - 0s 50us/step - loss: 10.2676 - acc: 0.3430\n",
      "Epoch 10/40\n",
      "691/691 [==============================] - 0s 48us/step - loss: 10.2529 - acc: 0.3459\n",
      "Epoch 11/40\n",
      "691/691 [==============================] - 0s 47us/step - loss: 10.2197 - acc: 0.3444\n",
      "Epoch 12/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 10.0174 - acc: 0.3415\n",
      "Epoch 13/40\n",
      "691/691 [==============================] - 0s 48us/step - loss: 8.5766 - acc: 0.3546\n",
      "Epoch 14/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 5.8777 - acc: 0.4674\n",
      "Epoch 15/40\n",
      "691/691 [==============================] - 0s 47us/step - loss: 4.4563 - acc: 0.5818\n",
      "Epoch 16/40\n",
      "691/691 [==============================] - 0s 49us/step - loss: 4.0231 - acc: 0.6425\n",
      "Epoch 17/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 4.0515 - acc: 0.6397\n",
      "Epoch 18/40\n",
      "691/691 [==============================] - 0s 50us/step - loss: 3.9214 - acc: 0.6295\n",
      "Epoch 19/40\n",
      "691/691 [==============================] - 0s 44us/step - loss: 3.9072 - acc: 0.6266\n",
      "Epoch 20/40\n",
      "691/691 [==============================] - 0s 49us/step - loss: 3.8689 - acc: 0.6295\n",
      "Epoch 21/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 3.8043 - acc: 0.6339\n",
      "Epoch 22/40\n",
      "691/691 [==============================] - 0s 54us/step - loss: 3.7297 - acc: 0.6339\n",
      "Epoch 23/40\n",
      "691/691 [==============================] - 0s 50us/step - loss: 3.5572 - acc: 0.6223\n",
      "Epoch 24/40\n",
      "691/691 [==============================] - 0s 44us/step - loss: 3.2741 - acc: 0.6136\n",
      "Epoch 25/40\n",
      "691/691 [==============================] - 0s 44us/step - loss: 2.9065 - acc: 0.6006\n",
      "Epoch 26/40\n",
      "691/691 [==============================] - 0s 59us/step - loss: 2.5022 - acc: 0.5948\n",
      "Epoch 27/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 2.1312 - acc: 0.5933\n",
      "Epoch 28/40\n",
      "691/691 [==============================] - 0s 48us/step - loss: 1.9128 - acc: 0.5716\n",
      "Epoch 29/40\n",
      "691/691 [==============================] - 0s 44us/step - loss: 1.7590 - acc: 0.5774\n",
      "Epoch 30/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 1.6228 - acc: 0.6035\n",
      "Epoch 31/40\n",
      "691/691 [==============================] - 0s 48us/step - loss: 1.4744 - acc: 0.5948\n",
      "Epoch 32/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 1.3680 - acc: 0.5919\n",
      "Epoch 33/40\n",
      "691/691 [==============================] - 0s 51us/step - loss: 1.2887 - acc: 0.6006\n",
      "Epoch 34/40\n",
      "691/691 [==============================] - 0s 48us/step - loss: 1.2162 - acc: 0.6006\n",
      "Epoch 35/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 1.1260 - acc: 0.6151\n",
      "Epoch 36/40\n",
      "691/691 [==============================] - 0s 48us/step - loss: 1.0566 - acc: 0.6064\n",
      "Epoch 37/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 1.0288 - acc: 0.6310\n",
      "Epoch 38/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.9415 - acc: 0.6252\n",
      "Epoch 39/40\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.9570 - acc: 0.6208\n",
      "Epoch 40/40\n",
      "691/691 [==============================] - 0s 43us/step - loss: 0.8772 - acc: 0.6368\n",
      "77/77 [==============================] - 2s 22ms/step\n",
      "Epoch 1/40\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.2069 - acc: 0.6064\n",
      "Epoch 2/40\n",
      "691/691 [==============================] - 0s 41us/step - loss: 1.1236 - acc: 0.6020\n",
      "Epoch 3/40\n",
      "691/691 [==============================] - 0s 47us/step - loss: 1.0615 - acc: 0.6194\n",
      "Epoch 4/40\n",
      "691/691 [==============================] - 0s 53us/step - loss: 1.0293 - acc: 0.5919\n",
      "Epoch 5/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.9910 - acc: 0.5948\n",
      "Epoch 6/40\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.9618 - acc: 0.6035\n",
      "Epoch 7/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 0.9376 - acc: 0.6020\n",
      "Epoch 8/40\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.9111 - acc: 0.6122\n",
      "Epoch 9/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 0.8912 - acc: 0.6035\n",
      "Epoch 10/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.8675 - acc: 0.5948\n",
      "Epoch 11/40\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.8440 - acc: 0.6078\n",
      "Epoch 12/40\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.8232 - acc: 0.5962\n",
      "Epoch 13/40\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.8144 - acc: 0.5919\n",
      "Epoch 14/40\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.7845 - acc: 0.5962\n",
      "Epoch 15/40\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.7672 - acc: 0.5904\n",
      "Epoch 16/40\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.7542 - acc: 0.6078\n",
      "Epoch 17/40\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.7465 - acc: 0.5977\n",
      "Epoch 18/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.7455 - acc: 0.6093\n",
      "Epoch 19/40\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.7308 - acc: 0.5962\n",
      "Epoch 20/40\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.7175 - acc: 0.6194\n",
      "Epoch 21/40\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.7118 - acc: 0.6266\n",
      "Epoch 22/40\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.7065 - acc: 0.6064\n",
      "Epoch 23/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.7008 - acc: 0.6425\n",
      "Epoch 24/40\n",
      "691/691 [==============================] - 0s 49us/step - loss: 0.6963 - acc: 0.6165\n",
      "Epoch 25/40\n",
      "691/691 [==============================] - 0s 63us/step - loss: 0.6881 - acc: 0.6498\n",
      "Epoch 26/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.6817 - acc: 0.6397\n",
      "Epoch 27/40\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.6831 - acc: 0.6715\n",
      "Epoch 28/40\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.6751 - acc: 0.6715\n",
      "Epoch 29/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.6674 - acc: 0.6541\n",
      "Epoch 30/40\n",
      "691/691 [==============================] - 0s 63us/step - loss: 0.6683 - acc: 0.6744\n",
      "Epoch 31/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.6656 - acc: 0.6729\n",
      "Epoch 32/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 0.6548 - acc: 0.6816\n",
      "Epoch 33/40\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.6497 - acc: 0.6918\n",
      "Epoch 34/40\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.6526 - acc: 0.6700\n",
      "Epoch 35/40\n",
      "691/691 [==============================] - 0s 60us/step - loss: 0.6572 - acc: 0.6816\n",
      "Epoch 36/40\n",
      "691/691 [==============================] - 0s 62us/step - loss: 0.6447 - acc: 0.6860\n",
      "Epoch 37/40\n",
      "691/691 [==============================] - 0s 60us/step - loss: 0.6409 - acc: 0.6932\n",
      "Epoch 38/40\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.6433 - acc: 0.6787\n",
      "Epoch 39/40\n",
      "691/691 [==============================] - 0s 49us/step - loss: 0.6371 - acc: 0.6874\n",
      "Epoch 40/40\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.6341 - acc: 0.6946\n",
      "77/77 [==============================] - 2s 23ms/step\n",
      "Epoch 1/40\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 5.6353 - acc: 0.6483\n",
      "Epoch 2/40\n",
      "691/691 [==============================] - 0s 48us/step - loss: 5.6003 - acc: 0.6483\n",
      "Epoch 3/40\n",
      "691/691 [==============================] - 0s 48us/step - loss: 5.4871 - acc: 0.6498\n",
      "Epoch 4/40\n",
      "691/691 [==============================] - 0s 51us/step - loss: 5.1905 - acc: 0.6498\n",
      "Epoch 5/40\n",
      "691/691 [==============================] - 0s 49us/step - loss: 4.5785 - acc: 0.6425\n",
      "Epoch 6/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 4.2241 - acc: 0.6049\n",
      "Epoch 7/40\n",
      "691/691 [==============================] - 0s 48us/step - loss: 4.2112 - acc: 0.5991\n",
      "Epoch 8/40\n",
      "691/691 [==============================] - 0s 49us/step - loss: 4.1043 - acc: 0.6064\n",
      "Epoch 9/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 4.0129 - acc: 0.6136\n",
      "Epoch 10/40\n",
      "691/691 [==============================] - 0s 47us/step - loss: 3.9515 - acc: 0.6093\n",
      "Epoch 11/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 3.8963 - acc: 0.6064\n",
      "Epoch 12/40\n",
      "691/691 [==============================] - 0s 51us/step - loss: 3.8417 - acc: 0.6107\n",
      "Epoch 13/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 3.8048 - acc: 0.6151\n",
      "Epoch 14/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 3.7406 - acc: 0.6252\n",
      "Epoch 15/40\n",
      "691/691 [==============================] - 0s 47us/step - loss: 3.7147 - acc: 0.6179\n",
      "Epoch 16/40\n",
      "691/691 [==============================] - 0s 56us/step - loss: 3.6789 - acc: 0.6252\n",
      "Epoch 17/40\n",
      "691/691 [==============================] - 0s 54us/step - loss: 3.6310 - acc: 0.6223\n",
      "Epoch 18/40\n",
      "691/691 [==============================] - 0s 51us/step - loss: 3.6232 - acc: 0.6107\n",
      "Epoch 19/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 3.5793 - acc: 0.6295\n",
      "Epoch 20/40\n",
      "691/691 [==============================] - 0s 44us/step - loss: 3.5490 - acc: 0.6324\n",
      "Epoch 21/40\n",
      "691/691 [==============================] - 0s 48us/step - loss: 3.5322 - acc: 0.6324\n",
      "Epoch 22/40\n",
      "691/691 [==============================] - 0s 53us/step - loss: 3.5079 - acc: 0.6397\n",
      "Epoch 23/40\n",
      "691/691 [==============================] - 0s 51us/step - loss: 3.4755 - acc: 0.6382\n",
      "Epoch 24/40\n",
      "691/691 [==============================] - 0s 47us/step - loss: 3.4611 - acc: 0.6411\n",
      "Epoch 25/40\n",
      "691/691 [==============================] - 0s 47us/step - loss: 3.4594 - acc: 0.6397\n",
      "Epoch 26/40\n",
      "691/691 [==============================] - 0s 47us/step - loss: 3.4208 - acc: 0.6483\n",
      "Epoch 27/40\n",
      "691/691 [==============================] - 0s 62us/step - loss: 3.4238 - acc: 0.6454\n",
      "Epoch 28/40\n",
      "691/691 [==============================] - 0s 58us/step - loss: 3.3975 - acc: 0.6512\n",
      "Epoch 29/40\n",
      "691/691 [==============================] - 0s 47us/step - loss: 3.3800 - acc: 0.6512\n",
      "Epoch 30/40\n",
      "691/691 [==============================] - 0s 44us/step - loss: 3.3671 - acc: 0.6527\n",
      "Epoch 31/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 3.3536 - acc: 0.6570\n",
      "Epoch 32/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 3.3492 - acc: 0.6556\n",
      "Epoch 33/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 3.3558 - acc: 0.6339\n",
      "Epoch 34/40\n",
      "691/691 [==============================] - 0s 48us/step - loss: 3.3112 - acc: 0.6599\n",
      "Epoch 35/40\n",
      "691/691 [==============================] - 0s 50us/step - loss: 3.3032 - acc: 0.6556\n",
      "Epoch 36/40\n",
      "691/691 [==============================] - 0s 53us/step - loss: 3.2883 - acc: 0.6585\n",
      "Epoch 37/40\n",
      "691/691 [==============================] - 0s 45us/step - loss: 3.2725 - acc: 0.6454\n",
      "Epoch 38/40\n",
      "691/691 [==============================] - 0s 46us/step - loss: 3.2758 - acc: 0.6556\n",
      "Epoch 39/40\n",
      "691/691 [==============================] - 0s 52us/step - loss: 3.2427 - acc: 0.6527\n",
      "Epoch 40/40\n",
      "691/691 [==============================] - 0s 57us/step - loss: 3.2302 - acc: 0.6483\n",
      "77/77 [==============================] - 2s 24ms/step\n",
      "Epoch 1/40\n",
      "692/692 [==============================] - 4s 6ms/step - loss: 6.8208 - acc: 0.5058\n",
      "Epoch 2/40\n",
      "692/692 [==============================] - 0s 49us/step - loss: 6.2059 - acc: 0.5246\n",
      "Epoch 3/40\n",
      "692/692 [==============================] - 0s 49us/step - loss: 5.5534 - acc: 0.5665\n",
      "Epoch 4/40\n",
      "692/692 [==============================] - 0s 50us/step - loss: 5.0506 - acc: 0.6113\n",
      "Epoch 5/40\n",
      "692/692 [==============================] - 0s 54us/step - loss: 4.9503 - acc: 0.6272\n",
      "Epoch 6/40\n",
      "692/692 [==============================] - 0s 45us/step - loss: 4.8772 - acc: 0.6301\n",
      "Epoch 7/40\n",
      "692/692 [==============================] - 0s 44us/step - loss: 4.7844 - acc: 0.6301\n",
      "Epoch 8/40\n",
      "692/692 [==============================] - 0s 51us/step - loss: 4.6127 - acc: 0.6243\n",
      "Epoch 9/40\n",
      "692/692 [==============================] - 0s 49us/step - loss: 4.2839 - acc: 0.6214\n",
      "Epoch 10/40\n",
      "692/692 [==============================] - 0s 45us/step - loss: 3.7737 - acc: 0.5751\n",
      "Epoch 11/40\n",
      "692/692 [==============================] - 0s 48us/step - loss: 3.3067 - acc: 0.4928\n",
      "Epoch 12/40\n",
      "692/692 [==============================] - 0s 51us/step - loss: 3.0686 - acc: 0.5000\n",
      "Epoch 13/40\n",
      "692/692 [==============================] - 0s 52us/step - loss: 2.8435 - acc: 0.5087\n",
      "Epoch 14/40\n",
      "692/692 [==============================] - 0s 45us/step - loss: 2.6247 - acc: 0.5217\n",
      "Epoch 15/40\n",
      "692/692 [==============================] - 0s 47us/step - loss: 2.4307 - acc: 0.5448\n",
      "Epoch 16/40\n",
      "692/692 [==============================] - 0s 49us/step - loss: 2.3018 - acc: 0.5434\n",
      "Epoch 17/40\n",
      "692/692 [==============================] - 0s 54us/step - loss: 2.2153 - acc: 0.5723\n",
      "Epoch 18/40\n",
      "692/692 [==============================] - 0s 48us/step - loss: 2.0965 - acc: 0.5723\n",
      "Epoch 19/40\n",
      "692/692 [==============================] - 0s 48us/step - loss: 2.0007 - acc: 0.5780\n",
      "Epoch 20/40\n",
      "692/692 [==============================] - 0s 46us/step - loss: 1.8923 - acc: 0.6026\n",
      "Epoch 21/40\n",
      "692/692 [==============================] - 0s 50us/step - loss: 1.7929 - acc: 0.6026\n",
      "Epoch 22/40\n",
      "692/692 [==============================] - 0s 46us/step - loss: 1.6981 - acc: 0.6055\n",
      "Epoch 23/40\n",
      "692/692 [==============================] - 0s 47us/step - loss: 1.5986 - acc: 0.6098\n",
      "Epoch 24/40\n",
      "692/692 [==============================] - 0s 51us/step - loss: 1.5156 - acc: 0.6055\n",
      "Epoch 25/40\n",
      "692/692 [==============================] - 0s 50us/step - loss: 1.4015 - acc: 0.6315\n",
      "Epoch 26/40\n",
      "692/692 [==============================] - 0s 47us/step - loss: 1.3218 - acc: 0.6127\n",
      "Epoch 27/40\n",
      "692/692 [==============================] - 0s 47us/step - loss: 1.2456 - acc: 0.6257\n",
      "Epoch 28/40\n",
      "692/692 [==============================] - 0s 51us/step - loss: 1.1772 - acc: 0.6185\n",
      "Epoch 29/40\n",
      "692/692 [==============================] - 0s 54us/step - loss: 1.1234 - acc: 0.6315\n",
      "Epoch 30/40\n",
      "692/692 [==============================] - 0s 51us/step - loss: 1.0542 - acc: 0.6199\n",
      "Epoch 31/40\n",
      "692/692 [==============================] - 0s 48us/step - loss: 0.9678 - acc: 0.6445\n",
      "Epoch 32/40\n",
      "692/692 [==============================] - 0s 48us/step - loss: 0.8946 - acc: 0.6445\n",
      "Epoch 33/40\n",
      "692/692 [==============================] - 0s 48us/step - loss: 0.8388 - acc: 0.6474\n",
      "Epoch 34/40\n",
      "692/692 [==============================] - 0s 55us/step - loss: 0.7987 - acc: 0.6488\n",
      "Epoch 35/40\n",
      "692/692 [==============================] - 0s 47us/step - loss: 0.7745 - acc: 0.6720\n",
      "Epoch 36/40\n",
      "692/692 [==============================] - 0s 47us/step - loss: 0.7786 - acc: 0.6792\n",
      "Epoch 37/40\n",
      "692/692 [==============================] - 0s 48us/step - loss: 0.7477 - acc: 0.6503\n",
      "Epoch 38/40\n",
      "692/692 [==============================] - 0s 53us/step - loss: 0.7627 - acc: 0.6806\n",
      "Epoch 39/40\n",
      "692/692 [==============================] - 0s 57us/step - loss: 0.7408 - acc: 0.6590\n",
      "Epoch 40/40\n",
      "692/692 [==============================] - 0s 53us/step - loss: 0.7334 - acc: 0.6734\n",
      "76/76 [==============================] - 2s 24ms/step\n",
      "Epoch 1/40\n",
      "692/692 [==============================] - 4s 6ms/step - loss: 4.1133 - acc: 0.6040\n",
      "Epoch 2/40\n",
      "692/692 [==============================] - 0s 44us/step - loss: 3.9119 - acc: 0.6387\n",
      "Epoch 3/40\n",
      "692/692 [==============================] - 0s 49us/step - loss: 3.9262 - acc: 0.6387\n",
      "Epoch 4/40\n",
      "692/692 [==============================] - 0s 47us/step - loss: 3.8429 - acc: 0.6358\n",
      "Epoch 5/40\n",
      "692/692 [==============================] - 0s 46us/step - loss: 3.7984 - acc: 0.6286\n",
      "Epoch 6/40\n",
      "692/692 [==============================] - 0s 47us/step - loss: 3.7317 - acc: 0.6243\n",
      "Epoch 7/40\n",
      "692/692 [==============================] - 0s 46us/step - loss: 3.6494 - acc: 0.6228\n",
      "Epoch 8/40\n",
      "692/692 [==============================] - 0s 51us/step - loss: 3.5805 - acc: 0.6142\n",
      "Epoch 9/40\n",
      "692/692 [==============================] - 0s 52us/step - loss: 3.5079 - acc: 0.6113\n",
      "Epoch 10/40\n",
      "692/692 [==============================] - 0s 45us/step - loss: 3.4792 - acc: 0.6040\n",
      "Epoch 11/40\n",
      "692/692 [==============================] - 0s 46us/step - loss: 3.4238 - acc: 0.6026\n",
      "Epoch 12/40\n",
      "692/692 [==============================] - 0s 48us/step - loss: 3.3873 - acc: 0.6084\n",
      "Epoch 13/40\n",
      "692/692 [==============================] - 0s 56us/step - loss: 3.3280 - acc: 0.5968\n",
      "Epoch 14/40\n",
      "692/692 [==============================] - 0s 54us/step - loss: 3.2497 - acc: 0.5968\n",
      "Epoch 15/40\n",
      "692/692 [==============================] - 0s 47us/step - loss: 3.1989 - acc: 0.6084\n",
      "Epoch 16/40\n",
      "692/692 [==============================] - 0s 46us/step - loss: 3.1594 - acc: 0.6012\n",
      "Epoch 17/40\n",
      "692/692 [==============================] - 0s 47us/step - loss: 3.1264 - acc: 0.6012\n",
      "Epoch 18/40\n",
      "692/692 [==============================] - 0s 52us/step - loss: 3.0580 - acc: 0.5925\n",
      "Epoch 19/40\n",
      "692/692 [==============================] - 0s 52us/step - loss: 3.0634 - acc: 0.5665\n",
      "Epoch 20/40\n",
      "692/692 [==============================] - 0s 50us/step - loss: 2.9786 - acc: 0.5809\n",
      "Epoch 21/40\n",
      "692/692 [==============================] - 0s 46us/step - loss: 2.9383 - acc: 0.6012\n",
      "Epoch 22/40\n",
      "692/692 [==============================] - 0s 46us/step - loss: 2.8773 - acc: 0.5737\n",
      "Epoch 23/40\n",
      "692/692 [==============================] - 0s 46us/step - loss: 2.8113 - acc: 0.5766\n",
      "Epoch 24/40\n",
      "692/692 [==============================] - 0s 54us/step - loss: 2.7585 - acc: 0.5925\n",
      "Epoch 25/40\n",
      "692/692 [==============================] - 0s 53us/step - loss: 2.6732 - acc: 0.5867\n",
      "Epoch 26/40\n",
      "692/692 [==============================] - 0s 49us/step - loss: 2.6437 - acc: 0.5448\n",
      "Epoch 27/40\n",
      "692/692 [==============================] - 0s 48us/step - loss: 2.5690 - acc: 0.5954\n",
      "Epoch 28/40\n",
      "692/692 [==============================] - 0s 46us/step - loss: 2.4901 - acc: 0.5925\n",
      "Epoch 29/40\n",
      "692/692 [==============================] - 0s 56us/step - loss: 2.4329 - acc: 0.5621\n",
      "Epoch 30/40\n",
      "692/692 [==============================] - 0s 54us/step - loss: 2.3667 - acc: 0.5780\n",
      "Epoch 31/40\n",
      "692/692 [==============================] - 0s 53us/step - loss: 2.3141 - acc: 0.5751\n",
      "Epoch 32/40\n",
      "692/692 [==============================] - 0s 45us/step - loss: 2.2433 - acc: 0.5737\n",
      "Epoch 33/40\n",
      "692/692 [==============================] - 0s 45us/step - loss: 2.1803 - acc: 0.6026\n",
      "Epoch 34/40\n",
      "692/692 [==============================] - 0s 47us/step - loss: 2.1076 - acc: 0.5737\n",
      "Epoch 35/40\n",
      "692/692 [==============================] - 0s 59us/step - loss: 2.0444 - acc: 0.5824\n",
      "Epoch 36/40\n",
      "692/692 [==============================] - 0s 52us/step - loss: 1.9867 - acc: 0.5954\n",
      "Epoch 37/40\n",
      "692/692 [==============================] - 0s 48us/step - loss: 1.9187 - acc: 0.6040\n",
      "Epoch 38/40\n",
      "692/692 [==============================] - 0s 45us/step - loss: 1.8784 - acc: 0.5954\n",
      "Epoch 39/40\n",
      "692/692 [==============================] - 0s 46us/step - loss: 1.8200 - acc: 0.6012\n",
      "Epoch 40/40\n",
      "692/692 [==============================] - 0s 47us/step - loss: 1.7688 - acc: 0.6012\n",
      "76/76 [==============================] - 2s 24ms/step\n",
      "Epoch 1/60\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 10.3213 - acc: 0.3415\n",
      "Epoch 2/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 9.3604 - acc: 0.3430\n",
      "Epoch 3/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 6.7027 - acc: 0.3502\n",
      "Epoch 4/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 4.0359 - acc: 0.4689\n",
      "Epoch 5/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 3.5398 - acc: 0.5369\n",
      "Epoch 6/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 3.3874 - acc: 0.5499\n",
      "Epoch 7/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 2.9296 - acc: 0.5456\n",
      "Epoch 8/60\n",
      "691/691 [==============================] - 0s 45us/step - loss: 2.5701 - acc: 0.5326\n",
      "Epoch 9/60\n",
      "691/691 [==============================] - 0s 45us/step - loss: 2.2307 - acc: 0.5514\n",
      "Epoch 10/60\n",
      "691/691 [==============================] - 0s 60us/step - loss: 1.9321 - acc: 0.5760\n",
      "Epoch 11/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 1.6912 - acc: 0.5818\n",
      "Epoch 12/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 1.4754 - acc: 0.6020\n",
      "Epoch 13/60\n",
      "691/691 [==============================] - 0s 45us/step - loss: 1.3012 - acc: 0.6035\n",
      "Epoch 14/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 1.1605 - acc: 0.6136\n",
      "Epoch 15/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 1.0714 - acc: 0.6151\n",
      "Epoch 16/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.9952 - acc: 0.6208\n",
      "Epoch 17/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.9482 - acc: 0.6194\n",
      "Epoch 18/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.9282 - acc: 0.6411\n",
      "Epoch 19/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.8883 - acc: 0.6208\n",
      "Epoch 20/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.8614 - acc: 0.6411\n",
      "Epoch 21/60\n",
      "691/691 [==============================] - 0s 45us/step - loss: 0.8387 - acc: 0.6295\n",
      "Epoch 22/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.8195 - acc: 0.6310\n",
      "Epoch 23/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.8072 - acc: 0.6411\n",
      "Epoch 24/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.7855 - acc: 0.6397\n",
      "Epoch 25/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.7735 - acc: 0.6382\n",
      "Epoch 26/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.7671 - acc: 0.6483\n",
      "Epoch 27/60\n",
      "691/691 [==============================] - 0s 45us/step - loss: 0.7519 - acc: 0.6527\n",
      "Epoch 28/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.7368 - acc: 0.6397\n",
      "Epoch 29/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.7271 - acc: 0.6614\n",
      "Epoch 30/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.7213 - acc: 0.6715\n",
      "Epoch 31/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.7097 - acc: 0.6643\n",
      "Epoch 32/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.7055 - acc: 0.6628\n",
      "Epoch 33/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.6951 - acc: 0.6700\n",
      "Epoch 34/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.6940 - acc: 0.6758\n",
      "Epoch 35/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.6847 - acc: 0.6744\n",
      "Epoch 36/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.6800 - acc: 0.6831\n",
      "Epoch 37/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.6739 - acc: 0.6903\n",
      "Epoch 38/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.6738 - acc: 0.6946\n",
      "Epoch 39/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.6651 - acc: 0.6903\n",
      "Epoch 40/60\n",
      "691/691 [==============================] - 0s 44us/step - loss: 0.6606 - acc: 0.6975\n",
      "Epoch 41/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.6597 - acc: 0.6946\n",
      "Epoch 42/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.6548 - acc: 0.6946\n",
      "Epoch 43/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.6631 - acc: 0.6686\n",
      "Epoch 44/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.6538 - acc: 0.6932\n",
      "Epoch 45/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.6472 - acc: 0.6961\n",
      "Epoch 46/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.6500 - acc: 0.6845\n",
      "Epoch 47/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.6411 - acc: 0.6918\n",
      "Epoch 48/60\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.6454 - acc: 0.6860\n",
      "Epoch 49/60\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.6369 - acc: 0.6903\n",
      "Epoch 50/60\n",
      "691/691 [==============================] - 0s 45us/step - loss: 0.6429 - acc: 0.6845\n",
      "Epoch 51/60\n",
      "691/691 [==============================] - 0s 44us/step - loss: 0.6311 - acc: 0.6932\n",
      "Epoch 52/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.6311 - acc: 0.7077\n",
      "Epoch 53/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.6271 - acc: 0.6918\n",
      "Epoch 54/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.6276 - acc: 0.6845\n",
      "Epoch 55/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.6296 - acc: 0.6903\n",
      "Epoch 56/60\n",
      "691/691 [==============================] - 0s 45us/step - loss: 0.6273 - acc: 0.6946\n",
      "Epoch 57/60\n",
      "691/691 [==============================] - 0s 43us/step - loss: 0.6199 - acc: 0.6903\n",
      "Epoch 58/60\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.6157 - acc: 0.6889\n",
      "Epoch 59/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.6331 - acc: 0.7033\n",
      "Epoch 60/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.6273 - acc: 0.6990\n",
      "77/77 [==============================] - 2s 24ms/step\n",
      "Epoch 1/60\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 9.7593 - acc: 0.3459\n",
      "Epoch 2/60\n",
      "691/691 [==============================] - 0s 42us/step - loss: 9.1450 - acc: 0.3589\n",
      "Epoch 3/60\n",
      "691/691 [==============================] - 0s 45us/step - loss: 8.3347 - acc: 0.3632\n",
      "Epoch 4/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 7.7492 - acc: 0.4255\n",
      "Epoch 5/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 7.4071 - acc: 0.4718\n",
      "Epoch 6/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 6.8132 - acc: 0.4978\n",
      "Epoch 7/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 5.6726 - acc: 0.5456\n",
      "Epoch 8/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 4.2740 - acc: 0.6020\n",
      "Epoch 9/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 4.0877 - acc: 0.6281\n",
      "Epoch 10/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 4.1074 - acc: 0.6310\n",
      "Epoch 11/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 3.9618 - acc: 0.6281\n",
      "Epoch 12/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 3.9033 - acc: 0.6252\n",
      "Epoch 13/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 3.8361 - acc: 0.6266\n",
      "Epoch 14/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 3.7743 - acc: 0.6295\n",
      "Epoch 15/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 3.7125 - acc: 0.6281\n",
      "Epoch 16/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 3.6526 - acc: 0.6324\n",
      "Epoch 17/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 3.5929 - acc: 0.6310\n",
      "Epoch 18/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 3.5404 - acc: 0.6339\n",
      "Epoch 19/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 3.4897 - acc: 0.6368\n",
      "Epoch 20/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 3.4362 - acc: 0.6339\n",
      "Epoch 21/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 3.3645 - acc: 0.6281\n",
      "Epoch 22/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 3.2594 - acc: 0.6310\n",
      "Epoch 23/60\n",
      "691/691 [==============================] - 0s 45us/step - loss: 2.8651 - acc: 0.6179\n",
      "Epoch 24/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 2.0656 - acc: 0.5239\n",
      "Epoch 25/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 1.7995 - acc: 0.5919\n",
      "Epoch 26/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 1.5821 - acc: 0.5615\n",
      "Epoch 27/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 1.4203 - acc: 0.5962\n",
      "Epoch 28/60\n",
      "691/691 [==============================] - 0s 51us/step - loss: 1.3434 - acc: 0.5673\n",
      "Epoch 29/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 1.2305 - acc: 0.6078\n",
      "Epoch 30/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 1.1413 - acc: 0.6136\n",
      "Epoch 31/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 1.0846 - acc: 0.5948\n",
      "Epoch 32/60\n",
      "691/691 [==============================] - 0s 43us/step - loss: 1.0444 - acc: 0.6382\n",
      "Epoch 33/60\n",
      "691/691 [==============================] - 0s 45us/step - loss: 0.9998 - acc: 0.6049\n",
      "Epoch 34/60\n",
      "691/691 [==============================] - 0s 61us/step - loss: 0.9751 - acc: 0.6570\n",
      "Epoch 35/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 0.9289 - acc: 0.6353\n",
      "Epoch 36/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.8980 - acc: 0.6411\n",
      "Epoch 37/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.8918 - acc: 0.6425\n",
      "Epoch 38/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 0.8522 - acc: 0.6440\n",
      "Epoch 39/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.8515 - acc: 0.6411\n",
      "Epoch 40/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.8295 - acc: 0.6599\n",
      "Epoch 41/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.8101 - acc: 0.6729\n",
      "Epoch 42/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.8021 - acc: 0.6715\n",
      "Epoch 43/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.7959 - acc: 0.6556\n",
      "Epoch 44/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.7803 - acc: 0.6744\n",
      "Epoch 45/60\n",
      "691/691 [==============================] - 0s 44us/step - loss: 0.7692 - acc: 0.6802\n",
      "Epoch 46/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.7823 - acc: 0.6802\n",
      "Epoch 47/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.7672 - acc: 0.6628\n",
      "Epoch 48/60\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.7597 - acc: 0.6700\n",
      "Epoch 49/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.7459 - acc: 0.6874\n",
      "Epoch 50/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.7442 - acc: 0.6773\n",
      "Epoch 51/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.7351 - acc: 0.7004\n",
      "Epoch 52/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.7264 - acc: 0.6831\n",
      "Epoch 53/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 0.7225 - acc: 0.6889\n",
      "Epoch 54/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 0.7293 - acc: 0.6874\n",
      "Epoch 55/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.7391 - acc: 0.6889\n",
      "Epoch 56/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.7216 - acc: 0.6961\n",
      "Epoch 57/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.7060 - acc: 0.6932\n",
      "Epoch 58/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.7099 - acc: 0.6975\n",
      "Epoch 59/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.6932 - acc: 0.7062\n",
      "Epoch 60/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.7136 - acc: 0.6961\n",
      "77/77 [==============================] - 2s 24ms/step\n",
      "Epoch 1/60\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 3.7233 - acc: 0.5774\n",
      "Epoch 2/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 3.5768 - acc: 0.5890\n",
      "Epoch 3/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 3.4821 - acc: 0.6035\n",
      "Epoch 4/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 3.4323 - acc: 0.5847\n",
      "Epoch 5/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 3.3667 - acc: 0.6107\n",
      "Epoch 6/60\n",
      "691/691 [==============================] - 0s 51us/step - loss: 3.3095 - acc: 0.6223\n",
      "Epoch 7/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 3.2827 - acc: 0.6165\n",
      "Epoch 8/60\n",
      "691/691 [==============================] - 0s 45us/step - loss: 3.2461 - acc: 0.6107\n",
      "Epoch 9/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 3.2125 - acc: 0.6165\n",
      "Epoch 10/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 3.1816 - acc: 0.6165\n",
      "Epoch 11/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 3.0796 - acc: 0.6136\n",
      "Epoch 12/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 1.7353 - acc: 0.5876\n",
      "Epoch 13/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 1.5108 - acc: 0.6165\n",
      "Epoch 14/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 1.2729 - acc: 0.6165\n",
      "Epoch 15/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 1.2151 - acc: 0.6208\n",
      "Epoch 16/60\n",
      "691/691 [==============================] - 0s 51us/step - loss: 1.1545 - acc: 0.6295\n",
      "Epoch 17/60\n",
      "691/691 [==============================] - 0s 45us/step - loss: 1.1118 - acc: 0.6425\n",
      "Epoch 18/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 1.0740 - acc: 0.6295\n",
      "Epoch 19/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 1.0387 - acc: 0.6541\n",
      "Epoch 20/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 1.0234 - acc: 0.6556\n",
      "Epoch 21/60\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.9882 - acc: 0.6483\n",
      "Epoch 22/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.9817 - acc: 0.6700\n",
      "Epoch 23/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.9550 - acc: 0.6614\n",
      "Epoch 24/60\n",
      "691/691 [==============================] - 0s 45us/step - loss: 0.9611 - acc: 0.6512\n",
      "Epoch 25/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.9133 - acc: 0.6657\n",
      "Epoch 26/60\n",
      "691/691 [==============================] - 0s 62us/step - loss: 0.9089 - acc: 0.6700\n",
      "Epoch 27/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.8869 - acc: 0.6671\n",
      "Epoch 28/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.8809 - acc: 0.6816\n",
      "Epoch 29/60\n",
      "691/691 [==============================] - 0s 45us/step - loss: 0.8634 - acc: 0.6787\n",
      "Epoch 30/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.8668 - acc: 0.6440\n",
      "Epoch 31/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.8768 - acc: 0.6758\n",
      "Epoch 32/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.8711 - acc: 0.6599\n",
      "Epoch 33/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.8584 - acc: 0.6512\n",
      "Epoch 34/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.8357 - acc: 0.6874\n",
      "Epoch 35/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.7983 - acc: 0.6874\n",
      "Epoch 36/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.7897 - acc: 0.6903\n",
      "Epoch 37/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.7780 - acc: 0.6889\n",
      "Epoch 38/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.7710 - acc: 0.6787\n",
      "Epoch 39/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.7661 - acc: 0.6787\n",
      "Epoch 40/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.7578 - acc: 0.6874\n",
      "Epoch 41/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.7514 - acc: 0.6802\n",
      "Epoch 42/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.7668 - acc: 0.6831\n",
      "Epoch 43/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 0.7339 - acc: 0.6889\n",
      "Epoch 44/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.7280 - acc: 0.6758\n",
      "Epoch 45/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.7346 - acc: 0.6874\n",
      "Epoch 46/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.7382 - acc: 0.6773\n",
      "Epoch 47/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.7350 - acc: 0.6903\n",
      "Epoch 48/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.7235 - acc: 0.6758\n",
      "Epoch 49/60\n",
      "691/691 [==============================] - 0s 45us/step - loss: 0.7100 - acc: 0.6990\n",
      "Epoch 50/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.7532 - acc: 0.6671\n",
      "Epoch 51/60\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.7054 - acc: 0.6889\n",
      "Epoch 52/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.6972 - acc: 0.6932\n",
      "Epoch 53/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.6964 - acc: 0.6903\n",
      "Epoch 54/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.6995 - acc: 0.6715\n",
      "Epoch 55/60\n",
      "691/691 [==============================] - 0s 44us/step - loss: 0.6910 - acc: 0.6961\n",
      "Epoch 56/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.6971 - acc: 0.6889\n",
      "Epoch 57/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.6961 - acc: 0.6657\n",
      "Epoch 58/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.6988 - acc: 0.6773\n",
      "Epoch 59/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.6971 - acc: 0.6860\n",
      "Epoch 60/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.7080 - acc: 0.6787\n",
      "77/77 [==============================] - 2s 24ms/step\n",
      "Epoch 1/60\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 5.5171 - acc: 0.6541\n",
      "Epoch 2/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 5.5021 - acc: 0.6556\n",
      "Epoch 3/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 5.4949 - acc: 0.6570\n",
      "Epoch 4/60\n",
      "691/691 [==============================] - 0s 45us/step - loss: 5.4793 - acc: 0.6556\n",
      "Epoch 5/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 5.4766 - acc: 0.6570\n",
      "Epoch 6/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 5.4432 - acc: 0.6570\n",
      "Epoch 7/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 5.3471 - acc: 0.6570\n",
      "Epoch 8/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 5.3000 - acc: 0.6585\n",
      "Epoch 9/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 5.2218 - acc: 0.6498\n",
      "Epoch 10/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 5.0395 - acc: 0.6411\n",
      "Epoch 11/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 4.8269 - acc: 0.6208\n",
      "Epoch 12/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 4.8139 - acc: 0.6020\n",
      "Epoch 13/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 4.7271 - acc: 0.6107\n",
      "Epoch 14/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 4.6962 - acc: 0.6078\n",
      "Epoch 15/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 4.6195 - acc: 0.6093\n",
      "Epoch 16/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 4.5863 - acc: 0.5904\n",
      "Epoch 17/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 4.5095 - acc: 0.5948\n",
      "Epoch 18/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 4.4567 - acc: 0.6136\n",
      "Epoch 19/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 4.4272 - acc: 0.5991\n",
      "Epoch 20/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 4.2937 - acc: 0.5890\n",
      "Epoch 21/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 4.1171 - acc: 0.5904\n",
      "Epoch 22/60\n",
      "691/691 [==============================] - 0s 51us/step - loss: 3.9277 - acc: 0.5673\n",
      "Epoch 23/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 3.7204 - acc: 0.5441\n",
      "Epoch 24/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 3.5837 - acc: 0.5615\n",
      "Epoch 25/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 3.4116 - acc: 0.5427\n",
      "Epoch 26/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 3.2952 - acc: 0.5499\n",
      "Epoch 27/60\n",
      "691/691 [==============================] - 0s 44us/step - loss: 3.1304 - acc: 0.5514\n",
      "Epoch 28/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 2.9854 - acc: 0.5398\n",
      "Epoch 29/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 2.8307 - acc: 0.5456\n",
      "Epoch 30/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 2.6800 - acc: 0.5601\n",
      "Epoch 31/60\n",
      "691/691 [==============================] - 0s 45us/step - loss: 2.4813 - acc: 0.5268\n",
      "Epoch 32/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 2.2515 - acc: 0.5586\n",
      "Epoch 33/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 2.0056 - acc: 0.5586\n",
      "Epoch 34/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 1.8002 - acc: 0.5615\n",
      "Epoch 35/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 1.6389 - acc: 0.5832\n",
      "Epoch 36/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 1.4674 - acc: 0.5847\n",
      "Epoch 37/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 1.3219 - acc: 0.5847\n",
      "Epoch 38/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 1.2148 - acc: 0.5933\n",
      "Epoch 39/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 1.0776 - acc: 0.6006\n",
      "Epoch 40/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.9988 - acc: 0.5991\n",
      "Epoch 41/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.9235 - acc: 0.6049\n",
      "Epoch 42/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.8559 - acc: 0.6122\n",
      "Epoch 43/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.8026 - acc: 0.6223\n",
      "Epoch 44/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.7832 - acc: 0.6266\n",
      "Epoch 45/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.7568 - acc: 0.6368\n",
      "Epoch 46/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.7419 - acc: 0.6281\n",
      "Epoch 47/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 0.6908 - acc: 0.6512\n",
      "Epoch 48/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.6767 - acc: 0.6585\n",
      "Epoch 49/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.6687 - acc: 0.6700\n",
      "Epoch 50/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.6743 - acc: 0.6570\n",
      "Epoch 51/60\n",
      "691/691 [==============================] - 0s 45us/step - loss: 0.6577 - acc: 0.6585\n",
      "Epoch 52/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.6352 - acc: 0.6802\n",
      "Epoch 53/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.6297 - acc: 0.6758\n",
      "Epoch 54/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.6227 - acc: 0.6657\n",
      "Epoch 55/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.6213 - acc: 0.6744\n",
      "Epoch 56/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 0.6271 - acc: 0.6657\n",
      "Epoch 57/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.6271 - acc: 0.6860\n",
      "Epoch 58/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 0.6537 - acc: 0.6368\n",
      "Epoch 59/60\n",
      "691/691 [==============================] - 0s 45us/step - loss: 0.6635 - acc: 0.6686\n",
      "Epoch 60/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.6112 - acc: 0.6715\n",
      "77/77 [==============================] - 2s 25ms/step\n",
      "Epoch 1/60\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 10.2813 - acc: 0.3488\n",
      "Epoch 2/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 10.1994 - acc: 0.3488\n",
      "Epoch 3/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 9.8922 - acc: 0.3502\n",
      "Epoch 4/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 8.6708 - acc: 0.3415\n",
      "Epoch 5/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 6.7263 - acc: 0.3444\n",
      "Epoch 6/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 4.8488 - acc: 0.4342\n",
      "Epoch 7/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 3.7422 - acc: 0.5441\n",
      "Epoch 8/60\n",
      "691/691 [==============================] - 0s 51us/step - loss: 3.7156 - acc: 0.6020\n",
      "Epoch 9/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 3.3322 - acc: 0.5528\n",
      "Epoch 10/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 3.1664 - acc: 0.4906\n",
      "Epoch 11/60\n",
      "691/691 [==============================] - 0s 51us/step - loss: 2.9379 - acc: 0.4935\n",
      "Epoch 12/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 2.7844 - acc: 0.5109\n",
      "Epoch 13/60\n",
      "691/691 [==============================] - 0s 43us/step - loss: 2.6214 - acc: 0.5065\n",
      "Epoch 14/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 2.4731 - acc: 0.4993\n",
      "Epoch 15/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 2.3197 - acc: 0.5137\n",
      "Epoch 16/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 2.1748 - acc: 0.4993\n",
      "Epoch 17/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 2.0302 - acc: 0.5065\n",
      "Epoch 18/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 1.8995 - acc: 0.5152\n",
      "Epoch 19/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 1.7777 - acc: 0.5051\n",
      "Epoch 20/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 1.6655 - acc: 0.5094\n",
      "Epoch 21/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 1.5651 - acc: 0.5384\n",
      "Epoch 22/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 1.4686 - acc: 0.5181\n",
      "Epoch 23/60\n",
      "691/691 [==============================] - 0s 63us/step - loss: 1.3751 - acc: 0.5499\n",
      "Epoch 24/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 1.2874 - acc: 0.5311\n",
      "Epoch 25/60\n",
      "691/691 [==============================] - 0s 45us/step - loss: 1.2082 - acc: 0.5470\n",
      "Epoch 26/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 1.1093 - acc: 0.5630\n",
      "Epoch 27/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.9436 - acc: 0.5514\n",
      "Epoch 28/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.8831 - acc: 0.6107\n",
      "Epoch 29/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 0.8559 - acc: 0.5890\n",
      "Epoch 30/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.8211 - acc: 0.5933\n",
      "Epoch 31/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.7799 - acc: 0.6339\n",
      "Epoch 32/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.7605 - acc: 0.6179\n",
      "Epoch 33/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.7471 - acc: 0.6281\n",
      "Epoch 34/60\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.7238 - acc: 0.6368\n",
      "Epoch 35/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 0.7208 - acc: 0.6469\n",
      "Epoch 36/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.7106 - acc: 0.6570\n",
      "Epoch 37/60\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.7095 - acc: 0.6440\n",
      "Epoch 38/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.6869 - acc: 0.6512\n",
      "Epoch 39/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.6892 - acc: 0.6614\n",
      "Epoch 40/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.6856 - acc: 0.6541\n",
      "Epoch 41/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.6883 - acc: 0.6614\n",
      "Epoch 42/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.6694 - acc: 0.6643\n",
      "Epoch 43/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.6613 - acc: 0.6802\n",
      "Epoch 44/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.6550 - acc: 0.6860\n",
      "Epoch 45/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.6591 - acc: 0.6831\n",
      "Epoch 46/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 0.6506 - acc: 0.6802\n",
      "Epoch 47/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.6444 - acc: 0.7004\n",
      "Epoch 48/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.6491 - acc: 0.7019\n",
      "Epoch 49/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.6458 - acc: 0.6744\n",
      "Epoch 50/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 0.6334 - acc: 0.6903\n",
      "Epoch 51/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.6304 - acc: 0.7062\n",
      "Epoch 52/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 0.6284 - acc: 0.7004\n",
      "Epoch 53/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.6330 - acc: 0.6961\n",
      "Epoch 54/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.6379 - acc: 0.6946\n",
      "Epoch 55/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.6255 - acc: 0.6787\n",
      "Epoch 56/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.6113 - acc: 0.7178\n",
      "Epoch 57/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 0.6262 - acc: 0.6975\n",
      "Epoch 58/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.6248 - acc: 0.7106\n",
      "Epoch 59/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 0.6205 - acc: 0.7004\n",
      "Epoch 60/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.6223 - acc: 0.6643\n",
      "77/77 [==============================] - 2s 24ms/step\n",
      "Epoch 1/60\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 5.3011 - acc: 0.6397\n",
      "Epoch 2/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 5.1018 - acc: 0.6223\n",
      "Epoch 3/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 4.8463 - acc: 0.5919\n",
      "Epoch 4/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 4.5740 - acc: 0.5572\n",
      "Epoch 5/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 4.1659 - acc: 0.5297\n",
      "Epoch 6/60\n",
      "691/691 [==============================] - 0s 44us/step - loss: 3.7044 - acc: 0.4848\n",
      "Epoch 7/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 3.4683 - acc: 0.4978\n",
      "Epoch 8/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 3.2629 - acc: 0.5224\n",
      "Epoch 9/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 3.0888 - acc: 0.5166\n",
      "Epoch 10/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 2.9066 - acc: 0.5094\n",
      "Epoch 11/60\n",
      "691/691 [==============================] - 0s 51us/step - loss: 2.7362 - acc: 0.5022\n",
      "Epoch 12/60\n",
      "691/691 [==============================] - 0s 45us/step - loss: 2.5529 - acc: 0.4993\n",
      "Epoch 13/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 2.3751 - acc: 0.5152\n",
      "Epoch 14/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 2.2139 - acc: 0.5166\n",
      "Epoch 15/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 2.0629 - acc: 0.5326\n",
      "Epoch 16/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 1.9145 - acc: 0.5441\n",
      "Epoch 17/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 1.7927 - acc: 0.5427\n",
      "Epoch 18/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 1.7220 - acc: 0.5311\n",
      "Epoch 19/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 1.5876 - acc: 0.5673\n",
      "Epoch 20/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 1.4836 - acc: 0.5601\n",
      "Epoch 21/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 1.3959 - acc: 0.5702\n",
      "Epoch 22/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 1.3126 - acc: 0.5847\n",
      "Epoch 23/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 1.2390 - acc: 0.5962\n",
      "Epoch 24/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 1.1608 - acc: 0.6035\n",
      "Epoch 25/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 1.1289 - acc: 0.5933\n",
      "Epoch 26/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 1.0506 - acc: 0.5962\n",
      "Epoch 27/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 1.0024 - acc: 0.6208\n",
      "Epoch 28/60\n",
      "691/691 [==============================] - 0s 69us/step - loss: 0.9589 - acc: 0.6223\n",
      "Epoch 29/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.9222 - acc: 0.6324\n",
      "Epoch 30/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.8915 - acc: 0.6425\n",
      "Epoch 31/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.8657 - acc: 0.6469\n",
      "Epoch 32/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.8399 - acc: 0.6425\n",
      "Epoch 33/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.8168 - acc: 0.6425\n",
      "Epoch 34/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 0.8008 - acc: 0.6541\n",
      "Epoch 35/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.7921 - acc: 0.6368\n",
      "Epoch 36/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.7971 - acc: 0.6700\n",
      "Epoch 37/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.7644 - acc: 0.6425\n",
      "Epoch 38/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.7474 - acc: 0.6512\n",
      "Epoch 39/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.7340 - acc: 0.6512\n",
      "Epoch 40/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.7262 - acc: 0.6541\n",
      "Epoch 41/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 0.7134 - acc: 0.6541\n",
      "Epoch 42/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.7145 - acc: 0.6512\n",
      "Epoch 43/60\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.6994 - acc: 0.6599\n",
      "Epoch 44/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.6944 - acc: 0.6657\n",
      "Epoch 45/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.6868 - acc: 0.6729\n",
      "Epoch 46/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.6901 - acc: 0.6614\n",
      "Epoch 47/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.6822 - acc: 0.6628\n",
      "Epoch 48/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.6739 - acc: 0.6686\n",
      "Epoch 49/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.6858 - acc: 0.6715\n",
      "Epoch 50/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 0.6743 - acc: 0.6787\n",
      "Epoch 51/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.6685 - acc: 0.6657\n",
      "Epoch 52/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.6531 - acc: 0.6744\n",
      "Epoch 53/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.6493 - acc: 0.6816\n",
      "Epoch 54/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.6436 - acc: 0.6831\n",
      "Epoch 55/60\n",
      "691/691 [==============================] - 0s 45us/step - loss: 0.6365 - acc: 0.6802\n",
      "Epoch 56/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 0.6319 - acc: 0.6889\n",
      "Epoch 57/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.6326 - acc: 0.6874\n",
      "Epoch 58/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.6245 - acc: 0.6903\n",
      "Epoch 59/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.6227 - acc: 0.6946\n",
      "Epoch 60/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.6230 - acc: 0.6932\n",
      "77/77 [==============================] - 2s 25ms/step\n",
      "Epoch 1/60\n",
      "691/691 [==============================] - 5s 7ms/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 2/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 3/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 4/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 5/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 6/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 7/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 8/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 9/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 10/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 11/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 12/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 13/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 14/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 15/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 16/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 17/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 18/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 19/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 20/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 21/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 22/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 23/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 24/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 25/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 26/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 27/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 28/60\n",
      "691/691 [==============================] - 0s 51us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 29/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 30/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 31/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 32/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 33/60\n",
      "691/691 [==============================] - 0s 44us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 34/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 35/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 36/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 37/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 38/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 39/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 40/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 41/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 42/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 43/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 44/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 45/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 46/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 47/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 48/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 49/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 50/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 51/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 52/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 53/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 54/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 55/60\n",
      "691/691 [==============================] - 0s 51us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 56/60\n",
      "691/691 [==============================] - 0s 58us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 57/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 58/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 59/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 10.0822 - acc: 0.3676\n",
      "Epoch 60/60\n",
      "691/691 [==============================] - 0s 46us/step - loss: 10.0822 - acc: 0.3676\n",
      "77/77 [==============================] - 2s 25ms/step\n",
      "Epoch 1/60\n",
      "691/691 [==============================] - 5s 7ms/step - loss: 10.0610 - acc: 0.3546\n",
      "Epoch 2/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 9.8857 - acc: 0.3575\n",
      "Epoch 3/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 9.3791 - acc: 0.3575\n",
      "Epoch 4/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 8.3371 - acc: 0.3647\n",
      "Epoch 5/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 6.1250 - acc: 0.3763\n",
      "Epoch 6/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 3.7017 - acc: 0.4776\n",
      "Epoch 7/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 2.9824 - acc: 0.5991\n",
      "Epoch 8/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 2.9533 - acc: 0.6281\n",
      "Epoch 9/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 2.7032 - acc: 0.6107\n",
      "Epoch 10/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 2.5195 - acc: 0.5818\n",
      "Epoch 11/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 2.4657 - acc: 0.5789\n",
      "Epoch 12/60\n",
      "691/691 [==============================] - 0s 45us/step - loss: 2.3870 - acc: 0.5890\n",
      "Epoch 13/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 2.3100 - acc: 0.6035\n",
      "Epoch 14/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 2.2656 - acc: 0.5962\n",
      "Epoch 15/60\n",
      "691/691 [==============================] - 0s 51us/step - loss: 2.1978 - acc: 0.6006\n",
      "Epoch 16/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 2.1463 - acc: 0.6020\n",
      "Epoch 17/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 2.0889 - acc: 0.5919\n",
      "Epoch 18/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 2.0137 - acc: 0.5977\n",
      "Epoch 19/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 1.9668 - acc: 0.6064\n",
      "Epoch 20/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 1.8994 - acc: 0.6006\n",
      "Epoch 21/60\n",
      "691/691 [==============================] - 0s 45us/step - loss: 1.8493 - acc: 0.5991\n",
      "Epoch 22/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 1.7694 - acc: 0.5991\n",
      "Epoch 23/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 1.6919 - acc: 0.6122\n",
      "Epoch 24/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 1.6187 - acc: 0.6006\n",
      "Epoch 25/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 1.5512 - acc: 0.6093\n",
      "Epoch 26/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 1.4820 - acc: 0.6165\n",
      "Epoch 27/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 1.4200 - acc: 0.6078\n",
      "Epoch 28/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 1.3727 - acc: 0.6165\n",
      "Epoch 29/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 1.3413 - acc: 0.6179\n",
      "Epoch 30/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 1.3105 - acc: 0.6237\n",
      "Epoch 31/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 1.2825 - acc: 0.6223\n",
      "Epoch 32/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 1.2580 - acc: 0.6208\n",
      "Epoch 33/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 1.2422 - acc: 0.6281\n",
      "Epoch 34/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 1.2120 - acc: 0.6368\n",
      "Epoch 35/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 1.1982 - acc: 0.6208\n",
      "Epoch 36/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 1.1766 - acc: 0.6281\n",
      "Epoch 37/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 1.1588 - acc: 0.6353\n",
      "Epoch 38/60\n",
      "691/691 [==============================] - 0s 66us/step - loss: 1.1394 - acc: 0.6208\n",
      "Epoch 39/60\n",
      "691/691 [==============================] - 0s 56us/step - loss: 1.1241 - acc: 0.6266\n",
      "Epoch 40/60\n",
      "691/691 [==============================] - 0s 59us/step - loss: 1.1077 - acc: 0.6281\n",
      "Epoch 41/60\n",
      "691/691 [==============================] - 0s 55us/step - loss: 1.0993 - acc: 0.6353\n",
      "Epoch 42/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 1.0784 - acc: 0.6266\n",
      "Epoch 43/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 1.0631 - acc: 0.6281\n",
      "Epoch 44/60\n",
      "691/691 [==============================] - 0s 47us/step - loss: 1.0618 - acc: 0.6382\n",
      "Epoch 45/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 1.0358 - acc: 0.6281\n",
      "Epoch 46/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 1.0274 - acc: 0.6353\n",
      "Epoch 47/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 1.0193 - acc: 0.6281\n",
      "Epoch 48/60\n",
      "691/691 [==============================] - 0s 50us/step - loss: 1.0074 - acc: 0.6498\n",
      "Epoch 49/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.9996 - acc: 0.6425\n",
      "Epoch 50/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 0.9923 - acc: 0.6339\n",
      "Epoch 51/60\n",
      "691/691 [==============================] - 0s 49us/step - loss: 0.9837 - acc: 0.6425\n",
      "Epoch 52/60\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.9768 - acc: 0.6570\n",
      "Epoch 53/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.9678 - acc: 0.6483\n",
      "Epoch 54/60\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.9541 - acc: 0.6643\n",
      "Epoch 55/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.9359 - acc: 0.6599\n",
      "Epoch 56/60\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.9216 - acc: 0.6527\n",
      "Epoch 57/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.9053 - acc: 0.6556\n",
      "Epoch 58/60\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.8971 - acc: 0.6585\n",
      "Epoch 59/60\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.8510 - acc: 0.6541\n",
      "Epoch 60/60\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.8209 - acc: 0.6585\n",
      "77/77 [==============================] - 2s 25ms/step\n",
      "Epoch 1/60\n",
      "692/692 [==============================] - 5s 7ms/step - loss: 3.8145 - acc: 0.5578\n",
      "Epoch 2/60\n",
      "692/692 [==============================] - 0s 51us/step - loss: 3.6278 - acc: 0.5983\n",
      "Epoch 3/60\n",
      "692/692 [==============================] - 0s 47us/step - loss: 3.5819 - acc: 0.5997\n",
      "Epoch 4/60\n",
      "692/692 [==============================] - 0s 47us/step - loss: 3.5250 - acc: 0.5694\n",
      "Epoch 5/60\n",
      "692/692 [==============================] - 0s 51us/step - loss: 3.4867 - acc: 0.5679\n",
      "Epoch 6/60\n",
      "692/692 [==============================] - 0s 59us/step - loss: 3.4461 - acc: 0.5780\n",
      "Epoch 7/60\n",
      "692/692 [==============================] - 0s 55us/step - loss: 3.3873 - acc: 0.5766\n",
      "Epoch 8/60\n",
      "692/692 [==============================] - 0s 52us/step - loss: 3.3562 - acc: 0.5795\n",
      "Epoch 9/60\n",
      "692/692 [==============================] - 0s 49us/step - loss: 3.3190 - acc: 0.5910\n",
      "Epoch 10/60\n",
      "692/692 [==============================] - 0s 48us/step - loss: 3.2920 - acc: 0.5795\n",
      "Epoch 11/60\n",
      "692/692 [==============================] - 0s 50us/step - loss: 3.2603 - acc: 0.5809\n",
      "Epoch 12/60\n",
      "692/692 [==============================] - 0s 55us/step - loss: 3.2362 - acc: 0.5853\n",
      "Epoch 13/60\n",
      "692/692 [==============================] - 0s 49us/step - loss: 3.2025 - acc: 0.5896\n",
      "Epoch 14/60\n",
      "692/692 [==============================] - 0s 51us/step - loss: 3.1677 - acc: 0.5910\n",
      "Epoch 15/60\n",
      "692/692 [==============================] - 0s 50us/step - loss: 3.1311 - acc: 0.5954\n",
      "Epoch 16/60\n",
      "692/692 [==============================] - 0s 55us/step - loss: 3.0740 - acc: 0.5838\n",
      "Epoch 17/60\n",
      "692/692 [==============================] - 0s 57us/step - loss: 3.0289 - acc: 0.5751\n",
      "Epoch 18/60\n",
      "692/692 [==============================] - 0s 56us/step - loss: 2.9229 - acc: 0.5882\n",
      "Epoch 19/60\n",
      "692/692 [==============================] - 0s 51us/step - loss: 2.7544 - acc: 0.5737\n",
      "Epoch 20/60\n",
      "692/692 [==============================] - 0s 49us/step - loss: 2.5239 - acc: 0.5679\n",
      "Epoch 21/60\n",
      "692/692 [==============================] - 0s 49us/step - loss: 2.3355 - acc: 0.5795\n",
      "Epoch 22/60\n",
      "692/692 [==============================] - 0s 51us/step - loss: 2.1888 - acc: 0.5694\n",
      "Epoch 23/60\n",
      "692/692 [==============================] - 0s 61us/step - loss: 2.0473 - acc: 0.5665\n",
      "Epoch 24/60\n",
      "692/692 [==============================] - 0s 57us/step - loss: 1.9433 - acc: 0.5650\n",
      "Epoch 25/60\n",
      "692/692 [==============================] - 0s 57us/step - loss: 1.8210 - acc: 0.5650\n",
      "Epoch 26/60\n",
      "692/692 [==============================] - 0s 60us/step - loss: 1.7083 - acc: 0.5636\n",
      "Epoch 27/60\n",
      "692/692 [==============================] - 0s 53us/step - loss: 1.6069 - acc: 0.5795\n",
      "Epoch 28/60\n",
      "692/692 [==============================] - 0s 48us/step - loss: 1.5158 - acc: 0.5795\n",
      "Epoch 29/60\n",
      "692/692 [==============================] - 0s 49us/step - loss: 1.4242 - acc: 0.6040\n",
      "Epoch 30/60\n",
      "692/692 [==============================] - 0s 49us/step - loss: 1.3555 - acc: 0.6113\n",
      "Epoch 31/60\n",
      "692/692 [==============================] - 0s 60us/step - loss: 1.2913 - acc: 0.6142\n",
      "Epoch 32/60\n",
      "692/692 [==============================] - 0s 56us/step - loss: 1.2343 - acc: 0.6402\n",
      "Epoch 33/60\n",
      "692/692 [==============================] - 0s 55us/step - loss: 1.1976 - acc: 0.6098\n",
      "Epoch 34/60\n",
      "692/692 [==============================] - 0s 50us/step - loss: 1.1546 - acc: 0.6373\n",
      "Epoch 35/60\n",
      "692/692 [==============================] - 0s 48us/step - loss: 1.0960 - acc: 0.6488\n",
      "Epoch 36/60\n",
      "692/692 [==============================] - 0s 49us/step - loss: 1.0601 - acc: 0.6344\n",
      "Epoch 37/60\n",
      "692/692 [==============================] - 0s 47us/step - loss: 1.0269 - acc: 0.6517\n",
      "Epoch 38/60\n",
      "692/692 [==============================] - 0s 56us/step - loss: 0.9979 - acc: 0.6532\n",
      "Epoch 39/60\n",
      "692/692 [==============================] - 0s 55us/step - loss: 0.9658 - acc: 0.6676\n",
      "Epoch 40/60\n",
      "692/692 [==============================] - 0s 56us/step - loss: 0.9358 - acc: 0.6647\n",
      "Epoch 41/60\n",
      "692/692 [==============================] - 0s 55us/step - loss: 0.9155 - acc: 0.6662\n",
      "Epoch 42/60\n",
      "692/692 [==============================] - 0s 48us/step - loss: 0.8813 - acc: 0.6532\n",
      "Epoch 43/60\n",
      "692/692 [==============================] - 0s 48us/step - loss: 0.8480 - acc: 0.6604\n",
      "Epoch 44/60\n",
      "692/692 [==============================] - 0s 48us/step - loss: 0.8323 - acc: 0.6749\n",
      "Epoch 45/60\n",
      "692/692 [==============================] - 0s 47us/step - loss: 0.7847 - acc: 0.6835\n",
      "Epoch 46/60\n",
      "692/692 [==============================] - 0s 57us/step - loss: 0.7628 - acc: 0.6806\n",
      "Epoch 47/60\n",
      "692/692 [==============================] - 0s 56us/step - loss: 0.7362 - acc: 0.6691\n",
      "Epoch 48/60\n",
      "692/692 [==============================] - 0s 55us/step - loss: 0.7041 - acc: 0.6734\n",
      "Epoch 49/60\n",
      "692/692 [==============================] - 0s 49us/step - loss: 0.7029 - acc: 0.6806\n",
      "Epoch 50/60\n",
      "692/692 [==============================] - 0s 48us/step - loss: 0.6776 - acc: 0.6561\n",
      "Epoch 51/60\n",
      "692/692 [==============================] - 0s 55us/step - loss: 0.6580 - acc: 0.6749\n",
      "Epoch 52/60\n",
      "692/692 [==============================] - 0s 49us/step - loss: 0.6777 - acc: 0.6734\n",
      "Epoch 53/60\n",
      "692/692 [==============================] - 0s 61us/step - loss: 0.6639 - acc: 0.6720\n",
      "Epoch 54/60\n",
      "692/692 [==============================] - 0s 58us/step - loss: 0.6506 - acc: 0.6806\n",
      "Epoch 55/60\n",
      "692/692 [==============================] - 0s 55us/step - loss: 0.6394 - acc: 0.6936\n",
      "Epoch 56/60\n",
      "692/692 [==============================] - 0s 50us/step - loss: 0.6434 - acc: 0.6734\n",
      "Epoch 57/60\n",
      "692/692 [==============================] - 0s 50us/step - loss: 0.6414 - acc: 0.6792\n",
      "Epoch 58/60\n",
      "692/692 [==============================] - 0s 50us/step - loss: 0.6285 - acc: 0.6864\n",
      "Epoch 59/60\n",
      "692/692 [==============================] - 0s 50us/step - loss: 0.6414 - acc: 0.6676\n",
      "Epoch 60/60\n",
      "692/692 [==============================] - 0s 59us/step - loss: 0.6461 - acc: 0.6821\n",
      "76/76 [==============================] - 2s 26ms/step\n",
      "Epoch 1/60\n",
      "692/692 [==============================] - 4s 6ms/step - loss: 4.6838 - acc: 0.6488\n",
      "Epoch 2/60\n",
      "692/692 [==============================] - 0s 49us/step - loss: 3.1785 - acc: 0.5650\n",
      "Epoch 3/60\n",
      "692/692 [==============================] - 0s 48us/step - loss: 2.6572 - acc: 0.4639\n",
      "Epoch 4/60\n",
      "692/692 [==============================] - 0s 53us/step - loss: 2.3727 - acc: 0.5376\n",
      "Epoch 5/60\n",
      "692/692 [==============================] - 0s 51us/step - loss: 2.2165 - acc: 0.5217\n",
      "Epoch 6/60\n",
      "692/692 [==============================] - 0s 59us/step - loss: 2.0692 - acc: 0.5130\n",
      "Epoch 7/60\n",
      "692/692 [==============================] - 0s 55us/step - loss: 1.9325 - acc: 0.5520\n",
      "Epoch 8/60\n",
      "692/692 [==============================] - 0s 52us/step - loss: 1.7817 - acc: 0.5636\n",
      "Epoch 9/60\n",
      "692/692 [==============================] - 0s 47us/step - loss: 1.6296 - acc: 0.5694\n",
      "Epoch 10/60\n",
      "692/692 [==============================] - 0s 50us/step - loss: 1.5061 - acc: 0.5462\n",
      "Epoch 11/60\n",
      "692/692 [==============================] - 0s 48us/step - loss: 1.3824 - acc: 0.5954\n",
      "Epoch 12/60\n",
      "692/692 [==============================] - 0s 55us/step - loss: 1.2735 - acc: 0.5766\n",
      "Epoch 13/60\n",
      "692/692 [==============================] - 0s 52us/step - loss: 1.1748 - acc: 0.6098\n",
      "Epoch 14/60\n",
      "692/692 [==============================] - 0s 48us/step - loss: 1.0904 - acc: 0.6127\n",
      "Epoch 15/60\n",
      "692/692 [==============================] - 0s 49us/step - loss: 1.0233 - acc: 0.6142\n",
      "Epoch 16/60\n",
      "692/692 [==============================] - 0s 50us/step - loss: 0.9577 - acc: 0.6243\n",
      "Epoch 17/60\n",
      "692/692 [==============================] - 0s 60us/step - loss: 0.9488 - acc: 0.6113\n",
      "Epoch 18/60\n",
      "692/692 [==============================] - 0s 60us/step - loss: 0.8837 - acc: 0.6214\n",
      "Epoch 19/60\n",
      "692/692 [==============================] - 0s 57us/step - loss: 0.8553 - acc: 0.6532\n",
      "Epoch 20/60\n",
      "692/692 [==============================] - 0s 48us/step - loss: 0.8338 - acc: 0.6460\n",
      "Epoch 21/60\n",
      "692/692 [==============================] - 0s 50us/step - loss: 0.8011 - acc: 0.6517\n",
      "Epoch 22/60\n",
      "692/692 [==============================] - 0s 49us/step - loss: 0.7746 - acc: 0.6474\n",
      "Epoch 23/60\n",
      "692/692 [==============================] - 0s 51us/step - loss: 0.7649 - acc: 0.6647\n",
      "Epoch 24/60\n",
      "692/692 [==============================] - 0s 61us/step - loss: 0.7394 - acc: 0.6488\n",
      "Epoch 25/60\n",
      "692/692 [==============================] - 0s 54us/step - loss: 0.7447 - acc: 0.6662\n",
      "Epoch 26/60\n",
      "692/692 [==============================] - 0s 58us/step - loss: 0.7546 - acc: 0.6618\n",
      "Epoch 27/60\n",
      "692/692 [==============================] - 0s 56us/step - loss: 0.7243 - acc: 0.6618\n",
      "Epoch 28/60\n",
      "692/692 [==============================] - 0s 48us/step - loss: 0.7030 - acc: 0.6676\n",
      "Epoch 29/60\n",
      "692/692 [==============================] - 0s 49us/step - loss: 0.6872 - acc: 0.6749\n",
      "Epoch 30/60\n",
      "692/692 [==============================] - 0s 48us/step - loss: 0.6922 - acc: 0.6662\n",
      "Epoch 31/60\n",
      "692/692 [==============================] - 0s 48us/step - loss: 0.6779 - acc: 0.6691\n",
      "Epoch 32/60\n",
      "692/692 [==============================] - 0s 58us/step - loss: 0.6657 - acc: 0.6821\n",
      "Epoch 33/60\n",
      "692/692 [==============================] - 0s 53us/step - loss: 0.6621 - acc: 0.6763\n",
      "Epoch 34/60\n",
      "692/692 [==============================] - 0s 55us/step - loss: 0.6539 - acc: 0.6792\n",
      "Epoch 35/60\n",
      "692/692 [==============================] - 0s 50us/step - loss: 0.6580 - acc: 0.6734\n",
      "Epoch 36/60\n",
      "692/692 [==============================] - 0s 46us/step - loss: 0.6589 - acc: 0.6792\n",
      "Epoch 37/60\n",
      "692/692 [==============================] - 0s 49us/step - loss: 0.6449 - acc: 0.6676\n",
      "Epoch 38/60\n",
      "692/692 [==============================] - 0s 50us/step - loss: 0.6376 - acc: 0.6893\n",
      "Epoch 39/60\n",
      "692/692 [==============================] - 0s 54us/step - loss: 0.6366 - acc: 0.6908\n",
      "Epoch 40/60\n",
      "692/692 [==============================] - 0s 56us/step - loss: 0.6360 - acc: 0.6792\n",
      "Epoch 41/60\n",
      "692/692 [==============================] - 0s 55us/step - loss: 0.6309 - acc: 0.6908\n",
      "Epoch 42/60\n",
      "692/692 [==============================] - 0s 55us/step - loss: 0.6303 - acc: 0.6908\n",
      "Epoch 43/60\n",
      "692/692 [==============================] - 0s 51us/step - loss: 0.6303 - acc: 0.6922\n",
      "Epoch 44/60\n",
      "692/692 [==============================] - 0s 48us/step - loss: 0.6272 - acc: 0.6893\n",
      "Epoch 45/60\n",
      "692/692 [==============================] - 0s 48us/step - loss: 0.6262 - acc: 0.6879\n",
      "Epoch 46/60\n",
      "692/692 [==============================] - 0s 47us/step - loss: 0.6168 - acc: 0.7038\n",
      "Epoch 47/60\n",
      "692/692 [==============================] - 0s 56us/step - loss: 0.6213 - acc: 0.6879\n",
      "Epoch 48/60\n",
      "692/692 [==============================] - 0s 54us/step - loss: 0.6206 - acc: 0.6893\n",
      "Epoch 49/60\n",
      "692/692 [==============================] - 0s 54us/step - loss: 0.6680 - acc: 0.6633\n",
      "Epoch 50/60\n",
      "692/692 [==============================] - 0s 56us/step - loss: 0.6773 - acc: 0.6460\n",
      "Epoch 51/60\n",
      "692/692 [==============================] - 0s 49us/step - loss: 0.6473 - acc: 0.6965\n",
      "Epoch 52/60\n",
      "692/692 [==============================] - 0s 48us/step - loss: 0.6582 - acc: 0.6835\n",
      "Epoch 53/60\n",
      "692/692 [==============================] - 0s 49us/step - loss: 0.6232 - acc: 0.6864\n",
      "Epoch 54/60\n",
      "692/692 [==============================] - 0s 49us/step - loss: 0.6066 - acc: 0.6908\n",
      "Epoch 55/60\n",
      "692/692 [==============================] - 0s 57us/step - loss: 0.6032 - acc: 0.6994\n",
      "Epoch 56/60\n",
      "692/692 [==============================] - 0s 55us/step - loss: 0.6063 - acc: 0.6835\n",
      "Epoch 57/60\n",
      "692/692 [==============================] - 0s 53us/step - loss: 0.6061 - acc: 0.7009\n",
      "Epoch 58/60\n",
      "692/692 [==============================] - 0s 50us/step - loss: 0.6041 - acc: 0.6994\n",
      "Epoch 59/60\n",
      "692/692 [==============================] - 0s 47us/step - loss: 0.5987 - acc: 0.7095\n",
      "Epoch 60/60\n",
      "692/692 [==============================] - 0s 50us/step - loss: 0.5977 - acc: 0.6879\n",
      "76/76 [==============================] - 2s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seek/anaconda3/envs/U4-S2-NNF/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "768/768 [==============================] - 5s 6ms/step - loss: 4.5566 - acc: 0.4844\n",
      "Epoch 2/60\n",
      "768/768 [==============================] - 0s 70us/step - loss: 3.1315 - acc: 0.5742\n",
      "Epoch 3/60\n",
      "768/768 [==============================] - 0s 67us/step - loss: 2.2914 - acc: 0.5638\n",
      "Epoch 4/60\n",
      "768/768 [==============================] - 0s 68us/step - loss: 2.0807 - acc: 0.5716\n",
      "Epoch 5/60\n",
      "768/768 [==============================] - 0s 67us/step - loss: 1.7613 - acc: 0.5755\n",
      "Epoch 6/60\n",
      "768/768 [==============================] - 0s 65us/step - loss: 1.5754 - acc: 0.5872\n",
      "Epoch 7/60\n",
      "768/768 [==============================] - 0s 64us/step - loss: 1.4180 - acc: 0.5768\n",
      "Epoch 8/60\n",
      "768/768 [==============================] - 0s 63us/step - loss: 1.3505 - acc: 0.5586\n",
      "Epoch 9/60\n",
      "768/768 [==============================] - 0s 68us/step - loss: 1.2709 - acc: 0.5885\n",
      "Epoch 10/60\n",
      "768/768 [==============================] - 0s 66us/step - loss: 1.2107 - acc: 0.5990\n",
      "Epoch 11/60\n",
      "768/768 [==============================] - 0s 65us/step - loss: 1.1837 - acc: 0.6081\n",
      "Epoch 12/60\n",
      "768/768 [==============================] - 0s 67us/step - loss: 1.1628 - acc: 0.6328\n",
      "Epoch 13/60\n",
      "768/768 [==============================] - 0s 68us/step - loss: 1.0938 - acc: 0.6198\n",
      "Epoch 14/60\n",
      "768/768 [==============================] - 0s 72us/step - loss: 1.0589 - acc: 0.6406\n",
      "Epoch 15/60\n",
      "768/768 [==============================] - 0s 71us/step - loss: 1.0418 - acc: 0.6263\n",
      "Epoch 16/60\n",
      "768/768 [==============================] - 0s 69us/step - loss: 1.0246 - acc: 0.6354\n",
      "Epoch 17/60\n",
      "768/768 [==============================] - 0s 68us/step - loss: 1.0159 - acc: 0.6276\n",
      "Epoch 18/60\n",
      "768/768 [==============================] - 0s 66us/step - loss: 0.9912 - acc: 0.6471\n",
      "Epoch 19/60\n",
      "768/768 [==============================] - 0s 66us/step - loss: 0.9746 - acc: 0.6393\n",
      "Epoch 20/60\n",
      "768/768 [==============================] - 0s 68us/step - loss: 0.9719 - acc: 0.6484\n",
      "Epoch 21/60\n",
      "768/768 [==============================] - 0s 65us/step - loss: 0.9772 - acc: 0.6341\n",
      "Epoch 22/60\n",
      "768/768 [==============================] - 0s 69us/step - loss: 0.9456 - acc: 0.6393\n",
      "Epoch 23/60\n",
      "768/768 [==============================] - 0s 69us/step - loss: 0.9329 - acc: 0.6484\n",
      "Epoch 24/60\n",
      "768/768 [==============================] - 0s 67us/step - loss: 0.9245 - acc: 0.6484\n",
      "Epoch 25/60\n",
      "768/768 [==============================] - 0s 65us/step - loss: 0.9210 - acc: 0.6536\n",
      "Epoch 26/60\n",
      "768/768 [==============================] - 0s 67us/step - loss: 0.9018 - acc: 0.6510\n",
      "Epoch 27/60\n",
      "768/768 [==============================] - 0s 63us/step - loss: 0.8979 - acc: 0.6549\n",
      "Epoch 28/60\n",
      "768/768 [==============================] - 0s 67us/step - loss: 0.9194 - acc: 0.6419\n",
      "Epoch 29/60\n",
      "768/768 [==============================] - 0s 63us/step - loss: 0.8977 - acc: 0.6432\n",
      "Epoch 30/60\n",
      "768/768 [==============================] - 0s 69us/step - loss: 0.8780 - acc: 0.6641\n",
      "Epoch 31/60\n",
      "768/768 [==============================] - 0s 68us/step - loss: 0.8765 - acc: 0.6484\n",
      "Epoch 32/60\n",
      "768/768 [==============================] - 0s 67us/step - loss: 0.8664 - acc: 0.6693\n",
      "Epoch 33/60\n",
      "768/768 [==============================] - 0s 68us/step - loss: 0.8477 - acc: 0.6628\n",
      "Epoch 34/60\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.8451 - acc: 0.6641\n",
      "Epoch 35/60\n",
      "768/768 [==============================] - 0s 67us/step - loss: 0.8707 - acc: 0.6563\n",
      "Epoch 36/60\n",
      "768/768 [==============================] - 0s 67us/step - loss: 0.8441 - acc: 0.6654\n",
      "Epoch 37/60\n",
      "768/768 [==============================] - 0s 68us/step - loss: 0.8237 - acc: 0.6641\n",
      "Epoch 38/60\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.8217 - acc: 0.6589\n",
      "Epoch 39/60\n",
      "768/768 [==============================] - 0s 80us/step - loss: 0.8247 - acc: 0.6602\n",
      "Epoch 40/60\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.8293 - acc: 0.6719\n",
      "Epoch 41/60\n",
      "768/768 [==============================] - 0s 67us/step - loss: 0.8588 - acc: 0.6523\n",
      "Epoch 42/60\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.8079 - acc: 0.6654\n",
      "Epoch 43/60\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.8117 - acc: 0.6523\n",
      "Epoch 44/60\n",
      "768/768 [==============================] - 0s 67us/step - loss: 0.8255 - acc: 0.6693\n",
      "Epoch 45/60\n",
      "768/768 [==============================] - 0s 75us/step - loss: 0.7834 - acc: 0.6706\n",
      "Epoch 46/60\n",
      "768/768 [==============================] - 0s 74us/step - loss: 0.7740 - acc: 0.6693\n",
      "Epoch 47/60\n",
      "768/768 [==============================] - 0s 69us/step - loss: 0.7787 - acc: 0.6745\n",
      "Epoch 48/60\n",
      "768/768 [==============================] - 0s 68us/step - loss: 0.7659 - acc: 0.6667\n",
      "Epoch 49/60\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.7653 - acc: 0.6654\n",
      "Epoch 50/60\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.7860 - acc: 0.6784\n",
      "Epoch 51/60\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.7644 - acc: 0.6914\n",
      "Epoch 52/60\n",
      "768/768 [==============================] - 0s 74us/step - loss: 0.7717 - acc: 0.6706\n",
      "Epoch 53/60\n",
      "768/768 [==============================] - 0s 67us/step - loss: 0.7803 - acc: 0.6810\n",
      "Epoch 54/60\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.7783 - acc: 0.6758\n",
      "Epoch 55/60\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.7567 - acc: 0.6823\n",
      "Epoch 56/60\n",
      "768/768 [==============================] - 0s 79us/step - loss: 0.7587 - acc: 0.6940\n",
      "Epoch 57/60\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.7394 - acc: 0.6901\n",
      "Epoch 58/60\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.7803 - acc: 0.6667\n",
      "Epoch 59/60\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.7773 - acc: 0.6719\n",
      "Epoch 60/60\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.7352 - acc: 0.6836\n",
      "Best: 0.665364585040758 using {'batch_size': 60, 'epochs': 60}\n",
      "Means: 0.6002604179472352, Stdev: 0.1145761389810906 with: {'batch_size': 60, 'epochs': 20}\n",
      "Means: 0.6341145881839717, Stdev: 0.1062633951636483 with: {'batch_size': 60, 'epochs': 40}\n",
      "Means: 0.665364585040758, Stdev: 0.038648972103071236 with: {'batch_size': 60, 'epochs': 60}\n",
      "Means: 0.5208333301125094, Stdev: 0.13120622785070982 with: {'batch_size': 80, 'epochs': 20}\n",
      "Means: 0.6341145791423818, Stdev: 0.06580130546541955 with: {'batch_size': 80, 'epochs': 40}\n",
      "Means: 0.6328125020954758, Stdev: 0.15303328124206264 with: {'batch_size': 80, 'epochs': 60}\n"
     ]
    }
   ],
   "source": [
    "# define the grid search parameters\n",
    "param_grid = {'batch_size': [60, 80],\n",
    "              'epochs': [20, 40, 60]}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, cv=10, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X, Y)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b5feRhSiZ9o9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EKcuY6OiaLfz"
   },
   "source": [
    "## Optimizer\n",
    "\n",
    "Remember that there's a different optimizers [optimizers](https://keras.io/optimizers/). At some point, take some time to read up on them a little bit. \"adam\" usually gives the best results. The thing to know about choosing an optimizer is that different optimizers have different hyperparameters like learning rate, momentum, etc. So based on the optimizer you choose you might also have to tune the learning rate and momentum of those optimizers after that. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DG3wq5iOaLig"
   },
   "source": [
    "## Learning Rate\n",
    "\n",
    "Remember that the Learning Rate is a hyperparameter that is specific to your gradient-descent based optimizer selection. A learning rate that is too high will cause divergent behavior, but a Learning Rate that is too low will fail to converge, again, you're looking for the sweet spot. I would start out tuning learning rates by orders of magnitude: [.001, .01, .1, .2, .3, .5] etc. I wouldn't go above .5, but you can try it and see what the behavior is like. \n",
    "\n",
    "Once you have narrowed it down, make the window even smaller and try it again. If after running the above specification your model reports that .1 is the best optimizer, then you should probably try things like [.05, .08, .1, .12, .15] to try and narrow it down. \n",
    "\n",
    "It can also be good to tune the number of epochs in combination with the learning rate since the number of iterations that you allow the learning rate to reach the minimum can determine if you have let it run long enough to converge to the minimum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gNTBUWd1aLlA"
   },
   "source": [
    "## Momentum\n",
    "\n",
    "Momentum is a hyperparameter that is more commonly associated with Stochastic Gradient Descent. SGD is a common optimizer because it's what people understand and know, but I doubt it will get you the best results, you can try hyperparameter tuning its attributes and see if you can beat the performance from adam. Momentum is a property that decides the willingness of an optimizer to overshoot the minimum. Imagine a ball rolling down one side of a bowl and then up the opposite side a little bit before settling back to the bottom. The purpose of momentum is to try and escale local minima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xnEG-bCJaLnZ"
   },
   "source": [
    "## Activation Functions\n",
    "\n",
    "We've talked about this a little bit, typically you'l want to use ReLU for hidden layers and either Sigmoid, or Softmax for output layers of binary and multi-class classification implementations respectively, but try other activation functions and see if you can get any better results with sigmoid or tanh or something. There are a lot of activation functions that we haven't really talked about. Maybe you'll get good results with them. Maybe you won't. :) <https://keras.io/activations/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oul9sPq-dU-h"
   },
   "source": [
    "## Network Weight Initialization\n",
    "\n",
    "You saw how big of an effect the way that we initialize our network's weights can have on our results. There are **a lot** of what are called initialization modes. I don't understand all of them, but they can have a big affect on your model's initial accuracy. Your model will get further with less epochs if you initialize it with weights that are well suited to the problem you're trying to solve.\n",
    "\n",
    "`init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bqtEuxeQaLqE"
   },
   "source": [
    "## Dropout Regularization and the Weight Constraint\n",
    "\n",
    "the Dropout Regularization value is a percentage of neurons that you want to be randomly deactivated during training. The weight constraint is a second regularization parameter that works in tandem with dropout regularization. You should tune these two values at the same time. \n",
    "\n",
    "Using dropout on visible vs hidden layers might have a different effect. Using dropout on hidden layers might not have any effect while using dropout on hidden layers might have a substantial effect. You don't necessarily need to turn use dropout unless you see that your model has overfitting and generalizability problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P2c5Cv6oaLtO"
   },
   "source": [
    "## Neurons in Hidden Layer \n",
    "\n",
    "Remember that when we only had a single perceptron our model was only able to fit to linearly separable data, but as we have added layers and nodes to those layers our network has become a powerhouse of fitting nonlinearity in data. The larger the network and the more nodes generally the stronger the network's capacity to fit nonlinear patterns in data. The more nodes and layers the longer it will take to train a network, and higher the probability of overfitting. The larger your network gets the more you'll need dropout regularization or other regularization techniques to keep it in check. \n",
    "\n",
    "Typically depth (more layers) is more important than width (more nodes) for neural networks. This is part of why Deep Learning is so highly touted. Certain deep learning architectures have truly been huge breakthroughs for certain machine learning tasks. \n",
    "\n",
    "You might borrow ideas from other network architectures. For example if I was doing image recognition and I wasn't taking cues from state of the art architectures like resnet, alexnet, googlenet, etc. Then I'm probably going to have to do a lot more experimentation on my own before I find something that works.\n",
    "\n",
    "There are some heuristics, but I am highly skeptical of them. I think you're better off experimenting on your own and forming your own intuition for these kinds of problems. \n",
    "\n",
    "- https://machinelearningmastery.com/how-to-configure-the-number-of-layers-and-nodes-in-a-neural-network/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3LvRYQOwd-aZ"
   },
   "source": [
    "# Hyperparameter Tuning Tips:\n",
    "\n",
    "1) Use **at least** 3-fold cross validation. 5-fold or 10-fold would be better if you're patient enough.\n",
    "\n",
    "2) Sampling your dataset can speed up iterations if you have enough data to justify it.\n",
    "\n",
    "3) Start with \"Coarse Grids\" we gave an example of this when we were talking about Learning Rate, start with wide gaps between values that you're testing and then run additional tests with more narrow gaps between values until you find an optimum.\n",
    "\n",
    "4) Even though we're using Cross Validation, reproducibility can still be a challenge. Don't be afraid to run some tests multiple times to see if you get the same results. Sometimes the accuracy differences are so slight that grid search picking one hyperparameter over another is just luck of the draw.\n",
    "\n",
    "5) Run your tests in verbose mode. Not only will you be less stressed out wondering if it's actually running, but you will be able to more quickly identify if something has gone haywire by glancing at the output every now and again.\n",
    "\n",
    "6) Pick a moderate amount of epochs and stick with that all throughout your training, until the very end, then tune your epochs. \n",
    "\n",
    "7) As you begin to have a lot of hyperparameters narrowed down, test them along with narrow versions of other hyperparameters in order to catch the small effects of interactions between specific hyperparameters.\n",
    "\n",
    "8) Being a perfectionist here is going to be a long and painful journey, so please do a cost-benefit analysis of how you're using your time here. Learn the concept, have the experience, but don't spend 3 days hyperparameter tuning your assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z2cC0lpAhDQ_"
   },
   "source": [
    "## Additional Reading:\n",
    "\n",
    "I know I sound like a shill for Jason Brownlee, but honestly he has some of the very best articles on the internet in regards to hyperparameter tuning with Keras. I have leaned on his articles heavily when doing hyperparameter tuning before and saw great results from following his advice. He has articles on lots and lots of Keras related topics, so keep an ey out for his website: <http://machinelearningmastery.com> as you look through search results today.\n",
    "\n",
    "- https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "- https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/\n",
    "- https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
    "- https://machinelearningmastery.com/introduction-to-weight-constraints-to-reduce-generalization-error-in-deep-learning/\n",
    "- https://machinelearningmastery.com/how-to-configure-the-number-of-layers-and-nodes-in-a-neural-network/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_434_Hyperparameter_Tuning.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "U4-S2-NNF (Python 3.7)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
